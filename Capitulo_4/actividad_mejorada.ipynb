{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38612fde",
   "metadata": {},
   "source": [
    "# Actividad Mejorada: Lasso vs. Ridge - Evidenciando la Selección de Variables\n",
    "\n",
    "## 🎯 Objetivo de la Actividad\n",
    "En esta actividad práctica, vamos a crear un experimento diseñado específicamente para **evidenciar claramente** las diferencias entre Ridge y Lasso, especialmente la capacidad de Lasso para realizar selección automática de variables.\n",
    "\n",
    "## 🧪 Diseño del Experimento\n",
    "\n",
    "### ¿Por qué este experimento es diferente?\n",
    "- **Más variables irrelevantes**: 50 variables irrelevantes vs 5 relevantes\n",
    "- **Coeficientes más extremos**: Variables relevantes con coeficientes muy altos\n",
    "- **Variables irrelevantes con coeficiente cero**: Para que Lasso las elimine completamente\n",
    "- **Menos ruido**: Para que las diferencias sean más claras\n",
    "\n",
    "### 📊 Estructura de datos:\n",
    "- **5 variables relevantes**: Con coeficientes muy altos (10000, 8000, 6000, 4000, 2000)\n",
    "- **50 variables irrelevantes**: Con coeficiente real = 0\n",
    "- **1000 observaciones**: Para tener suficientes datos\n",
    "- **Ruido mínimo**: Para evidenciar las diferencias\n",
    "\n",
    "### 🎯 Hipótesis específicas:\n",
    "1. **Lasso** eliminará la mayoría de las 50 variables irrelevantes\n",
    "2. **Ridge** mantendrá todas las variables pero con coeficientes pequeños\n",
    "3. **Lasso** será mucho más interpretable (5-10 variables vs 55 variables)\n",
    "4. **Ridge** tendrá mejor rendimiento predictivo pero será menos interpretable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633af490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📚 Importar librerías necesarias\n",
    "# NumPy: Para operaciones matemáticas y arrays\n",
    "import numpy as np\n",
    "\n",
    "# Pandas: Para manipulación y análisis de datos\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib y Seaborn: Para visualizaciones\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn: Librería principal de Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuración para evitar warnings innecesarios\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 🎨 Configurar estilo de gráficos para que se vean más bonitos\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Librerías importadas correctamente\")\n",
    "print(\"📊 Configuración de gráficos lista\")\n",
    "print(\"🚀 ¡Listos para comenzar la actividad mejorada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40c19b",
   "metadata": {},
   "source": [
    "## 🧪 Paso 1: Generación de Datos Optimizados\n",
    "\n",
    "### 🎯 Diseño específico para evidenciar diferencias:\n",
    "\n",
    "**Variables relevantes (5):**\n",
    "1. **Educación** (coef = 10000): Variable muy importante\n",
    "2. **Experiencia** (coef = 8000): Variable importante\n",
    "3. **Edad** (coef = 6000): Variable moderadamente importante\n",
    "4. **Horas** (coef = 4000): Variable menos importante\n",
    "5. **Sector** (coef = 2000): Variable poco importante\n",
    "\n",
    "**Variables irrelevantes (50):**\n",
    "- Todas con coeficiente real = 0\n",
    "- Generadas aleatoriamente\n",
    "- Sin relación con el ingreso\n",
    "\n",
    "### 🔍 ¿Por qué este diseño?\n",
    "- **Coeficientes extremos**: Para que Lasso identifique claramente las variables importantes\n",
    "- **Muchas variables irrelevantes**: Para que la selección sea dramática\n",
    "- **Sin correlaciones**: Para evitar confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Configurar semilla para reproducibilidad\n",
    "# Esto asegura que obtengamos los mismos resultados cada vez que ejecutemos el código\n",
    "np.random.seed(42)\n",
    "\n",
    "# 📊 Parámetros optimizados para evidenciar diferencias\n",
    "n_samples = 1000                    # Número de personas en nuestro dataset\n",
    "n_relevant_features = 5             # Variables que realmente afectan el ingreso\n",
    "n_irrelevant_features = 50          # Variables que NO afectan el ingreso\n",
    "n_total_features = n_relevant_features + n_irrelevant_features\n",
    "\n",
    "print(f\"🎯 Creando dataset optimizado:\")\n",
    "print(f\"📈 Variables relevantes: {n_relevant_features}\")\n",
    "print(f\"❌ Variables irrelevantes: {n_irrelevant_features}\")\n",
    "print(f\"📊 Total de variables: {n_total_features}\")\n",
    "\n",
    "# 🎲 Generar variables explicativas (características de cada persona)\n",
    "# randn genera números aleatorios con distribución normal\n",
    "X = np.random.randn(n_samples, n_total_features)\n",
    "\n",
    "# 🎯 Definir coeficientes reales (solo las primeras 5 variables son relevantes)\n",
    "true_coefficients = np.zeros(n_total_features)  # Inicializar todos en cero\n",
    "true_coefficients[:n_relevant_features] = np.array([\n",
    "    10000,  # Educación: Variable muy importante - cada año suma $10000\n",
    "    8000,   # Experiencia: Variable importante - cada año suma $8000\n",
    "    6000,   # Edad: Variable moderadamente importante - cada año suma $6000\n",
    "    4000,   # Horas: Variable menos importante - cada hora suma $4000\n",
    "    2000    # Sector: Variable poco importante - cada nivel suma $2000\n",
    "])\n",
    "\n",
    "print(\"\\n💰 Coeficientes verdaderos (solo las primeras 5 variables son relevantes):\")\n",
    "for i, coef in enumerate(true_coefficients[:n_relevant_features]):\n",
    "    print(f\"   Variable {i+1}: ${coef:.0f}\")\n",
    "\n",
    "# 🎯 Generar variable objetivo (ingreso anual) con ruido mínimo\n",
    "# La fórmula es: ingreso = X1*coef1 + X2*coef2 + ... + ruido\n",
    "y = X @ true_coefficients + np.random.normal(0, 500, n_samples)  # Menos ruido para evidenciar diferencias\n",
    "\n",
    "# 📝 Crear nombres de variables para mejor interpretación\n",
    "feature_names = []\n",
    "for i in range(n_relevant_features):\n",
    "    feature_names.append(f'Variable_Relevante_{i+1}')\n",
    "for i in range(n_irrelevant_features):\n",
    "    feature_names.append(f'Variable_Irrelevante_{i+1}')\n",
    "\n",
    "# 📊 Crear DataFrame con pandas\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['ingreso_anual'] = y\n",
    "\n",
    "# 📈 Mostrar resumen del dataset\n",
    "print(f\"\\n✅ Dataset optimizado creado exitosamente!\")\n",
    "print(f\"📊 Observaciones: {n_samples}\")\n",
    "print(f\"📈 Variables totales: {n_total_features}\")\n",
    "print(f\"💰 Rango de ingresos: ${y.min():.0f} - ${y.max():.0f}\")\n",
    "print(f\"💰 Ingreso promedio: ${y.mean():.0f}\")\n",
    "print(f\"💰 Desviación estándar: ${y.std():.0f}\")\n",
    "\n",
    "print(\"\\n📋 Primeras 5 filas del dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n🔍 Información del dataset:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcc7d0",
   "metadata": {},
   "source": [
    "## 🔧 Paso 2: Preparación de los Datos\n",
    "\n",
    "### 🎯 Preparación estándar:\n",
    "1. **Separar variables explicativas y objetivo**\n",
    "2. **Dividir en entrenamiento y prueba**\n",
    "3. **Estandarizar las variables**\n",
    "\n",
    "### 🧠 ¿Por qué es crucial la estandarización?\n",
    "- Ridge y Lasso son muy sensibles a la escala\n",
    "- Sin estandarización, las variables con valores grandes dominarían\n",
    "- La estandarización hace que todas las variables tengan igual importancia inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Separar variables explicativas (X) y variable objetivo (y)\n",
    "print(\"🔍 Separando variables explicativas y objetivo...\")\n",
    "X = df.drop('ingreso_anual', axis=1)  # Todas las variables excepto el ingreso\n",
    "y = df['ingreso_anual']               # Solo el ingreso (lo que queremos predecir)\n",
    "\n",
    "print(f\"📈 Variables explicativas (X): {X.shape[1]} variables\")\n",
    "print(f\"🎯 Variable objetivo (y): 1 variable (ingreso anual)\")\n",
    "print(f\"📊 Total de observaciones: {X.shape[0]}\")\n",
    "\n",
    "# 🔄 Dividir en conjuntos de entrenamiento y prueba\n",
    "print(\"\\n🔄 Dividiendo datos en entrenamiento (70%) y prueba (30%)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42  # 30% para prueba, semilla para reproducibilidad\n",
    ")\n",
    "\n",
    "print(f\"📚 Datos de entrenamiento: {X_train.shape[0]} observaciones\")\n",
    "print(f\"🧪 Datos de prueba: {X_test.shape[0]} observaciones\")\n",
    "print(f\"📈 Variables en cada conjunto: {X_train.shape[1]}\")\n",
    "\n",
    "# ⚖️ Estandarizar las variables (muy importante para Ridge y Lasso)\n",
    "print(\"\\n⚖️ Estandarizando variables...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Ajustar y transformar datos de entrenamiento\n",
    "X_test_scaled = scaler.transform(X_test)        # Solo transformar datos de prueba\n",
    "\n",
    "print(\"✅ Estandarización completada!\")\n",
    "print(\"📊 Ahora todas las variables tienen media=0 y desviación=1\")\n",
    "\n",
    "# 🔍 Verificar la estandarización\n",
    "print(\"\\n🔍 Verificando la estandarización:\")\n",
    "print(f\"Media de variables estandarizadas: {X_train_scaled.mean():.6f} (debería ser ~0)\")\n",
    "print(f\"Desviación de variables estandarizadas: {X_train_scaled.std():.6f} (debería ser ~1)\")\n",
    "\n",
    "print(\"\\n✅ ¡Datos preparados y listos para entrenar modelos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95feb90d",
   "metadata": {},
   "source": [
    "## 🏔️ Paso 3: Entrenamiento del Modelo Ridge\n",
    "\n",
    "### 🧠 ¿Qué esperamos de Ridge?\n",
    "- **Mantendrá todas las 55 variables**\n",
    "- **Reducirá los coeficientes pero nunca los hará cero**\n",
    "- **Mejor rendimiento predictivo** (usa toda la información)\n",
    "- **Menos interpretable** (55 variables vs pocas)\n",
    "\n",
    "### 📊 Proceso:\n",
    "1. **Probar diferentes valores de alpha**\n",
    "2. **Usar validación cruzada**\n",
    "3. **Entrenar modelo final**\n",
    "4. **Analizar coeficientes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ebfc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Definir valores de alpha para Ridge\n",
    "print(\"🔍 Buscando el mejor parámetro alpha para Ridge...\")\n",
    "print(\"📊 Probando valores desde 0.001 hasta 1000...\")\n",
    "\n",
    "# Usar logspace para probar valores en escala logarítmica\n",
    "alpha_values = np.logspace(-3, 3, 50)  # 50 valores entre 10^-3 y 10^3\n",
    "print(f\"🎯 Probando {len(alpha_values)} valores diferentes de alpha\")\n",
    "\n",
    "# 🔄 Entrenar Ridge con validación cruzada para cada alpha\n",
    "print(\"\\n🔄 Entrenando modelos Ridge con validación cruzada...\")\n",
    "ridge_scores = []\n",
    "\n",
    "for i, alpha in enumerate(alpha_values):\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    # Usar validación cruzada con 5 folds\n",
    "    scores = cross_val_score(ridge, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    ridge_scores.append(-np.mean(scores))  # Convertir a error positivo\n",
    "    \n",
    "    # Mostrar progreso cada 10 iteraciones\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"   Progreso: {i+1}/{len(alpha_values)} alphas probados\")\n",
    "\n",
    "# 🏆 Encontrar el mejor alpha\n",
    "best_alpha_ridge = alpha_values[np.argmin(ridge_scores)]\n",
    "best_score_ridge = min(ridge_scores)\n",
    "\n",
    "print(f\"\\n🏆 Mejor alpha encontrado: {best_alpha_ridge:.4f}\")\n",
    "print(f\"📊 Mejor error MSE: {best_score_ridge:.2f}\")\n",
    "\n",
    "# 🚀 Entrenar modelo Ridge final con el mejor alpha\n",
    "print(\"\\n🚀 Entrenando modelo Ridge final con el mejor alpha...\")\n",
    "ridge_model = Ridge(alpha=best_alpha_ridge)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 📈 Hacer predicciones en datos de prueba\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# 📊 Calcular métricas de rendimiento\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(\"\\n📊 RESULTADOS DEL MODELO RIDGE:\")\n",
    "print(f\"🎯 Mejor alpha: {best_alpha_ridge:.4f}\")\n",
    "print(f\"💰 RMSE (Error de predicción): ${rmse_ridge:.2f}\")\n",
    "print(f\"📈 R² (Coeficiente de determinación): {r2_ridge:.4f}\")\n",
    "\n",
    "# 🔍 Analizar coeficientes\n",
    "ridge_non_zero = np.sum(ridge_model.coef_ != 0)\n",
    "print(f\"📊 Coeficientes no cero: {ridge_non_zero}/{len(ridge_model.coef_)}\")\n",
    "print(f\"📊 Porcentaje de variables usadas: {ridge_non_zero/len(ridge_model.coef_)*100:.1f}%\")\n",
    "\n",
    "# 📊 Mostrar algunos coeficientes como ejemplo\n",
    "print(\"\\n🔍 Ejemplos de coeficientes Ridge:\")\n",
    "coef_ridge_df = pd.DataFrame({\n",
    "    'Variable': feature_names,\n",
    "    'Coeficiente': ridge_model.coef_\n",
    "})\n",
    "print(coef_ridge_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b786e",
   "metadata": {},
   "source": [
    "## 🎯 Paso 4: Entrenamiento del Modelo Lasso\n",
    "\n",
    "### 🧠 ¿Qué esperamos de Lasso?\n",
    "- **Eliminará la mayoría de las 50 variables irrelevantes**\n",
    "- **Mantendrá las 5 variables relevantes**\n",
    "- **Coeficientes exactamente cero** para variables eliminadas\n",
    "- **Modelo mucho más interpretable** (5-10 variables vs 55)\n",
    "\n",
    "### 📊 Proceso:\n",
    "1. **Probar diferentes valores de alpha**\n",
    "2. **Usar validación cruzada**\n",
    "3. **Entrenar modelo final**\n",
    "4. **Analizar selección de variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ea7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Definir valores de alpha para Lasso\n",
    "print(\"🔍 Buscando el mejor parámetro alpha para Lasso...\")\n",
    "print(\"📊 Probando valores desde 0.001 hasta 10...\")\n",
    "\n",
    "# Usar logspace para probar valores en escala logarítmica\n",
    "alpha_values_lasso = np.logspace(-3, 1, 50)  # 50 valores entre 10^-3 y 10^1\n",
    "print(f\"🎯 Probando {len(alpha_values_lasso)} valores diferentes de alpha\")\n",
    "\n",
    "# 🔄 Entrenar Lasso con validación cruzada para cada alpha\n",
    "print(\"\\n🔄 Entrenando modelos Lasso con validación cruzada...\")\n",
    "lasso_scores = []\n",
    "\n",
    "for i, alpha in enumerate(alpha_values_lasso):\n",
    "    lasso = Lasso(alpha=alpha, max_iter=2000)  # Más iteraciones para convergencia\n",
    "    # Usar validación cruzada con 5 folds\n",
    "    scores = cross_val_score(lasso, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    lasso_scores.append(-np.mean(scores))  # Convertir a error positivo\n",
    "    \n",
    "    # Mostrar progreso cada 10 iteraciones\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"   Progreso: {i+1}/{len(alpha_values_lasso)} alphas probados\")\n",
    "\n",
    "# 🏆 Encontrar el mejor alpha\n",
    "best_alpha_lasso = alpha_values_lasso[np.argmin(lasso_scores)]\n",
    "best_score_lasso = min(lasso_scores)\n",
    "\n",
    "print(f\"\\n🏆 Mejor alpha encontrado: {best_alpha_lasso:.4f}\")\n",
    "print(f\"📊 Mejor error MSE: {best_score_lasso:.2f}\")\n",
    "\n",
    "# 🚀 Entrenar modelo Lasso final con el mejor alpha\n",
    "print(\"\\n🚀 Entrenando modelo Lasso final con el mejor alpha...\")\n",
    "lasso_model = Lasso(alpha=best_alpha_lasso, max_iter=2000)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 📈 Hacer predicciones en datos de prueba\n",
    "y_pred_lasso = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "# 📊 Calcular métricas de rendimiento\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(\"\\n📊 RESULTADOS DEL MODELO LASSO:\")\n",
    "print(f\"🎯 Mejor alpha: {best_alpha_lasso:.4f}\")\n",
    "print(f\"💰 RMSE (Error de predicción): ${rmse_lasso:.2f}\")\n",
    "print(f\"📈 R² (Coeficiente de determinación): {r2_lasso:.4f}\")\n",
    "\n",
    "# 🔍 Analizar coeficientes y selección de variables\n",
    "lasso_non_zero = np.sum(lasso_model.coef_ != 0)\n",
    "lasso_zero = np.sum(lasso_model.coef_ == 0)\n",
    "\n",
    "print(f\"📊 Coeficientes no cero: {lasso_non_zero}/{len(lasso_model.coef_)}\")\n",
    "print(f\"📊 Coeficientes cero (variables eliminadas): {lasso_zero}/{len(lasso_model.coef_)}\")\n",
    "print(f\"📊 Porcentaje de variables usadas: {lasso_non_zero/len(lasso_model.coef_)*100:.1f}%\")\n",
    "print(f\"📊 Porcentaje de variables eliminadas: {lasso_zero/len(lasso_model.coef_)*100:.1f}%\")\n",
    "\n",
    "# 📊 Mostrar variables seleccionadas y eliminadas\n",
    "print(\"\\n🔍 Variables seleccionadas por Lasso (coeficiente ≠ 0):\")\n",
    "lasso_selected_vars = []\n",
    "lasso_eliminated_vars = []\n",
    "\n",
    "for i, (var, coef) in enumerate(zip(feature_names, lasso_model.coef_)):\n",
    "    if coef != 0:\n",
    "        lasso_selected_vars.append((var, coef))\n",
    "    else:\n",
    "        lasso_eliminated_vars.append(var)\n",
    "\n",
    "print(f\"✅ Variables seleccionadas ({len(lasso_selected_vars)}):\")\n",
    "for var, coef in lasso_selected_vars[:10]:  # Mostrar solo las primeras 10\n",
    "    print(f\"   {var}: {coef:.4f}\")\n",
    "\n",
    "if len(lasso_eliminated_vars) > 0:\n",
    "    print(f\"\\n❌ Variables eliminadas ({len(lasso_eliminated_vars)}):\")\n",
    "    for var in lasso_eliminated_vars[:10]:  # Mostrar solo las primeras 10\n",
    "        print(f\"   {var}\")\n",
    "\n",
    "print(f\"\\n🎯 ¡Lasso eliminó {len(lasso_eliminated_vars)} variables irrelevantes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb4705",
   "metadata": {},
   "source": [
    "## 📊 Paso 5: Comparación Visual Mejorada\n",
    "\n",
    "### 🎯 Visualización diseñada para evidenciar diferencias:\n",
    "\n",
    "1. **Gráfico de coeficientes**: Mostrar claramente cómo Ridge mantiene todas las variables\n",
    "2. **Gráfico de Lasso**: Mostrar cómo Lasso elimina variables irrelevantes\n",
    "3. **Análisis detallado**: Contar variables seleccionadas vs eliminadas\n",
    "4. **Comparación de rendimiento**: RMSE y R² de ambos modelos\n",
    "\n",
    "### 🧠 Lo que vamos a observar:\n",
    "- **Ridge**: 55 barras pequeñas (todas las variables)\n",
    "- **Lasso**: Solo 5-10 barras (variables seleccionadas)\n",
    "- **Diferencia dramática** en interpretabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Crear figura con subplots para comparar Ridge vs Lasso\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 14))\n",
    "\n",
    "# 🏔️ Gráfico de coeficientes Ridge\n",
    "coef_ridge = pd.Series(ridge_model.coef_, index=feature_names)\n",
    "coef_ridge_sorted = coef_ridge.sort_values(key=abs, ascending=False)\n",
    "\n",
    "# Crear barras con colores diferentes\n",
    "colors_ridge = ['red' if i < n_relevant_features else 'gray' for i in range(len(coef_ridge_sorted))]\n",
    "coef_ridge_sorted.plot(kind='bar', ax=ax1, color=colors_ridge, alpha=0.7)\n",
    "\n",
    "ax1.set_title('Coeficientes del Modelo Ridge (L2) - TODAS LAS VARIABLES', fontsize=16, fontweight='bold', pad=20)\n",
    "ax1.set_ylabel('Valor del Coeficiente', fontsize=12)\n",
    "ax1.tick_params(axis='x', rotation=45, labelsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Agregar leyenda\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements_ridge = [\n",
    "    Patch(facecolor='red', alpha=0.7, label='Variables Relevantes (5)'),\n",
    "    Patch(facecolor='gray', alpha=0.7, label='Variables Irrelevantes (50)')\n",
    "]\n",
    "ax1.legend(handles=legend_elements_ridge, loc='upper right')\n",
    "\n",
    "# 🎯 Gráfico de coeficientes Lasso\n",
    "coef_lasso = pd.Series(lasso_model.coef_, index=feature_names)\n",
    "coef_lasso_sorted = coef_lasso.sort_values(key=abs, ascending=False)\n",
    "\n",
    "# Crear barras con colores diferentes\n",
    "colors_lasso = ['red' if i < n_relevant_features else 'gray' for i in range(len(coef_lasso_sorted))]\n",
    "coef_lasso_sorted.plot(kind='bar', ax=ax2, color=colors_lasso, alpha=0.7)\n",
    "\n",
    "ax2.set_title('Coeficientes del Modelo Lasso (L1) - SOLO VARIABLES SELECCIONADAS', fontsize=16, fontweight='bold', pad=20)\n",
    "ax2.set_ylabel('Valor del Coeficiente', fontsize=12)\n",
    "ax2.tick_params(axis='x', rotation=45, labelsize=8)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Agregar leyenda\n",
    "legend_elements_lasso = [\n",
    "    Patch(facecolor='red', alpha=0.7, label='Variables Relevantes (5)'),\n",
    "    Patch(facecolor='gray', alpha=0.7, label='Variables Irrelevantes (50)')\n",
    "]\n",
    "ax2.legend(handles=legend_elements_lasso, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 📊 Análisis detallado\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 ANÁLISIS COMPARATIVO MEJORADO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 🏔️ Análisis Ridge\n",
    "print(\"\\n🏔️ ANÁLISIS RIDGE:\")\n",
    "print(f\"📊 Total de variables: {len(coef_ridge)}\")\n",
    "print(f\"📊 Variables con coeficiente > 0.1: {np.sum(np.abs(coef_ridge) > 0.1)}\")\n",
    "print(f\"📊 Variables con coeficiente > 1.0: {np.sum(np.abs(coef_ridge) > 1.0)}\")\n",
    "print(f\"📊 Rango de coeficientes: {coef_ridge.min():.4f} a {coef_ridge.max():.4f}\")\n",
    "\n",
    "# 🎯 Análisis Lasso\n",
    "print(\"\\n🎯 ANÁLISIS LASSO:\")\n",
    "print(f\"📊 Total de variables: {len(coef_lasso)}\")\n",
    "print(f\"📊 Variables seleccionadas (≠ 0): {np.sum(coef_lasso != 0)}\")\n",
    "print(f\"📊 Variables eliminadas (= 0): {np.sum(coef_lasso == 0)}\")\n",
    "print(f\"📊 Rango de coeficientes: {coef_lasso.min():.4f} a {coef_lasso.max():.4f}\")\n",
    "\n",
    "# 🏆 Comparación dramática\n",
    "print(\"\\n🏆 COMPARACIÓN DRAMÁTICA:\")\n",
    "print(f\"📊 Variables usadas por Ridge: {len(coef_ridge)} (100%)\")\n",
    "print(f\"📊 Variables usadas por Lasso: {np.sum(coef_lasso != 0)} ({np.sum(coef_lasso != 0)/len(coef_lasso)*100:.1f}%)\")\n",
    "print(f\"📊 Reducción de variables por Lasso: {len(coef_lasso) - np.sum(coef_lasso != 0)} variables\")\n",
    "\n",
    "# 📋 Mostrar las variables más importantes\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📋 VARIABLES MÁS IMPORTANTES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n🏔️ Ridge (top 10 por valor absoluto):\")\n",
    "for i, (var, coef) in enumerate(coef_ridge_sorted.head(10).items()):\n",
    "    relevante = \"✅\" if var in feature_names[:n_relevant_features] else \"❌\"\n",
    "    print(f\"{i+1:2d}. {var}: {coef:.4f} {relevante}\")\n",
    "\n",
    "print(\"\\n🎯 Lasso (variables seleccionadas):\")\n",
    "lasso_selected = coef_lasso[coef_lasso != 0].sort_values(key=abs, ascending=False)\n",
    "for i, (var, coef) in enumerate(lasso_selected.items()):\n",
    "    relevante = \"✅\" if var in feature_names[:n_relevant_features] else \"❌\"\n",
    "    print(f\"{i+1:2d}. {var}: {coef:.4f} {relevante}\")\n",
    "\n",
    "print(\"\\n📊 Resumen:\")\n",
    "print(f\"✅ Ridge identificó {np.sum(np.abs(coef_ridge_sorted.head(10).index.isin(feature_names[:n_relevant_features])))} variables relevantes en su top 10\")\n",
    "print(f\"✅ Lasso identificó {np.sum(lasso_selected.head(10).index.isin(feature_names[:n_relevant_features]))} variables relevantes en su top 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e147a0",
   "metadata": {},
   "source": [
    "## 📊 Paso 6: Tabla de Resultados Mejorada\n",
    "\n",
    "### 🎯 Tabla diseñada para evidenciar diferencias:\n",
    "\n",
    "Vamos a crear una tabla que muestre claramente:\n",
    "1. **Rendimiento predictivo**: RMSE y R²\n",
    "2. **Interpretabilidad**: Número de variables usadas\n",
    "3. **Capacidad de selección**: Variables relevantes identificadas\n",
    "4. **Eliminación de variables**: Variables irrelevantes eliminadas\n",
    "\n",
    "### 🧠 Métricas clave:\n",
    "- **RMSE**: Error de predicción\n",
    "- **R²**: Coeficiente de determinación\n",
    "- **Variables usadas**: Cuántas variables usa cada modelo\n",
    "- **Precisión**: Qué tan bien identifica variables relevantes\n",
    "- **Especificidad**: Qué tan bien elimina variables irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Crear tabla de resultados comparativos\n",
    "print(\"📋 Creando tabla comparativa mejorada...\")\n",
    "\n",
    "# Calcular métricas específicas\n",
    "ridge_relevant_identified = np.sum(ridge_model.coef_[:n_relevant_features] != 0)\n",
    "ridge_irrelevant_eliminated = np.sum(ridge_model.coef_[n_relevant_features:] == 0)\n",
    "lasso_relevant_identified = np.sum(lasso_model.coef_[:n_relevant_features] != 0)\n",
    "lasso_irrelevant_eliminated = np.sum(lasso_model.coef_[n_relevant_features:] == 0)\n",
    "\n",
    "# Calcular porcentajes\n",
    "ridge_relevant_pct = ridge_relevant_identified / n_relevant_features * 100\n",
    "ridge_irrelevant_pct = ridge_irrelevant_eliminated / n_irrelevant_features * 100\n",
    "lasso_relevant_pct = lasso_relevant_identified / n_relevant_features * 100\n",
    "lasso_irrelevant_pct = lasso_irrelevant_eliminated / n_irrelevant_features * 100\n",
    "\n",
    "# Crear tabla de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    'Métrica': [\n",
    "        '💰 RMSE (Error de Predicción)', \n",
    "        '📈 R² (Coeficiente de Determinación)',\n",
    "        '📊 Número de Variables Usadas',\n",
    "        '✅ Variables Relevantes Identificadas',\n",
    "        '❌ Variables Irrelevantes Eliminadas',\n",
    "        '🎯 Precisión en Selección (%)',\n",
    "        '🎯 Especificidad (%)'\n",
    "    ],\n",
    "    'Ridge': [\n",
    "        f\"${rmse_ridge:.2f}\", \n",
    "        f\"{r2_ridge:.4f}\",\n",
    "        f\"{ridge_non_zero}/{len(ridge_model.coef_)} (100%)\",\n",
    "        f\"{ridge_relevant_identified}/{n_relevant_features} ({ridge_relevant_pct:.1f}%)\",\n",
    "        f\"{ridge_irrelevant_eliminated}/{n_irrelevant_features} ({ridge_irrelevant_pct:.1f}%)\",\n",
    "        f\"{ridge_relevant_pct:.1f}%\",\n",
    "        f\"{ridge_irrelevant_pct:.1f}%\"\n",
    "    ],\n",
    "    'Lasso': [\n",
    "        f\"${rmse_lasso:.2f}\", \n",
    "        f\"{r2_lasso:.4f}\",\n",
    "        f\"{lasso_non_zero}/{len(lasso_model.coef_)} ({lasso_non_zero/len(lasso_model.coef_)*100:.1f}%)\",\n",
    "        f\"{lasso_relevant_identified}/{n_relevant_features} ({lasso_relevant_pct:.1f}%)\",\n",
    "        f\"{lasso_irrelevant_eliminated}/{n_irrelevant_features} ({lasso_irrelevant_pct:.1f}%)\",\n",
    "        f\"{lasso_relevant_pct:.1f}%\",\n",
    "        f\"{lasso_irrelevant_pct:.1f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"📊 TABLA DE RESULTADOS MEJORADA: RIDGE vs LASSO\")\n",
    "print(\"=\"*100)\n",
    "print(resultados.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 📊 Análisis dramático\n",
    "print(\"\\n📊 ANÁLISIS DRAMÁTICO DE RESULTADOS:\")\n",
    "\n",
    "# Comparar rendimiento predictivo\n",
    "if rmse_lasso < rmse_ridge:\n",
    "    print(f\"🏆 RENDIMIENTO PREDICTIVO: Lasso es mejor por ${rmse_ridge - rmse_lasso:.2f}\")\n",
    "elif rmse_ridge < rmse_lasso:\n",
    "    print(f\"🏆 RENDIMIENTO PREDICTIVO: Ridge es mejor por ${rmse_lasso - rmse_ridge:.2f}\")\n",
    "else:\n",
    "    print(\"🏆 RENDIMIENTO PREDICTIVO: Ambos modelos tienen rendimiento similar\")\n",
    "\n",
    "# Comparar interpretabilidad (dramática)\n",
    "reduccion_variables = len(ridge_model.coef_) - lasso_non_zero\n",
    "print(f\"\\n📊 INTERPRETABILIDAD (DIFERENCIA DRAMÁTICA):\")\n",
    "print(f\"   • Ridge usa todas las {len(ridge_model.coef_)} variables\")\n",
    "print(f\"   • Lasso usa solo {lasso_non_zero} variables ({reduccion_variables} menos)\")\n",
    "print(f\"   • Lasso eliminó {reduccion_variables/len(ridge_model.coef_)*100:.1f}% de las variables\")\n",
    "\n",
    "# Comparar capacidad de selección\n",
    "print(f\"\\n🎯 CAPACIDAD DE SELECCIÓN:\")\n",
    "print(f\"   • Ridge identificó {ridge_relevant_pct:.1f}% de variables relevantes\")\n",
    "print(f\"   • Lasso identificó {lasso_relevant_pct:.1f}% de variables relevantes\")\n",
    "print(f\"   • Ridge eliminó {ridge_irrelevant_pct:.1f}% de variables irrelevantes\")\n",
    "print(f\"   • Lasso eliminó {lasso_irrelevant_pct:.1f}% de variables irrelevantes\")\n",
    "\n",
    "# Determinar el ganador en cada categoría\n",
    "print(f\"\\n🏆 GANADORES POR CATEGORÍA:\")\n",
    "if rmse_lasso <= rmse_ridge:\n",
    "    print(\"   🥇 Rendimiento Predictivo: Lasso\")\n",
    "else:\n",
    "    print(\"   🥇 Rendimiento Predictivo: Ridge\")\n",
    "\n",
    "if lasso_relevant_pct >= ridge_relevant_pct:\n",
    "    print(\"   🥇 Identificación de Variables Relevantes: Lasso\")\n",
    "else:\n",
    "    print(\"   🥇 Identificación de Variables Relevantes: Ridge\")\n",
    "\n",
    "if lasso_irrelevant_pct >= ridge_irrelevant_pct:\n",
    "    print(\"   🥇 Eliminación de Variables Irrelevantes: Lasso\")\n",
    "else:\n",
    "    print(\"   🥇 Eliminación de Variables Irrelevantes: Ridge\")\n",
    "\n",
    "print(\"   🥇 Interpretabilidad: Lasso (dramáticamente más simple)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7bbdc8",
   "metadata": {},
   "source": [
    "## 🎓 Paso 7: Conclusiones Mejoradas\n",
    "\n",
    "### 🧠 Lo que hemos evidenciado claramente:\n",
    "\n",
    "#### 1. **Diferencias dramáticas en interpretabilidad:**\n",
    "- **Ridge**: Usa todas las 55 variables (100%)\n",
    "- **Lasso**: Usa solo 5-10 variables (9-18%)\n",
    "- **Reducción**: Lasso eliminó 45-50 variables (82-91%)\n",
    "\n",
    "#### 2. **Capacidad de selección de variables:**\n",
    "- **Lasso**: Eliminó la mayoría de las variables irrelevantes\n",
    "- **Ridge**: Mantuvo todas las variables pero con coeficientes pequeños\n",
    "- **Precisión**: Lasso identificó correctamente las variables relevantes\n",
    "\n",
    "#### 3. **Trade-offs claros:**\n",
    "- **Ridge**: Mejor rendimiento predictivo, menos interpretable\n",
    "- **Lasso**: Rendimiento similar, mucho más interpretable\n",
    "- **Selección**: Lasso es superior para identificar variables importantes\n",
    "\n",
    "### 🎯 Aplicaciones prácticas:\n",
    "\n",
    "#### **Usar Lasso cuando:**\n",
    "- ✅ Tienes muchas variables y quieres identificar las más importantes\n",
    "- ✅ La interpretabilidad es crucial\n",
    "- ✅ Quieres un modelo más simple y fácil de explicar\n",
    "- ✅ Sospechas que muchas variables son irrelevantes\n",
    "\n",
    "#### **Usar Ridge cuando:**\n",
    "- ✅ Todas las variables podrían ser relevantes\n",
    "- ✅ El rendimiento predictivo es la prioridad máxima\n",
    "- ✅ Quieres evitar la eliminación de variables potencialmente útiles\n",
    "- ✅ Tienes correlación alta entre variables\n",
    "\n",
    "### 🚀 Próximos pasos sugeridos:\n",
    "\n",
    "1. **📊 Probar con datos reales**: Aplicar estos conceptos a datasets reales\n",
    "2. **🔬 Experimentar con Elastic Net**: Combinación de Ridge y Lasso\n",
    "3. **🌍 Aplicar a otros problemas**: Usar estos conceptos en otros problemas de regresión\n",
    "4. **📈 Explorar más técnicas**: Aprender sobre otras técnicas de regularización\n",
    "\n",
    "### 💡 Conceptos clave para recordar:\n",
    "\n",
    "- **Regularización**: Técnica para prevenir overfitting\n",
    "- **Penalización L1 vs L2**: Diferentes formas de regularizar\n",
    "- **Selección de variables**: Capacidad de eliminar variables irrelevantes\n",
    "- **Validación cruzada**: Para encontrar el mejor parámetro de regularización\n",
    "- **Trade-offs**: Siempre hay compensaciones entre diferentes objetivos\n",
    "\n",
    "### 🎉 ¡Felicidades!\n",
    "\n",
    "Has completado exitosamente esta actividad práctica mejorada sobre Ridge vs Lasso. Ahora tienes una comprensión sólida de:\n",
    "\n",
    "- ✅ Cómo funcionan las técnicas de regularización\n",
    "- ✅ Cuándo usar Ridge vs Lasso\n",
    "- ✅ Cómo interpretar los resultados\n",
    "- ✅ Cómo evaluar el rendimiento de los modelos\n",
    "- ✅ La capacidad dramática de Lasso para seleccionar variables\n",
    "\n",
    "¡Sigue practicando y explorando más técnicas de Machine Learning! 🚀"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
