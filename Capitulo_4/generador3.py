import nbformat as nbf

def generar_notebook_modelo_formato_corregido():
    """
    Genera un notebook de Jupyter con el formato de Markdown corregido
    para un manual introductorio, demostrando la RegresiÃ³n Lasso.
    """
    
    print("Iniciando la creaciÃ³n del notebook de modelado con formato corregido...")
    
    nb = nbf.v4.new_notebook()

    # --- CELDA 1: TÃ­tulo e IntroducciÃ³n (Markdown) ---
    cell1_md = """
# # AplicaciÃ³n PrÃ¡ctica: PredicciÃ³n de Ingresos con RegresiÃ³n Lasso
# 
## ğŸ¯ Objetivo de la Actividad
En esta actividad prÃ¡ctica, aprenderemos a usar la **RegresiÃ³n Lasso** para predecir el ingreso monetario de una persona. MÃ¡s allÃ¡ de la predicciÃ³n, nuestro objetivo principal es descubrir quÃ© caracterÃ­sticas socioeconÃ³micas son las mÃ¡s influyentes para determinar dicho ingreso.

### Â¿QuÃ© es la RegresiÃ³n Lasso?
Es una tÃ©cnica de Machine Learning que realiza dos tareas simultÃ¡neamente:
1.  **PredicciÃ³n**: Crea un modelo para estimar un valor numÃ©rico (como el ingreso).
2.  **SelecciÃ³n de Variables**: Identifica y descarta automÃ¡ticamente las variables menos importantes.

### ğŸ“‹ HipÃ³tesis que vamos a probar:
1.  Podemos construir un modelo que explique una parte significativa de la variaciÃ³n en los ingresos.
2.  **Lasso** nos ayudarÃ¡ a identificar un subconjunto de variables clave de entre todas las disponibles en la encuesta.

### ğŸ§  Conceptos Clave que Aprenderemos:
- **RegresiÃ³n Lineal**: La base sobre la que se construye Lasso.
- **PenalizaciÃ³n L1**: El "ingrediente secreto" de Lasso que permite la selecciÃ³n de variables.
- **ValidaciÃ³n Cruzada**: CÃ³mo elegir el mejor parÃ¡metro para nuestro modelo de forma automÃ¡tica.
- **InterpretaciÃ³n de Coeficientes**: CÃ³mo entender los resultados del modelo y quÃ© nos dicen sobre el mundo real.
"""

    # --- CELDA 2: ConfiguraciÃ³n del Entorno (CÃ³digo) ---
    cell2_code = """
# ğŸ“š Importar librerÃ­as necesarias
# NumPy: Para operaciones matemÃ¡ticas y arrays
import numpy as np

# Pandas: Para manipulaciÃ³n y anÃ¡lisis de datos
import pandas as pd

# Matplotlib y Seaborn: Para visualizaciones de alta calidad
import matplotlib.pyplot as plt
import seaborn as sns

# Scikit-learn: Nuestra librerÃ­a principal de Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LassoCV
from sklearn.metrics import mean_squared_error, r2_score

#  Configurar estilo de grÃ¡ficos para que se vean mÃ¡s profesionales
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("viridis")

print("âœ… LibrerÃ­as importadas correctamente")
print("ğŸ“Š ConfiguraciÃ³n de grÃ¡ficos lista")
print("ğŸš€ Â¡Listos para comenzar la actividad!")
"""

    # --- CELDA 3: Carga de Datos (Markdown) ---
    cell3_md = """
## Paso 1: Carga y ExploraciÃ³n de los Datos

### Â¿QuÃ© datos estamos usando?
Vamos a cargar un archivo llamado `data_processed_income_positive.csv`. Este no es el archivo original de la encuesta, sino una versiÃ³n que ya ha sido preparada para el modelado.
 
### ğŸ§  Concepto Importante: Preprocesamiento
El preprocesamiento es el conjunto de pasos que se realizan para limpiar y transformar los datos antes de dÃ¡rselos a un modelo. En nuestro caso, el preprocesamiento incluyÃ³:

1.  **Filtrado**: Se eliminaron las personas con ingreso cero para simplificar el problema.
2.  **TransformaciÃ³n LogarÃ­tmica**: La variable de ingreso fue transformada para que su distribuciÃ³n sea mÃ¡s simÃ©trica, lo que ayuda a los modelos lineales.
3.  **EstandarizaciÃ³n y CodificaciÃ³n**: Las variables numÃ©ricas se pusieron en la misma escala y las categÃ³ricas se convirtieron a un formato numÃ©rico.

> ğŸ’¡ **Nota:** La calidad del preprocesamiento es a menudo mÃ¡s importante que la elecciÃ³n del modelo en sÃ­.
"""
    
    # --- CELDA 4: Carga de Datos (CÃ³digo) ---
    cell4_code = """
# ğŸ“‚ Cargar los datos ya procesados desde el archivo CSV
try:
    data = pd.read_csv("data_processed_income_positive.csv")
    print(f"âœ… Datos preprocesados cargados exitosamente.")
    print(f"ğŸ“Š Dimensiones del dataset: {data.shape[0]} filas y {data.shape[1]} columnas.")
except FileNotFoundError:
    print("âŒ Error: El archivo 'data_processed_income_positive.csv' no fue encontrado.")
    print("   Por favor, asegÃºrate de haber ejecutado primero el script de preprocesamiento.")

# ğŸ“‹ Mostrar las primeras 5 filas para verificar la carga
print("\\nğŸ“‹ Primeras 5 filas del dataset procesado:")
display(data.head())
"""

    # --- CELDA 5: PreparaciÃ³n de Datos (Markdown) ---
    cell5_md = """
## Paso 2: PreparaciÃ³n para el Modelado

Antes de entrenar, debemos realizar dos pasos cruciales:

1.  **Separar variables**: Distinguir entre las **variables predictoras (X)** y la **variable objetivo (y)**.
2.  **Dividir en entrenamiento y prueba**: Para evaluar de forma honesta quÃ© tan bien generaliza nuestro modelo.

### ğŸ§  Conceptos Importantes:

**Variables Predictoras (X) vs. Variable Objetivo (y)**
- **X (features)**: Todas las columnas excepto `log_ingmo2hd`.
- **y (target)**: La columna `log_ingmo2hd`.

**Train-Test Split**
- **Datos de Entrenamiento (70%)**: Para "enseÃ±arle" al modelo los patrones en los datos.
- **Datos de Prueba (30%)**: Para evaluar el rendimiento del modelo en datos "nuevos" que no ha visto durante el entrenamiento.
"""

    # --- CELDA 6: SeparaciÃ³n y DivisiÃ³n (CÃ³digo) ---
    cell6_code = """
# ğŸ“Š Separar variables explicativas (X) y variable objetivo (y)
print("ğŸ” Separando variables predictoras (X) y objetivo (y)...")
X = data.drop('log_ingmo2hd', axis=1)
y = data['log_ingmo2hd']

print(f"ğŸ“ˆ Variables predictoras (X): {X.shape[1]} columnas")
print(f"ğŸ¯ Variable objetivo (y): 1 columna ('log_ingmo2hd')")

# ğŸ”„ Dividir en conjuntos de entrenamiento y prueba
print("\\nğŸ”„ Dividiendo datos en entrenamiento (70%) y prueba (30%)...")
# 'random_state=42' es una semilla que asegura que la divisiÃ³n sea siempre la misma, haciendo nuestro experimento reproducible.
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.30, random_state=42
)

print(f"ğŸ“š Datos de entrenamiento: {X_train.shape[0]} observaciones")
print(f"ğŸ§ª Datos de prueba: {X_test.shape[0]} observaciones")

print("\\nâœ… Â¡Datos preparados y listos para entrenar el modelo!")
"""

    # --- CELDA 7: Entrenamiento del Modelo (Markdown) ---
    cell7_md = """
## Paso 3: Entrenamiento del Modelo Lasso
 
### Â¿QuÃ© es `LassoCV`?
Usaremos `LassoCV`. Es una versiÃ³n "inteligente" de Lasso que incluye **ValidaciÃ³n Cruzada (Cross-Validation)** para encontrar el mejor parÃ¡metro de regularizaciÃ³n de forma automÃ¡tica.

### ğŸ§  Concepto clave: El ParÃ¡metro `alpha`
Lasso tiene un parÃ¡metro llamado **alpha (Î±)** que controla la fuerza de la regularizaciÃ³n:
- **Î± pequeÃ±o**: Poca penalizaciÃ³n. El modelo se parece a una regresiÃ³n normal.
- **Î± grande**: Mucha penalizaciÃ³n. El modelo elimina mÃ¡s variables.

`LassoCV` prueba una gama de `alphas` y elige el que produce el mejor rendimiento predictivo.
"""

    # --- CELDA 8: Entrenamiento del Modelo (CÃ³digo) ---
    cell8_code = """
# ğŸš€ Entrenar el modelo Lasso con ValidaciÃ³n Cruzada
print("ğŸ” Buscando el mejor parÃ¡metro alpha y entrenando el modelo Lasso...")

# 1. Definimos el modelo LassoCV
#    Le decimos que pruebe 200 valores de alpha y use 5 "folds" para la validaciÃ³n cruzada.
lasso_cv_model = LassoCV(alphas=np.logspace(-5, 1, 200), cv=5, random_state=42, max_iter=2000)

# 2. Entrenamos el modelo con los datos de entrenamiento
lasso_cv_model.fit(X_train, y_train)

# ğŸ† Mostrar el mejor alpha encontrado
print(f"\\nğŸ† Mejor alpha encontrado: {lasso_cv_model.alpha_:.5f}")
print("âœ… Â¡Modelo Lasso entrenado exitosamente!")
"""

    # --- CELDA 9: EvaluaciÃ³n (Markdown) ---
    cell9_md = """
## Paso 4: EvaluaciÃ³n del DesempeÃ±o del Modelo
 
Ahora que el modelo estÃ¡ entrenado, debemos evaluar quÃ© tan bien funciona en el conjunto de prueba.

### ğŸ§  MÃ©tricas de EvaluaciÃ³n:
- **RMSE (RaÃ­z del Error CuadrÃ¡tico Medio)**: Nos dice, en promedio, cuÃ¡l es el error de predicciÃ³n en la unidad original (Soles). **Menor es mejor**.
- **RÂ² (Coeficiente de DeterminaciÃ³n)**: Indica quÃ© porcentaje de la variabilidad del ingreso es explicado por nuestro modelo. **MÃ¡s cercano a 1 (o 100%) es mejor**.

### ğŸ’¡ Paso Crucial: Revertir la TransformaciÃ³n LogarÃ­tmica
Nuestro modelo predice el *logaritmo* del ingreso. Para que el error (RMSE) sea interpretable, debemos convertir las predicciones de vuelta a Soles usando la funciÃ³n exponencial (`np.expm1`).
"""

    # --- CELDA 10: EvaluaciÃ³n (CÃ³digo) ---
    cell10_code = """
# ğŸ“ˆ Hacer predicciones en datos de prueba
y_pred_log = lasso_cv_model.predict(X_test)

# ğŸ”„ Revertir la transformaciÃ³n logarÃ­tmica para obtener predicciones en Soles
y_pred_original = np.expm1(y_pred_log)
y_test_original = np.expm1(y_test)

# ğŸ“Š Calcular mÃ©tricas de rendimiento
rmse_lasso = np.sqrt(mean_squared_error(y_test_original, y_pred_original))
r2_lasso = r2_score(y_test_original, y_pred_original)

print("ğŸ“Š RESULTADOS DEL MODELO LASSO EN DATOS DE PRUEBA:")
print(f"ğŸ’° RMSE (Error de predicciÃ³n): ${rmse_lasso:,.2f} Soles")
print(f"ğŸ“ˆ RÂ² (Coeficiente de determinaciÃ³n): {r2_lasso:.4f} (es decir, el modelo explica el {r2_lasso:.1%} de la varianza del ingreso)")
"""

    # --- CELDA 11: InterpretaciÃ³n (Markdown) ---
    cell11_md = """
## Paso 5: InterpretaciÃ³n de Resultados - El Poder de Lasso
 
Esta es la parte mÃ¡s interesante. Â¿QuÃ© variables considerÃ³ el modelo como importantes?

### ğŸ§  Concepto Clave: Coeficientes del Modelo
El modelo asigna un **coeficiente** a cada variable. La magia de Lasso es que:
- Si el coeficiente es **cero**, Lasso ha **descartado** esa variable por no considerarla relevante.
- Si el coeficiente es **distinto de cero**, es una **variable seleccionada**.

**InterpretaciÃ³n de los coeficientes (en nuestro modelo log-level):**
- Un **coeficiente positivo** (ej: 0.10) significa que un aumento en esa variable se asocia con un aumento porcentual en el ingreso (aprox. 10%).
- Un **coeficiente negativo** (ej: -0.05) significa que un aumento en esa variable se asocia con una disminuciÃ³n porcentual en el ingreso (aprox. 5%).
"""
    
    # --- CELDA 12: InterpretaciÃ³n (CÃ³digo) ---
    cell12_code = """
# ğŸ” Analizar coeficientes y selecciÃ³n de variables
print("ğŸ” Analizando los coeficientes del modelo Lasso...")

# Crear un DataFrame con los predictores y sus coeficientes
coeficientes_lasso = pd.DataFrame({
    'predictor': X.columns,
    'coef': lasso_cv_model.coef_
})

# Filtrar los coeficientes que no son cero
coeficientes_seleccionados = coeficientes_lasso[coeficientes_lasso['coef'] != 0].copy()
lasso_zero = np.sum(lasso_cv_model.coef_ == 0)

# Ordenar por el valor absoluto para ver los mÃ¡s importantes
coeficientes_seleccionados['importancia'] = coeficientes_seleccionados['coef'].abs()
coeficientes_seleccionados = coeficientes_seleccionados.sort_values(by='importancia', ascending=False).drop('importancia', axis=1)

print(f"\\nğŸ¯ De {len(coeficientes_lasso)} caracterÃ­sticas iniciales, Lasso seleccionÃ³ {len(coeficientes_seleccionados)}.")
print(f"âŒ Lasso eliminÃ³ {lasso_zero} variables al asignarles un coeficiente de cero.")

print("\\nğŸ“‹ Variables mÃ¡s importantes seleccionadas por el modelo:")
display(coeficientes_seleccionados.head(15).round(4))
"""
    
    # --- CELDA 13: VisualizaciÃ³n (Markdown) ---
    cell13_md = """
## Paso 6: VisualizaciÃ³n de los Coeficientes
 
Un grÃ¡fico a menudo cuenta una historia mÃ¡s clara que una tabla. Vamos a visualizar los 20 coeficientes mÃ¡s importantes para entender de un vistazo quÃ© factores tienen el mayor impacto en el ingreso.

### ğŸ“ˆ Lo que vamos a observar:
- **Barras a la derecha (positivas)**: CaracterÃ­sticas que aumentan el ingreso.
- **Barras a la izquierda (negativas)**: CaracterÃ­sticas que disminuyen el ingreso.
- **Longitud de la barra**: La magnitud del impacto.
"""

    # --- CELDA 14: VisualizaciÃ³n (CÃ³digo) ---
    cell14_code = """
# ğŸ¨ Preparando la visualizaciÃ³n de coeficientes...

# Tomamos los 20 coeficientes con mayor valor absoluto y los ordenamos por su valor para el grÃ¡fico
top_coef = coeficientes_seleccionados.head(20).sort_values('coef')

plt.figure(figsize=(14, 10))
sns.barplot(x='coef', y='predictor', data=top_coef, palette='coolwarm')

plt.title('Top 20 Coeficientes del Modelo Lasso', fontsize=18, fontweight='bold', pad=20)
plt.xlabel('Valor del Coeficiente (Impacto en el Log-Ingreso)', fontsize=14)
plt.ylabel('Predictor', fontsize=14)
plt.axvline(x=0, color='black', linewidth=0.8, linestyle='--')
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.show()
"""
    # --- CELDA 15: ConclusiÃ³n (Markdown) ---
    cell15_md = """
## ğŸ“ Resumen y Conclusiones de la Actividad
 
### ğŸ§  Lo que hemos logrado:
1.  **Construimos un Modelo Predictivo**: Creamos un modelo Lasso que puede estimar el ingreso de una persona basÃ¡ndose en sus caracterÃ­sticas, explicando una porciÃ³n significativa de la varianza (`RÂ²`).
2.  **Realizamos SelecciÃ³n de Variables**: De un gran nÃºmero de variables iniciales, Lasso nos ayudÃ³ a identificar un subconjunto mÃ¡s pequeÃ±o y manejable de predictores importantes. Esto es invaluable en ciencias sociales, donde a menudo tenemos "demasiados" datos.
3.  **Obtuvimos Insights Interpretables**: Al analizar los coeficientes, podemos empezar a formular hipÃ³tesis sobre quÃ© factores (como la educaciÃ³n, el tipo de trabajo, o la posesiÃ³n de ciertos bienes) estÃ¡n mÃ¡s fuertemente asociados con mayores o menores ingresos en nuestra poblaciÃ³n de estudio.

### ğŸ’¡ Conceptos clave para recordar:
- **Lasso (L1 Regularization)**: Es una herramienta poderosa para construir modelos *parsimoniosos* (simples) y evitar el sobreajuste.
- **Preprocesamiento**: Es un paso no negociable. La calidad del modelo depende directamente de la calidad de los datos que le damos.
- **InterpretaciÃ³n**: Los modelos no son solo cajas negras. Entender los coeficientes nos permite conectar los resultados matemÃ¡ticos con el conocimiento del dominio.

### ğŸ‰ Â¡Felicidades!
Has completado exitosamente esta actividad. Ahora tienes una comprensiÃ³n sÃ³lida de cÃ³mo aplicar la RegresiÃ³n Lasso a un problema del mundo real, desde la carga de datos hasta la interpretaciÃ³n de resultados.

Â¡Sigue practicando y explorando para afianzar estos conceptos! ğŸš€
"""

    notebook_cells = [
        nbf.v4.new_markdown_cell(cell1_md),
        nbf.v4.new_code_cell(cell2_code),
        nbf.v4.new_markdown_cell(cell3_md),
        nbf.v4.new_code_cell(cell4_code),
        nbf.v4.new_markdown_cell(cell5_md),
        nbf.v4.new_code_cell(cell6_code),
        nbf.v4.new_markdown_cell(cell7_md),
        nbf.v4.new_code_cell(cell8_code),
        nbf.v4.new_markdown_cell(cell9_md),
        nbf.v4.new_code_cell(cell10_code),
        nbf.v4.new_markdown_cell(cell11_md),
        nbf.v4.new_code_cell(cell12_code),
        nbf.v4.new_markdown_cell(cell13_md),
        nbf.v4.new_code_cell(cell14_code),
        nbf.v4.new_markdown_cell(cell15_md)
    ]

    nb['cells'] = notebook_cells
    notebook_filename = "Modelo_Lasso_Prediccion_Ingreso.ipynb"
    with open(notebook_filename, 'w', encoding='utf-8') as f:
        nbf.write(nb, f)

    print(f"\nNotebook '{notebook_filename}' creado exitosamente con el formato corregido.")

if __name__ == "__main__":
    generar_notebook_modelo_formato_corregido()