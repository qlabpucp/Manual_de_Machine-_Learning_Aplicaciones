{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c9ebc47",
   "metadata": {},
   "source": [
    "# Actividad: Lasso vs. Ridge - ComparaciÃ³n de Modelos de RegularizaciÃ³n\n",
    "\n",
    "## ğŸ¯ Objetivo de la Actividad\n",
    "En esta actividad prÃ¡ctica, aprenderemos a comparar dos tÃ©cnicas fundamentales de regularizaciÃ³n en Machine Learning: **Ridge Regression** y **Lasso Regression**. \n",
    "\n",
    "### Â¿QuÃ© es la RegularizaciÃ³n?\n",
    "La regularizaciÃ³n es una tÃ©cnica que ayuda a prevenir el **overfitting** (sobreajuste) en nuestros modelos. Cuando un modelo se sobreajusta, memoriza los datos de entrenamiento pero no generaliza bien a nuevos datos.\n",
    "\n",
    "### Â¿Por quÃ© comparar Ridge vs Lasso?\n",
    "- **Ridge (L2)**: Reduce los coeficientes pero nunca los hace exactamente cero\n",
    "- **Lasso (L1)**: Puede hacer que algunos coeficientes sean exactamente cero, eliminando variables\n",
    "\n",
    "### ğŸ“‹ HipÃ³tesis que vamos a probar:\n",
    "1. **Lasso** tendrÃ¡ un error de predicciÃ³n similar o mejor que Ridge\n",
    "2. **Lasso** producirÃ¡ un modelo mÃ¡s interpretable al reducir a cero los coeficientes de variables irrelevantes\n",
    "3. **Ridge** mantendrÃ¡ todos los coeficientes pero con valores pequeÃ±os\n",
    "\n",
    "### ğŸ§  Conceptos Clave que Aprenderemos:\n",
    "- **PenalizaciÃ³n L1 vs L2**: Diferentes formas de regularizar\n",
    "- **SelecciÃ³n de Variables**: CÃ³mo Lasso puede eliminar automÃ¡ticamente variables irrelevantes\n",
    "- **Trade-off**: Interpretabilidad vs Rendimiento predictivo\n",
    "- **ValidaciÃ³n Cruzada**: Para encontrar el mejor parÃ¡metro de regularizaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š Importar librerÃ­as necesarias\n",
    "# NumPy: Para operaciones matemÃ¡ticas y arrays\n",
    "import numpy as np\n",
    "\n",
    "# Pandas: Para manipulaciÃ³n y anÃ¡lisis de datos\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib y Seaborn: Para visualizaciones\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn: LibrerÃ­a principal de Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ConfiguraciÃ³n para evitar warnings innecesarios\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ğŸ¨ Configurar estilo de grÃ¡ficos para que se vean mÃ¡s bonitos\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")\n",
    "print(\"ğŸ“Š ConfiguraciÃ³n de grÃ¡ficos lista\")\n",
    "print(\"ğŸš€ Â¡Listos para comenzar la actividad!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba822142",
   "metadata": {},
   "source": [
    "## ğŸ“Š Paso 1: GeneraciÃ³n de Datos Simulados\n",
    "\n",
    "### Â¿Por quÃ© usar datos simulados?\n",
    "Para entender mejor cÃ³mo funcionan Ridge y Lasso, vamos a crear datos donde **sabemos exactamente** quÃ© variables son importantes y cuÃ¡les no. Esto nos permitirÃ¡ evaluar si nuestros modelos pueden identificar correctamente las variables relevantes.\n",
    "\n",
    "### ğŸ¯ Estructura de nuestros datos:\n",
    "- **10 variables relevantes**: Que realmente afectan el ingreso anual\n",
    "- **20 variables irrelevantes**: Que no tienen relaciÃ³n con el ingreso\n",
    "- **1000 observaciones**: Para tener suficientes datos\n",
    "- **Ruido**: Para simular condiciones reales (nada es perfecto en la vida real)\n",
    "\n",
    "### ğŸ§  Concepto importante: Coeficientes Verdaderos\n",
    "En la vida real, nunca sabemos los \"coeficientes verdaderos\", pero aquÃ­ los definimos para poder evaluar quÃ© tan bien funcionan nuestros modelos.\n",
    "\n",
    "### ğŸ“ˆ Variables que simularemos:\n",
    "1. **EducaciÃ³n** (coef = 5000): AÃ±os de estudio\n",
    "2. **Experiencia laboral** (coef = 3000): AÃ±os trabajando\n",
    "3. **Edad** (coef = 2000): Edad del trabajador\n",
    "4. **Horas trabajadas** (coef = 1500): Horas semanales\n",
    "5. **Sector econÃ³mico** (coef = 1000): Tipo de industria\n",
    "6. **TamaÃ±o de empresa** (coef = 800): NÃºmero de empleados\n",
    "7. **Nivel de responsabilidad** (coef = 600): Cargo en la empresa\n",
    "8. **UbicaciÃ³n geogrÃ¡fica** (coef = 400): Ciudad/regiÃ³n\n",
    "9. **Certificaciones** (coef = 300): Certificaciones profesionales\n",
    "10. **Idiomas** (coef = 200): NÃºmero de idiomas hablados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08be9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ Configurar semilla para reproducibilidad\n",
    "# Esto asegura que obtengamos los mismos resultados cada vez que ejecutemos el cÃ³digo\n",
    "np.random.seed(42)\n",
    "\n",
    "# ğŸ“Š ParÃ¡metros de la simulaciÃ³n\n",
    "n_samples = 1000                    # NÃºmero de personas en nuestro dataset\n",
    "n_relevant_features = 10            # Variables que realmente afectan el ingreso\n",
    "n_irrelevant_features = 20          # Variables que NO afectan el ingreso\n",
    "n_total_features = n_relevant_features + n_irrelevant_features\n",
    "\n",
    "print(f\"ğŸ¯ Creando dataset con {n_samples} personas y {n_total_features} variables\")\n",
    "print(f\"ğŸ“ˆ Variables relevantes: {n_relevant_features}\")\n",
    "print(f\"âŒ Variables irrelevantes: {n_irrelevant_features}\")\n",
    "\n",
    "# ğŸ² Generar variables explicativas (caracterÃ­sticas de cada persona)\n",
    "# randn genera nÃºmeros aleatorios con distribuciÃ³n normal\n",
    "X = np.random.randn(n_samples, n_total_features)\n",
    "\n",
    "# ğŸ¯ Definir coeficientes reales (solo las primeras 10 variables son relevantes)\n",
    "true_coefficients = np.zeros(n_total_features)  # Inicializar todos en cero\n",
    "true_coefficients[:n_relevant_features] = np.array([\n",
    "    5000,  # EducaciÃ³n: Cada aÃ±o adicional suma $5000 al ingreso\n",
    "    3000,  # Experiencia laboral: Cada aÃ±o de experiencia suma $3000\n",
    "    2000,  # Edad: La edad tiene un efecto moderado\n",
    "    1500,  # Horas trabajadas: MÃ¡s horas = mÃ¡s ingreso\n",
    "    1000,  # Sector econÃ³mico: Algunos sectores pagan mejor\n",
    "    800,   # TamaÃ±o de empresa: Empresas grandes suelen pagar mÃ¡s\n",
    "    600,   # Nivel de responsabilidad: MÃ¡s responsabilidad = mÃ¡s pago\n",
    "    400,   # UbicaciÃ³n geogrÃ¡fica: Algunas ciudades pagan mejor\n",
    "    300,   # Certificaciones: Certificaciones profesionales aumentan el ingreso\n",
    "    200    # Idiomas: Cada idioma adicional suma un poco\n",
    "])\n",
    "\n",
    "print(\"\\nğŸ’° Coeficientes verdaderos (solo las primeras 10 variables son relevantes):\")\n",
    "for i, coef in enumerate(true_coefficients[:n_relevant_features]):\n",
    "    print(f\"   Variable {i+1}: ${coef:.0f}\")\n",
    "\n",
    "# ğŸ¯ Generar variable objetivo (ingreso anual) con ruido\n",
    "# La fÃ³rmula es: ingreso = X1*coef1 + X2*coef2 + ... + ruido\n",
    "y = X @ true_coefficients + np.random.normal(0, 1000, n_samples)\n",
    "\n",
    "# ğŸ“ Crear nombres de variables para mejor interpretaciÃ³n\n",
    "feature_names = []\n",
    "for i in range(n_relevant_features):\n",
    "    feature_names.append(f'Variable_Relevante_{i+1}')\n",
    "for i in range(n_irrelevant_features):\n",
    "    feature_names.append(f'Variable_Irrelevante_{i+1}')\n",
    "\n",
    "# ğŸ“Š Crear DataFrame con pandas\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['ingreso_anual'] = y\n",
    "\n",
    "# ğŸ“ˆ Mostrar resumen del dataset\n",
    "print(f\"\\nâœ… Dataset creado exitosamente!\")\n",
    "print(f\"ğŸ“Š Observaciones: {n_samples}\")\n",
    "print(f\"ğŸ“ˆ Variables totales: {n_total_features}\")\n",
    "print(f\"ğŸ’° Rango de ingresos: ${y.min():.0f} - ${y.max():.0f}\")\n",
    "print(f\"ğŸ’° Ingreso promedio: ${y.mean():.0f}\")\n",
    "print(f\"ğŸ’° DesviaciÃ³n estÃ¡ndar: ${y.std():.0f}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ Primeras 5 filas del dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nğŸ” InformaciÃ³n del dataset:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc6ebb3",
   "metadata": {},
   "source": [
    "## ğŸ”§ Paso 2: PreparaciÃ³n de los Datos\n",
    "\n",
    "### Â¿Por quÃ© necesitamos preparar los datos?\n",
    "\n",
    "Antes de entrenar nuestros modelos, necesitamos hacer algunos ajustes importantes:\n",
    "\n",
    "1. **Separar variables explicativas y objetivo**: Distinguir entre lo que queremos predecir y lo que usamos para predecir\n",
    "2. **Dividir en entrenamiento y prueba**: Para evaluar quÃ© tan bien generaliza nuestro modelo\n",
    "3. **Estandarizar las variables**: Para que todas las variables tengan la misma escala\n",
    "\n",
    "### ğŸ§  Conceptos importantes:\n",
    "\n",
    "**Train-Test Split**: Dividimos nuestros datos en dos partes:\n",
    "- **Datos de entrenamiento** (70%): Para enseÃ±ar al modelo\n",
    "- **Datos de prueba** (30%): Para evaluar quÃ© tan bien funciona\n",
    "\n",
    "**EstandarizaciÃ³n**: Convertimos todas las variables a la misma escala (media=0, desviaciÃ³n=1). Esto es importante porque:\n",
    "- Ridge y Lasso son sensibles a la escala de las variables\n",
    "- Variables con valores grandes pueden dominar el modelo\n",
    "- La estandarizaciÃ³n hace que todas las variables tengan igual importancia inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Separar variables explicativas (X) y variable objetivo (y)\n",
    "print(\"ğŸ” Separando variables explicativas y objetivo...\")\n",
    "X = df.drop('ingreso_anual', axis=1)  # Todas las variables excepto el ingreso\n",
    "y = df['ingreso_anual']               # Solo el ingreso (lo que queremos predecir)\n",
    "\n",
    "print(f\"ğŸ“ˆ Variables explicativas (X): {X.shape[1]} variables\")\n",
    "print(f\"ğŸ¯ Variable objetivo (y): 1 variable (ingreso anual)\")\n",
    "print(f\"ğŸ“Š Total de observaciones: {X.shape[0]}\")\n",
    "\n",
    "# ğŸ”„ Dividir en conjuntos de entrenamiento y prueba\n",
    "print(\"\\nğŸ”„ Dividiendo datos en entrenamiento (70%) y prueba (30%)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42  # 30% para prueba, semilla para reproducibilidad\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“š Datos de entrenamiento: {X_train.shape[0]} observaciones\")\n",
    "print(f\"ğŸ§ª Datos de prueba: {X_test.shape[0]} observaciones\")\n",
    "print(f\"ğŸ“ˆ Variables en cada conjunto: {X_train.shape[1]}\")\n",
    "\n",
    "# âš–ï¸ Estandarizar las variables (muy importante para Ridge y Lasso)\n",
    "print(\"\\nâš–ï¸ Estandarizando variables...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Ajustar y transformar datos de entrenamiento\n",
    "X_test_scaled = scaler.transform(X_test)        # Solo transformar datos de prueba\n",
    "\n",
    "print(\"âœ… EstandarizaciÃ³n completada!\")\n",
    "print(\"ğŸ“Š Ahora todas las variables tienen media=0 y desviaciÃ³n=1\")\n",
    "\n",
    "# ğŸ” Verificar la estandarizaciÃ³n\n",
    "print(\"\\nğŸ” Verificando la estandarizaciÃ³n:\")\n",
    "print(f\"Media de variables estandarizadas: {X_train_scaled.mean():.6f} (deberÃ­a ser ~0)\")\n",
    "print(f\"DesviaciÃ³n de variables estandarizadas: {X_train_scaled.std():.6f} (deberÃ­a ser ~1)\")\n",
    "\n",
    "print(\"\\nâœ… Â¡Datos preparados y listos para entrenar modelos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d9103",
   "metadata": {},
   "source": [
    "## ğŸ”ï¸ Paso 3: Entrenamiento del Modelo Ridge\n",
    "\n",
    "### Â¿QuÃ© es Ridge Regression?\n",
    "\n",
    "**Ridge Regression** es una tÃ©cnica de regularizaciÃ³n que usa **penalizaciÃ³n L2**. Su objetivo es reducir el overfitting agregando una penalizaciÃ³n a los coeficientes grandes.\n",
    "\n",
    "### ğŸ§  Concepto clave: PenalizaciÃ³n L2\n",
    "\n",
    "La funciÃ³n objetivo de Ridge es:\n",
    "```\n",
    "Error = Error de predicciÃ³n + Î± Ã— (Î²â‚Â² + Î²â‚‚Â² + ... + Î²â‚šÂ²)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "- **Î± (alpha)**: ParÃ¡metro de regularizaciÃ³n (controla la fuerza de la penalizaciÃ³n)\n",
    "- **Î²áµ¢Â²**: Cuadrado de cada coeficiente\n",
    "\n",
    "### ğŸ” Â¿CÃ³mo funciona Ridge?\n",
    "\n",
    "1. **Reduce coeficientes**: Hace que los coeficientes sean mÃ¡s pequeÃ±os\n",
    "2. **Nunca los hace cero**: Los coeficientes se acercan a cero pero nunca llegan exactamente a cero\n",
    "3. **Mantiene todas las variables**: Todas las variables siguen en el modelo\n",
    "\n",
    "### ğŸ¯ Â¿CuÃ¡ndo usar Ridge?\n",
    "\n",
    "- Cuando todas las variables podrÃ­an ser relevantes\n",
    "- Cuando quieres evitar eliminar variables potencialmente Ãºtiles\n",
    "- Cuando el rendimiento predictivo es la prioridad\n",
    "\n",
    "### ğŸ“Š Proceso que vamos a seguir:\n",
    "\n",
    "1. **Probar diferentes valores de alpha**: Para encontrar el mejor parÃ¡metro\n",
    "2. **Usar validaciÃ³n cruzada**: Para evaluar cada valor de alpha\n",
    "3. **Entrenar el modelo final**: Con el mejor alpha encontrado\n",
    "4. **Evaluar el rendimiento**: En datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Definir valores de alpha para Ridge\n",
    "print(\"ğŸ” Buscando el mejor parÃ¡metro alpha para Ridge...\")\n",
    "print(\"ğŸ“Š Probando valores desde 0.001 hasta 1000...\")\n",
    "\n",
    "# Usar logspace para probar valores en escala logarÃ­tmica\n",
    "alpha_values = np.logspace(-3, 3, 50)  # 50 valores entre 10^-3 y 10^3\n",
    "print(f\"ğŸ¯ Probando {len(alpha_values)} valores diferentes de alpha\")\n",
    "\n",
    "# ğŸ”„ Entrenar Ridge con validaciÃ³n cruzada para cada alpha\n",
    "print(\"\\nğŸ”„ Entrenando modelos Ridge con validaciÃ³n cruzada...\")\n",
    "ridge_scores = []\n",
    "\n",
    "for i, alpha in enumerate(alpha_values):\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    # Usar validaciÃ³n cruzada con 5 folds\n",
    "    scores = cross_val_score(ridge, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    ridge_scores.append(-np.mean(scores))  # Convertir a error positivo\n",
    "    \n",
    "    # Mostrar progreso cada 10 iteraciones\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"   Progreso: {i+1}/{len(alpha_values)} alphas probados\")\n",
    "\n",
    "# ğŸ† Encontrar el mejor alpha\n",
    "best_alpha_ridge = alpha_values[np.argmin(ridge_scores)]\n",
    "best_score_ridge = min(ridge_scores)\n",
    "\n",
    "print(f\"\\nğŸ† Mejor alpha encontrado: {best_alpha_ridge:.4f}\")\n",
    "print(f\"ğŸ“Š Mejor error MSE: {best_score_ridge:.2f}\")\n",
    "\n",
    "# ğŸš€ Entrenar modelo Ridge final con el mejor alpha\n",
    "print(\"\\nğŸš€ Entrenando modelo Ridge final con el mejor alpha...\")\n",
    "ridge_model = Ridge(alpha=best_alpha_ridge)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ğŸ“ˆ Hacer predicciones en datos de prueba\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# ğŸ“Š Calcular mÃ©tricas de rendimiento\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(\"\\nğŸ“Š RESULTADOS DEL MODELO RIDGE:\")\n",
    "print(f\"ğŸ¯ Mejor alpha: {best_alpha_ridge:.4f}\")\n",
    "print(f\"ğŸ’° RMSE (Error de predicciÃ³n): ${rmse_ridge:.2f}\")\n",
    "print(f\"ğŸ“ˆ RÂ² (Coeficiente de determinaciÃ³n): {r2_ridge:.4f}\")\n",
    "\n",
    "# ğŸ” Analizar coeficientes\n",
    "ridge_non_zero = np.sum(ridge_model.coef_ != 0)\n",
    "print(f\"ğŸ“Š Coeficientes no cero: {ridge_non_zero}/{len(ridge_model.coef_)}\")\n",
    "print(f\"ğŸ“Š Porcentaje de variables usadas: {ridge_non_zero/len(ridge_model.coef_)*100:.1f}%\")\n",
    "\n",
    "# ğŸ“Š Mostrar algunos coeficientes como ejemplo\n",
    "print(\"\\nğŸ” Ejemplos de coeficientes Ridge:\")\n",
    "coef_ridge_df = pd.DataFrame({\n",
    "    'Variable': feature_names,\n",
    "    'Coeficiente': ridge_model.coef_\n",
    "})\n",
    "print(coef_ridge_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06461ea6",
   "metadata": {},
   "source": [
    "## ğŸ¯ Paso 4: Entrenamiento del Modelo Lasso\n",
    "\n",
    "### Â¿QuÃ© es Lasso Regression?\n",
    "\n",
    "**Lasso Regression** es una tÃ©cnica de regularizaciÃ³n que usa **penalizaciÃ³n L1**. Su objetivo es reducir el overfitting y realizar **selecciÃ³n automÃ¡tica de variables**.\n",
    "\n",
    "### ğŸ§  Concepto clave: PenalizaciÃ³n L1\n",
    "\n",
    "La funciÃ³n objetivo de Lasso es:\n",
    "```\n",
    "Error = Error de predicciÃ³n + Î± Ã— (|Î²â‚| + |Î²â‚‚| + ... + |Î²â‚š|)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "- **Î± (alpha)**: ParÃ¡metro de regularizaciÃ³n (controla la fuerza de la penalizaciÃ³n)\n",
    "- **|Î²áµ¢|**: Valor absoluto de cada coeficiente\n",
    "\n",
    "### ğŸ” Â¿CÃ³mo funciona Lasso?\n",
    "\n",
    "1. **Reduce coeficientes**: Hace que los coeficientes sean mÃ¡s pequeÃ±os\n",
    "2. **Puede hacerlos cero**: Los coeficientes pueden llegar exactamente a cero\n",
    "3. **SelecciÃ³n de variables**: Elimina automÃ¡ticamente variables irrelevantes\n",
    "\n",
    "### ğŸ¯ Â¿CuÃ¡ndo usar Lasso?\n",
    "\n",
    "- Cuando tienes muchas variables y quieres identificar las mÃ¡s importantes\n",
    "- Cuando la interpretabilidad es crucial\n",
    "- Cuando quieres un modelo mÃ¡s simple y fÃ¡cil de explicar\n",
    "- Cuando sospechas que muchas variables son irrelevantes\n",
    "\n",
    "### ğŸ†š Diferencias clave con Ridge:\n",
    "\n",
    "| Aspecto | Ridge (L2) | Lasso (L1) |\n",
    "|---------|------------|------------|\n",
    "| PenalizaciÃ³n | Î²áµ¢Â² (cuadrado) | \\|Î²áµ¢\\| (valor absoluto) |\n",
    "| Coeficientes cero | Nunca | Pueden ser cero |\n",
    "| SelecciÃ³n de variables | No | SÃ­ |\n",
    "| Interpretabilidad | Baja | Alta |\n",
    "\n",
    "### ğŸ“Š Proceso que vamos a seguir:\n",
    "\n",
    "1. **Probar diferentes valores de alpha**: Para encontrar el mejor parÃ¡metro\n",
    "2. **Usar validaciÃ³n cruzada**: Para evaluar cada valor de alpha\n",
    "3. **Entrenar el modelo final**: Con el mejor alpha encontrado\n",
    "4. **Evaluar el rendimiento**: En datos de prueba\n",
    "5. **Analizar selecciÃ³n de variables**: Ver quÃ© variables fueron eliminadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Definir valores de alpha para Lasso\n",
    "print(\"ğŸ” Buscando el mejor parÃ¡metro alpha para Lasso...\")\n",
    "print(\"ğŸ“Š Probando valores desde 0.001 hasta 10...\")\n",
    "\n",
    "# Usar logspace para probar valores en escala logarÃ­tmica\n",
    "alpha_values_lasso = np.logspace(-3, 1, 50)  # 50 valores entre 10^-3 y 10^1\n",
    "print(f\"ğŸ¯ Probando {len(alpha_values_lasso)} valores diferentes de alpha\")\n",
    "\n",
    "# ğŸ”„ Entrenar Lasso con validaciÃ³n cruzada para cada alpha\n",
    "print(\"\\nğŸ”„ Entrenando modelos Lasso con validaciÃ³n cruzada...\")\n",
    "lasso_scores = []\n",
    "\n",
    "for i, alpha in enumerate(alpha_values_lasso):\n",
    "    lasso = Lasso(alpha=alpha, max_iter=2000)  # MÃ¡s iteraciones para convergencia\n",
    "    # Usar validaciÃ³n cruzada con 5 folds\n",
    "    scores = cross_val_score(lasso, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    lasso_scores.append(-np.mean(scores))  # Convertir a error positivo\n",
    "    \n",
    "    # Mostrar progreso cada 10 iteraciones\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"   Progreso: {i+1}/{len(alpha_values_lasso)} alphas probados\")\n",
    "\n",
    "# ğŸ† Encontrar el mejor alpha\n",
    "best_alpha_lasso = alpha_values_lasso[np.argmin(lasso_scores)]\n",
    "best_score_lasso = min(lasso_scores)\n",
    "\n",
    "print(f\"\\nğŸ† Mejor alpha encontrado: {best_alpha_lasso:.4f}\")\n",
    "print(f\"ğŸ“Š Mejor error MSE: {best_score_lasso:.2f}\")\n",
    "\n",
    "# ğŸš€ Entrenar modelo Lasso final con el mejor alpha\n",
    "print(\"\\nğŸš€ Entrenando modelo Lasso final con el mejor alpha...\")\n",
    "lasso_model = Lasso(alpha=best_alpha_lasso, max_iter=2000)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ğŸ“ˆ Hacer predicciones en datos de prueba\n",
    "y_pred_lasso = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "# ğŸ“Š Calcular mÃ©tricas de rendimiento\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(\"\\nğŸ“Š RESULTADOS DEL MODELO LASSO:\")\n",
    "print(f\"ğŸ¯ Mejor alpha: {best_alpha_lasso:.4f}\")\n",
    "print(f\"ğŸ’° RMSE (Error de predicciÃ³n): ${rmse_lasso:.2f}\")\n",
    "print(f\"ğŸ“ˆ RÂ² (Coeficiente de determinaciÃ³n): {r2_lasso:.4f}\")\n",
    "\n",
    "# ğŸ” Analizar coeficientes y selecciÃ³n de variables\n",
    "lasso_non_zero = np.sum(lasso_model.coef_ != 0)\n",
    "lasso_zero = np.sum(lasso_model.coef_ == 0)\n",
    "\n",
    "print(f\"ğŸ“Š Coeficientes no cero: {lasso_non_zero}/{len(lasso_model.coef_)}\")\n",
    "print(f\"ğŸ“Š Coeficientes cero (variables eliminadas): {lasso_zero}/{len(lasso_model.coef_)}\")\n",
    "print(f\"ğŸ“Š Porcentaje de variables usadas: {lasso_non_zero/len(lasso_model.coef_)*100:.1f}%\")\n",
    "print(f\"ğŸ“Š Porcentaje de variables eliminadas: {lasso_zero/len(lasso_model.coef_)*100:.1f}%\")\n",
    "\n",
    "# ğŸ“Š Mostrar variables seleccionadas y eliminadas\n",
    "print(\"\\nğŸ” Variables seleccionadas por Lasso (coeficiente â‰  0):\")\n",
    "lasso_selected_vars = []\n",
    "lasso_eliminated_vars = []\n",
    "\n",
    "for i, (var, coef) in enumerate(zip(feature_names, lasso_model.coef_)):\n",
    "    if coef != 0:\n",
    "        lasso_selected_vars.append((var, coef))\n",
    "    else:\n",
    "        lasso_eliminated_vars.append(var)\n",
    "\n",
    "print(f\"âœ… Variables seleccionadas ({len(lasso_selected_vars)}):\")\n",
    "for var, coef in lasso_selected_vars[:10]:  # Mostrar solo las primeras 10\n",
    "    print(f\"   {var}: {coef:.4f}\")\n",
    "\n",
    "if len(lasso_eliminated_vars) > 0:\n",
    "    print(f\"\\nâŒ Variables eliminadas ({len(lasso_eliminated_vars)}):\")\n",
    "    for var in lasso_eliminated_vars[:10]:  # Mostrar solo las primeras 10\n",
    "        print(f\"   {var}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Â¡Lasso eliminÃ³ {len(lasso_eliminated_vars)} variables irrelevantes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756d8fc",
   "metadata": {},
   "source": [
    "## ğŸ“Š Paso 5: ComparaciÃ³n Visual de Coeficientes\n",
    "\n",
    "### Â¿Por quÃ© visualizar los coeficientes?\n",
    "\n",
    "La visualizaciÃ³n nos ayuda a entender mejor cÃ³mo funcionan Ridge y Lasso:\n",
    "\n",
    "1. **Ridge**: Todos los coeficientes son pequeÃ±os pero no cero\n",
    "2. **Lasso**: Algunos coeficientes son exactamente cero (variables eliminadas)\n",
    "\n",
    "### ğŸ§  Conceptos clave de la visualizaciÃ³n:\n",
    "\n",
    "- **Altura de las barras**: Magnitud del coeficiente\n",
    "- **Barras en cero**: Variables eliminadas por Lasso\n",
    "- **PatrÃ³n de distribuciÃ³n**: CÃ³mo se distribuyen los coeficientes\n",
    "\n",
    "### ğŸ“ˆ Lo que vamos a observar:\n",
    "\n",
    "1. **Diferencias en magnitud**: Ridge vs Lasso\n",
    "2. **SelecciÃ³n de variables**: Variables eliminadas por Lasso\n",
    "3. **Interpretabilidad**: CuÃ¡l modelo es mÃ¡s fÃ¡cil de interpretar\n",
    "\n",
    "### ğŸ¯ Preguntas que responderemos:\n",
    "\n",
    "- Â¿CuÃ¡ntas variables eliminÃ³ Lasso?\n",
    "- Â¿QuÃ© variables considera mÃ¡s importantes cada modelo?\n",
    "- Â¿CuÃ¡l modelo es mÃ¡s interpretable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Crear figura con subplots para comparar Ridge vs Lasso\n",
    "print(\"ğŸ¨ Creando visualizaciÃ³n comparativa de coeficientes...\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 14))\n",
    "\n",
    "# ğŸ”ï¸ GrÃ¡fico de coeficientes Ridge\n",
    "print(\"ğŸ“ˆ Preparando grÃ¡fico de coeficientes Ridge...\")\n",
    "coef_ridge = pd.Series(ridge_model.coef_, index=feature_names)\n",
    "coef_ridge_sorted = coef_ridge.sort_values(key=abs, ascending=False)\n",
    "\n",
    "# Crear barras con colores diferentes para variables relevantes vs irrelevantes\n",
    "colors_ridge = ['red' if i < n_relevant_features else 'gray' for i in range(len(coef_ridge_sorted))]\n",
    "coef_ridge_sorted.plot(kind='bar', ax=ax1, color=colors_ridge, alpha=0.7)\n",
    "\n",
    "ax1.set_title('Coeficientes del Modelo Ridge (L2)', fontsize=16, fontweight='bold', pad=20)\n",
    "ax1.set_ylabel('Valor del Coeficiente', fontsize=12)\n",
    "ax1.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Agregar leyenda\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements_ridge = [\n",
    "    Patch(facecolor='red', alpha=0.7, label='Variables Relevantes'),\n",
    "    Patch(facecolor='gray', alpha=0.7, label='Variables Irrelevantes')\n",
    "]\n",
    "ax1.legend(handles=legend_elements_ridge, loc='upper right')\n",
    "\n",
    "# ğŸ¯ GrÃ¡fico de coeficientes Lasso\n",
    "print(\"ğŸ“ˆ Preparando grÃ¡fico de coeficientes Lasso...\")\n",
    "coef_lasso = pd.Series(lasso_model.coef_, index=feature_names)\n",
    "coef_lasso_sorted = coef_lasso.sort_values(key=abs, ascending=False)\n",
    "\n",
    "# Crear barras con colores diferentes\n",
    "colors_lasso = ['red' if i < n_relevant_features else 'gray' for i in range(len(coef_lasso_sorted))]\n",
    "coef_lasso_sorted.plot(kind='bar', ax=ax2, color=colors_lasso, alpha=0.7)\n",
    "\n",
    "ax2.set_title('Coeficientes del Modelo Lasso (L1)', fontsize=16, fontweight='bold', pad=20)\n",
    "ax2.set_ylabel('Valor del Coeficiente', fontsize=12)\n",
    "ax2.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Agregar leyenda\n",
    "legend_elements_lasso = [\n",
    "    Patch(facecolor='red', alpha=0.7, label='Variables Relevantes'),\n",
    "    Patch(facecolor='gray', alpha=0.7, label='Variables Irrelevantes')\n",
    "]\n",
    "ax2.legend(handles=legend_elements_lasso, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ğŸ“Š AnÃ¡lisis detallado de los resultados\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š ANÃLISIS COMPARATIVO DE COEFICIENTES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ğŸ”ï¸ AnÃ¡lisis Ridge\n",
    "print(\"\\nğŸ”ï¸ ANÃLISIS RIDGE:\")\n",
    "print(f\"ğŸ“Š Total de variables: {len(coef_ridge)}\")\n",
    "print(f\"ğŸ“Š Variables con coeficiente > 0.1: {np.sum(np.abs(coef_ridge) > 0.1)}\")\n",
    "print(f\"ğŸ“Š Variables con coeficiente > 1.0: {np.sum(np.abs(coef_ridge) > 1.0)}\")\n",
    "print(f\"ğŸ“Š Rango de coeficientes: {coef_ridge.min():.4f} a {coef_ridge.max():.4f}\")\n",
    "\n",
    "# ğŸ¯ AnÃ¡lisis Lasso\n",
    "print(\"\\nğŸ¯ ANÃLISIS LASSO:\")\n",
    "print(f\"ğŸ“Š Total de variables: {len(coef_lasso)}\")\n",
    "print(f\"ğŸ“Š Variables seleccionadas (â‰  0): {np.sum(coef_lasso != 0)}\")\n",
    "print(f\"ğŸ“Š Variables eliminadas (= 0): {np.sum(coef_lasso == 0)}\")\n",
    "print(f\"ğŸ“Š Rango de coeficientes: {coef_lasso.min():.4f} a {coef_lasso.max():.4f}\")\n",
    "\n",
    "# ğŸ† ComparaciÃ³n\n",
    "print(\"\\nğŸ† COMPARACIÃ“N:\")\n",
    "print(f\"ğŸ“Š Variables usadas por Ridge: {len(coef_ridge)} (100%)\")\n",
    "print(f\"ğŸ“Š Variables usadas por Lasso: {np.sum(coef_lasso != 0)} ({np.sum(coef_lasso != 0)/len(coef_lasso)*100:.1f}%)\")\n",
    "print(f\"ğŸ“Š ReducciÃ³n de variables por Lasso: {len(coef_lasso) - np.sum(coef_lasso != 0)} variables\")\n",
    "\n",
    "# ğŸ“‹ Mostrar las variables mÃ¡s importantes segÃºn cada modelo\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“‹ TOP 10 VARIABLES MÃS IMPORTANTES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ”ï¸ Ridge (por valor absoluto):\")\n",
    "for i, (var, coef) in enumerate(coef_ridge_sorted.head(10).items()):\n",
    "    relevante = \"âœ…\" if i < n_relevant_features else \"âŒ\"\n",
    "    print(f\"{i+1:2d}. {var}: {coef:.4f} {relevante}\")\n",
    "\n",
    "print(\"\\nğŸ¯ Lasso (variables seleccionadas):\")\n",
    "lasso_selected = coef_lasso[coef_lasso != 0].sort_values(key=abs, ascending=False)\n",
    "for i, (var, coef) in enumerate(lasso_selected.items()):\n",
    "    relevante = \"âœ…\" if var in feature_names[:n_relevant_features] else \"âŒ\"\n",
    "    print(f\"{i+1:2d}. {var}: {coef:.4f} {relevante}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Resumen:\")\n",
    "print(f\"âœ… Ridge identificÃ³ {np.sum(np.abs(coef_ridge_sorted.head(10).index.isin(feature_names[:n_relevant_features])))} variables relevantes en su top 10\")\n",
    "print(f\"âœ… Lasso identificÃ³ {np.sum(lasso_selected.head(10).index.isin(feature_names[:n_relevant_features])))} variables relevantes en su top 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a07db3",
   "metadata": {},
   "source": [
    "## ğŸ“Š Paso 6: Tabla de Resultados Comparativos\n",
    "\n",
    "### Â¿Por quÃ© crear una tabla comparativa?\n",
    "\n",
    "Una tabla nos permite ver de manera clara y organizada las diferencias entre Ridge y Lasso en tÃ©rminos de:\n",
    "\n",
    "1. **Rendimiento predictivo**: Â¿CuÃ¡l modelo predice mejor?\n",
    "2. **Interpretabilidad**: Â¿CuÃ¡l modelo es mÃ¡s fÃ¡cil de entender?\n",
    "3. **SelecciÃ³n de variables**: Â¿CuÃ¡l modelo identifica mejor las variables importantes?\n",
    "\n",
    "### ğŸ§  MÃ©tricas que vamos a comparar:\n",
    "\n",
    "- **RMSE**: Error de predicciÃ³n (menor es mejor)\n",
    "- **RÂ²**: Coeficiente de determinaciÃ³n (mÃ¡s cercano a 1 es mejor)\n",
    "- **NÃºmero de variables**: CuÃ¡ntas variables usa cada modelo\n",
    "- **Capacidad de selecciÃ³n**: QuÃ© tan bien identifica variables relevantes\n",
    "\n",
    "### ğŸ¯ Preguntas que responderemos:\n",
    "\n",
    "- Â¿CuÃ¡l modelo tiene mejor rendimiento predictivo?\n",
    "- Â¿CuÃ¡l modelo es mÃ¡s interpretable?\n",
    "- Â¿CuÃ¡l modelo identifica mejor las variables relevantes?\n",
    "- Â¿CuÃ¡l modelo elimina mejor las variables irrelevantes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fcb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Crear tabla de resultados comparativos\n",
    "print(\"ğŸ“‹ Creando tabla comparativa de resultados...\")\n",
    "\n",
    "# Calcular mÃ©tricas adicionales para el anÃ¡lisis\n",
    "ridge_relevant_identified = np.sum(ridge_model.coef_[:n_relevant_features] != 0)\n",
    "ridge_irrelevant_eliminated = np.sum(ridge_model.coef_[n_relevant_features:] == 0)\n",
    "lasso_relevant_identified = np.sum(lasso_model.coef_[:n_relevant_features] != 0)\n",
    "lasso_irrelevant_eliminated = np.sum(lasso_model.coef_[n_relevant_features:] == 0)\n",
    "\n",
    "# Calcular porcentajes\n",
    "ridge_relevant_pct = ridge_relevant_identified / n_relevant_features * 100\n",
    "ridge_irrelevant_pct = ridge_irrelevant_eliminated / n_irrelevant_features * 100\n",
    "lasso_relevant_pct = lasso_relevant_identified / n_relevant_features * 100\n",
    "lasso_irrelevant_pct = lasso_irrelevant_eliminated / n_irrelevant_features * 100\n",
    "\n",
    "# Crear tabla de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    'MÃ©trica': [\n",
    "        'ğŸ’° RMSE (Error de PredicciÃ³n)', \n",
    "        'ğŸ“ˆ RÂ² (Coeficiente de DeterminaciÃ³n)',\n",
    "        'ğŸ“Š NÃºmero de Variables Usadas',\n",
    "        'âœ… Variables Relevantes Identificadas',\n",
    "        'âŒ Variables Irrelevantes Eliminadas',\n",
    "        'ğŸ¯ PrecisiÃ³n en SelecciÃ³n (%)',\n",
    "        'ğŸ¯ Especificidad (%)'\n",
    "    ],\n",
    "    'Ridge': [\n",
    "        f\"${rmse_ridge:.2f}\", \n",
    "        f\"{r2_ridge:.4f}\",\n",
    "        f\"{ridge_non_zero}/{len(ridge_model.coef_)} (100%)\",\n",
    "        f\"{ridge_relevant_identified}/{n_relevant_features} ({ridge_relevant_pct:.1f}%)\",\n",
    "        f\"{ridge_irrelevant_eliminated}/{n_irrelevant_features} ({ridge_irrelevant_pct:.1f}%)\",\n",
    "        f\"{ridge_relevant_pct:.1f}%\",\n",
    "        f\"{ridge_irrelevant_pct:.1f}%\"\n",
    "    ],\n",
    "    'Lasso': [\n",
    "        f\"${rmse_lasso:.2f}\", \n",
    "        f\"{r2_lasso:.4f}\",\n",
    "        f\"{lasso_non_zero}/{len(lasso_model.coef_)} ({lasso_non_zero/len(lasso_model.coef_)*100:.1f}%)\",\n",
    "        f\"{lasso_relevant_identified}/{n_relevant_features} ({lasso_relevant_pct:.1f}%)\",\n",
    "        f\"{lasso_irrelevant_eliminated}/{n_irrelevant_features} ({lasso_irrelevant_pct:.1f}%)\",\n",
    "        f\"{lasso_relevant_pct:.1f}%\",\n",
    "        f\"{lasso_irrelevant_pct:.1f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Mostrar tabla con formato mejorado\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ğŸ“Š TABLA DE RESULTADOS: RIDGE vs LASSO\")\n",
    "print(\"=\"*100)\n",
    "print(resultados.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ğŸ“Š AnÃ¡lisis de la tabla\n",
    "print(\"\\nğŸ“Š ANÃLISIS DE RESULTADOS:\")\n",
    "\n",
    "# Comparar rendimiento predictivo\n",
    "if rmse_lasso < rmse_ridge:\n",
    "    print(f\"ğŸ† RENDIMIENTO PREDICTIVO: Lasso es mejor por ${rmse_ridge - rmse_lasso:.2f}\")\n",
    "elif rmse_ridge < rmse_lasso:\n",
    "    print(f\"ğŸ† RENDIMIENTO PREDICTIVO: Ridge es mejor por ${rmse_lasso - rmse_ridge:.2f}\")\n",
    "else:\n",
    "    print(\"ğŸ† RENDIMIENTO PREDICTIVO: Ambos modelos tienen rendimiento similar\")\n",
    "\n",
    "# Comparar interpretabilidad\n",
    "reduccion_variables = len(ridge_model.coef_) - lasso_non_zero\n",
    "print(f\"\\nğŸ“Š INTERPRETABILIDAD:\")\n",
    "print(f\"   â€¢ Ridge usa todas las {len(ridge_model.coef_)} variables\")\n",
    "print(f\"   â€¢ Lasso usa solo {lasso_non_zero} variables ({reduccion_variables} menos)\")\n",
    "print(f\"   â€¢ Lasso eliminÃ³ {reduccion_variables/len(ridge_model.coef_)*100:.1f}% de las variables\")\n",
    "\n",
    "# Comparar capacidad de selecciÃ³n\n",
    "print(f\"\\nğŸ¯ CAPACIDAD DE SELECCIÃ“N:\")\n",
    "print(f\"   â€¢ Ridge identificÃ³ {ridge_relevant_pct:.1f}% de variables relevantes\")\n",
    "print(f\"   â€¢ Lasso identificÃ³ {lasso_relevant_pct:.1f}% de variables relevantes\")\n",
    "print(f\"   â€¢ Ridge eliminÃ³ {ridge_irrelevant_pct:.1f}% de variables irrelevantes\")\n",
    "print(f\"   â€¢ Lasso eliminÃ³ {lasso_irrelevant_pct:.1f}% de variables irrelevantes\")\n",
    "\n",
    "# Determinar el ganador en cada categorÃ­a\n",
    "print(f\"\\nğŸ† GANADORES POR CATEGORÃA:\")\n",
    "if rmse_lasso <= rmse_ridge:\n",
    "    print(\"   ğŸ¥‡ Rendimiento Predictivo: Lasso\")\n",
    "else:\n",
    "    print(\"   ğŸ¥‡ Rendimiento Predictivo: Ridge\")\n",
    "\n",
    "if lasso_relevant_pct >= ridge_relevant_pct:\n",
    "    print(\"   ğŸ¥‡ IdentificaciÃ³n de Variables Relevantes: Lasso\")\n",
    "else:\n",
    "    print(\"   ğŸ¥‡ IdentificaciÃ³n de Variables Relevantes: Ridge\")\n",
    "\n",
    "if lasso_irrelevant_pct >= ridge_irrelevant_pct:\n",
    "    print(\"   ğŸ¥‡ EliminaciÃ³n de Variables Irrelevantes: Lasso\")\n",
    "else:\n",
    "    print(\"   ğŸ¥‡ EliminaciÃ³n de Variables Irrelevantes: Ridge\")\n",
    "\n",
    "print(\"   ğŸ¥‡ Interpretabilidad: Lasso (menos variables = mÃ¡s simple)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac0dc3",
   "metadata": {},
   "source": [
    "## Paso 7: AnÃ¡lisis de la Capacidad de SelecciÃ³n de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d453cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lisis detallado de la selecciÃ³n de variables\n",
    "print(\"\\n=== ANÃLISIS DE SELECCIÃ“N DE VARIABLES ===\")\n",
    "\n",
    "# Variables realmente relevantes (primeras 10)\n",
    "variables_relevantes = feature_names[:n_relevant_features]\n",
    "variables_irrelevantes = feature_names[n_relevant_features:]\n",
    "\n",
    "# AnÃ¡lisis Ridge\n",
    "ridge_relevant_coefs = ridge_model.coef_[:n_relevant_features]\n",
    "ridge_irrelevant_coefs = ridge_model.coef_[n_relevant_features:]\n",
    "\n",
    "print(f\"\\nRIDGE:\")\n",
    "print(f\"- Variables relevantes con coeficiente > 0.1: {np.sum(np.abs(ridge_relevant_coefs) > 0.1)}/{n_relevant_features}\")\n",
    "print(f\"- Variables irrelevantes con coeficiente > 0.1: {np.sum(np.abs(ridge_irrelevant_coefs) > 0.1)}/{n_irrelevant_features}\")\n",
    "print(f\"- Promedio |coef| variables relevantes: {np.mean(np.abs(ridge_relevant_coefs)):.4f}\")\n",
    "print(f\"- Promedio |coef| variables irrelevantes: {np.mean(np.abs(ridge_irrelevant_coefs)):.4f}\")\n",
    "\n",
    "# AnÃ¡lisis Lasso\n",
    "lasso_relevant_coefs = lasso_model.coef_[:n_relevant_features]\n",
    "lasso_irrelevant_coefs = lasso_model.coef_[n_relevant_features:]\n",
    "\n",
    "print(f\"\\nLASSO:\")\n",
    "print(f\"- Variables relevantes seleccionadas: {np.sum(lasso_relevant_coefs != 0)}/{n_relevant_features}\")\n",
    "print(f\"- Variables irrelevantes eliminadas: {np.sum(lasso_irrelevant_coefs == 0)}/{n_irrelevant_features}\")\n",
    "print(f\"- PrecisiÃ³n en selecciÃ³n: {np.sum(lasso_relevant_coefs != 0) / n_relevant_features:.2%}\")\n",
    "print(f\"- Especificidad: {np.sum(lasso_irrelevant_coefs == 0) / n_irrelevant_features:.2%}\")\n",
    "\n",
    "# Mostrar quÃ© variables relevantes fueron identificadas por Lasso\n",
    "print(f\"\\nVariables relevantes identificadas por Lasso:\")\n",
    "for i, (var, coef) in enumerate(zip(variables_relevantes, lasso_relevant_coefs)):\n",
    "    status = \"âœ“\" if coef != 0 else \"âœ—\"\n",
    "    print(f\"{status} {var}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069cef3",
   "metadata": {},
   "source": [
    "## Paso 8: VisualizaciÃ³n de la EvoluciÃ³n de Coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e09ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar cÃ³mo cambian los coeficientes con diferentes valores de alpha\n",
    "alphas_ridge = np.logspace(-3, 3, 20)\n",
    "alphas_lasso = np.logspace(-3, 1, 20)\n",
    "\n",
    "coefs_ridge = []\n",
    "coefs_lasso = []\n",
    "\n",
    "for alpha in alphas_ridge:\n",
    "    ridge_temp = Ridge(alpha=alpha)\n",
    "    ridge_temp.fit(X_train_scaled, y_train)\n",
    "    coefs_ridge.append(ridge_temp.coef_)\n",
    "\n",
    "for alpha in alphas_lasso:\n",
    "    lasso_temp = Lasso(alpha=alpha, max_iter=2000)\n",
    "    lasso_temp.fit(X_train_scaled, y_train)\n",
    "    coefs_lasso.append(lasso_temp.coef_)\n",
    "\n",
    "coefs_ridge = np.array(coefs_ridge)\n",
    "coefs_lasso = np.array(coefs_lasso)\n",
    "\n",
    "# Crear grÃ¡ficos\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Ridge\n",
    "for i in range(n_total_features):\n",
    "    color = 'red' if i < n_relevant_features else 'gray'\n",
    "    alpha_val = 0.8 if i < n_relevant_features else 0.3\n",
    "    ax1.plot(alphas_ridge, coefs_ridge[:, i], color=color, alpha=alpha_val)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Alpha (ParÃ¡metro de RegularizaciÃ³n)')\n",
    "ax1.set_ylabel('Coeficientes')\n",
    "ax1.set_title('EvoluciÃ³n de Coeficientes - Ridge')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Lasso\n",
    "for i in range(n_total_features):\n",
    "    color = 'red' if i < n_relevant_features else 'gray'\n",
    "    alpha_val = 0.8 if i < n_relevant_features else 0.3\n",
    "    ax2.plot(alphas_lasso, coefs_lasso[:, i], color=color, alpha=alpha_val)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('Alpha (ParÃ¡metro de RegularizaciÃ³n)')\n",
    "ax2.set_ylabel('Coeficientes')\n",
    "ax2.set_title('EvoluciÃ³n de Coeficientes - Lasso')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservaciones:\")\n",
    "print(\"â€¢ LÃ­neas rojas: Variables realmente relevantes\")\n",
    "print(\"â€¢ LÃ­neas grises: Variables irrelevantes\")\n",
    "print(\"â€¢ Ridge: Los coeficientes se hacen pequeÃ±os pero nunca llegan a cero\")\n",
    "print(\"â€¢ Lasso: Los coeficientes pueden llegar exactamente a cero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c559f",
   "metadata": {},
   "source": [
    "## Paso 9: Conclusiones y Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSIONES Y RECOMENDACIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Comparar rendimiento predictivo\n",
    "if rmse_lasso < rmse_ridge:\n",
    "    mejor_prediccion = \"Lasso\"\n",
    "    diferencia_rmse = rmse_ridge - rmse_lasso\n",
    "    print(f\"1. RENDIMIENTO PREDICTIVO: Lasso es mejor por ${diferencia_rmse:.2f}\")\n",
    "else:\n",
    "    mejor_prediccion = \"Ridge\"\n",
    "    diferencia_rmse = rmse_lasso - rmse_ridge\n",
    "    print(f\"1. RENDIMIENTO PREDICTIVO: Ridge es mejor por ${diferencia_rmse:.2f}\")\n",
    "\n",
    "# Comparar interpretabilidad\n",
    "reduccion_variables = len(ridge_model.coef_) - lasso_non_zero\n",
    "print(f\"\\n2. INTERPRETABILIDAD:\")\n",
    "print(f\"   â€¢ Ridge usa todas las {len(ridge_model.coef_)} variables\")\n",
    "print(f\"   â€¢ Lasso usa solo {lasso_non_zero} variables ({reduccion_variables} menos)\")\n",
    "print(f\"   â€¢ Lasso eliminÃ³ {reduccion_variables/len(ridge_model.coef_)*100:.1f}% de las variables\")\n",
    "\n",
    "# AnÃ¡lisis de selecciÃ³n correcta\n",
    "precision_lasso = np.sum(lasso_relevant_coefs != 0) / n_relevant_features\n",
    "especificidad_lasso = np.sum(lasso_irrelevant_coefs == 0) / n_irrelevant_features\n",
    "\n",
    "print(f\"\\n3. CAPACIDAD DE SELECCIÃ“N DE VARIABLES:\")\n",
    "print(f\"   â€¢ PrecisiÃ³n (variables relevantes identificadas): {precision_lasso:.1%}\")\n",
    "print(f\"   â€¢ Especificidad (variables irrelevantes eliminadas): {especificidad_lasso:.1%}\")\n",
    "\n",
    "# RecomendaciÃ³n final\n",
    "print(f\"\\n4. RECOMENDACIÃ“N FINAL:\")\n",
    "if precision_lasso > 0.7 and especificidad_lasso > 0.8:\n",
    "    print(\"   âœ“ Lasso es la mejor opciÃ³n para este problema\")\n",
    "    print(\"   â€¢ Excelente capacidad de selecciÃ³n de variables\")\n",
    "    print(\"   â€¢ Modelo mÃ¡s interpretable y simple\")\n",
    "elif rmse_lasso < rmse_ridge * 1.05:  # Si Lasso no es mÃ¡s del 5% peor\n",
    "    print(\"   âœ“ Lasso es recomendable\")\n",
    "    print(\"   â€¢ Rendimiento predictivo similar a Ridge\")\n",
    "    print(\"   â€¢ Ventaja en interpretabilidad\")\n",
    "else:\n",
    "    print(\"   âš  Ridge podrÃ­a ser preferible\")\n",
    "    print(\"   â€¢ Mejor rendimiento predictivo\")\n",
    "    print(\"   â€¢ Considerar el trade-off con interpretabilidad\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c28838",
   "metadata": {},
   "source": [
    "## ğŸ“ Resumen de la Actividad\n",
    "\n",
    "### ğŸ§  Lo que hemos aprendido:\n",
    "\n",
    "#### 1. **Diferencias fundamentales entre Ridge y Lasso:**\n",
    "\n",
    "| Aspecto | Ridge (L2) | Lasso (L1) |\n",
    "|---------|------------|------------|\n",
    "| **PenalizaciÃ³n** | Î²áµ¢Â² (cuadrado) | \\|Î²áµ¢\\| (valor absoluto) |\n",
    "| **Coeficientes cero** | Nunca | Pueden ser cero |\n",
    "| **SelecciÃ³n de variables** | No | SÃ­ |\n",
    "| **Interpretabilidad** | Baja | Alta |\n",
    "\n",
    "#### 2. **Capacidad de selecciÃ³n de variables:**\n",
    "- **Lasso**: Puede identificar automÃ¡ticamente las variables mÃ¡s importantes\n",
    "- **Ridge**: Mantiene todas las variables pero con pesos reducidos\n",
    "\n",
    "#### 3. **Trade-offs importantes:**\n",
    "- **Interpretabilidad vs. Rendimiento predictivo**\n",
    "- **Simplicidad del modelo vs. Complejidad**\n",
    "- **SelecciÃ³n de variables vs. Uso de toda la informaciÃ³n**\n",
    "\n",
    "### ğŸ¯ Aplicaciones prÃ¡cticas:\n",
    "\n",
    "#### **Usar Lasso cuando:**\n",
    "- âœ… Tienes muchas variables y quieres identificar las mÃ¡s importantes\n",
    "- âœ… La interpretabilidad es crucial\n",
    "- âœ… Quieres un modelo mÃ¡s simple y fÃ¡cil de explicar\n",
    "- âœ… Sospechas que muchas variables son irrelevantes\n",
    "\n",
    "#### **Usar Ridge cuando:**\n",
    "- âœ… Todas las variables podrÃ­an ser relevantes\n",
    "- âœ… El rendimiento predictivo es la prioridad mÃ¡xima\n",
    "- âœ… Quieres evitar la eliminaciÃ³n de variables potencialmente Ãºtiles\n",
    "- âœ… Tienes correlaciÃ³n alta entre variables\n",
    "\n",
    "### ğŸš€ PrÃ³ximos pasos sugeridos:\n",
    "\n",
    "1. **ğŸ“Š Probar con datos reales**: Aplicar estos conceptos al dataset real de ingresos de PerÃº\n",
    "2. **ğŸ”¬ Experimentar con Elastic Net**: CombinaciÃ³n de Ridge y Lasso\n",
    "3. **ğŸŒ Aplicar a otros problemas**: Usar estos conceptos en otros problemas de regresiÃ³n\n",
    "4. **ğŸ“ˆ Explorar mÃ¡s tÃ©cnicas**: Aprender sobre otras tÃ©cnicas de regularizaciÃ³n\n",
    "\n",
    "### ğŸ’¡ Conceptos clave para recordar:\n",
    "\n",
    "- **RegularizaciÃ³n**: TÃ©cnica para prevenir overfitting\n",
    "- **PenalizaciÃ³n L1 vs L2**: Diferentes formas de regularizar\n",
    "- **SelecciÃ³n de variables**: Capacidad de eliminar variables irrelevantes\n",
    "- **ValidaciÃ³n cruzada**: Para encontrar el mejor parÃ¡metro de regularizaciÃ³n\n",
    "- **Trade-offs**: Siempre hay compensaciones entre diferentes objetivos\n",
    "\n",
    "### ğŸ‰ Â¡Felicidades!\n",
    "\n",
    "Has completado exitosamente esta actividad prÃ¡ctica sobre Ridge vs Lasso. Ahora tienes una comprensiÃ³n sÃ³lida de:\n",
    "\n",
    "- âœ… CÃ³mo funcionan las tÃ©cnicas de regularizaciÃ³n\n",
    "- âœ… CuÃ¡ndo usar Ridge vs Lasso\n",
    "- âœ… CÃ³mo interpretar los resultados\n",
    "- âœ… CÃ³mo evaluar el rendimiento de los modelos\n",
    "\n",
    "Â¡Sigue practicando y explorando mÃ¡s tÃ©cnicas de Machine Learning! ğŸš€"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
