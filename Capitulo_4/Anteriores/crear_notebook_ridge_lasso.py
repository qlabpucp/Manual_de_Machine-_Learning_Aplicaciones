
import nbformat as nbf

def crear_notebook_ridge_lasso():
    """Crear un notebook completo para comparar Ridge vs Lasso"""
    
    # Crear un nuevo notebook
    nb = nbf.v4.new_notebook()
    
    # Lista de todas las celdas
    celdas = []
    
    # === CELDA 1: TÃ­tulo principal ===
    celda1 = nbf.v4.new_markdown_cell("""# Actividad: Lasso vs. Ridge - ComparaciÃ³n de Modelos de RegularizaciÃ³n

## ğŸ¯ Objetivo de la Actividad
En esta actividad prÃ¡ctica, aprenderemos a comparar dos tÃ©cnicas fundamentales de regularizaciÃ³n en Machine Learning: **Ridge Regression** y **Lasso Regression**. 

### Â¿QuÃ© es la RegularizaciÃ³n?
La regularizaciÃ³n es una tÃ©cnica que ayuda a prevenir el **overfitting** (sobreajuste) en nuestros modelos. Cuando un modelo se sobreajusta, memoriza los datos de entrenamiento pero no generaliza bien a nuevos datos.

### Â¿Por quÃ© comparar Ridge vs Lasso?
- **Ridge (L2)**: Reduce los coeficientes pero nunca los hace exactamente cero
- **Lasso (L1)**: Puede hacer que algunos coeficientes sean exactamente cero, eliminando variables

### ğŸ“‹ HipÃ³tesis que vamos a probar:
1. **Lasso** tendrÃ¡ un error de predicciÃ³n similar o mejor que Ridge
2. **Lasso** producirÃ¡ un modelo mÃ¡s interpretable al reducir a cero los coeficientes de variables irrelevantes
3. **Ridge** mantendrÃ¡ todos los coeficientes pero con valores pequeÃ±os

### ğŸ§  Conceptos Clave que Aprenderemos:
- **PenalizaciÃ³n L1 vs L2**: Diferentes formas de regularizar
- **SelecciÃ³n de Variables**: CÃ³mo Lasso puede eliminar automÃ¡ticamente variables irrelevantes
- **Trade-off**: Interpretabilidad vs Rendimiento predictivo
- **ValidaciÃ³n Cruzada**: Para encontrar el mejor parÃ¡metro de regularizaciÃ³n""")
    
    # === CELDA 2: Importaciones ===
    celda2 = nbf.v4.new_code_cell("""# ğŸ“š Importar librerÃ­as necesarias
# NumPy: Para operaciones matemÃ¡ticas y arrays
import numpy as np

# Pandas: Para manipulaciÃ³n y anÃ¡lisis de datos
import pandas as pd

# Matplotlib y Seaborn: Para visualizaciones
import matplotlib.pyplot as plt
import seaborn as sns

# Scikit-learn: LibrerÃ­a principal de Machine Learning
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import Lasso, Ridge
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# ConfiguraciÃ³n para evitar warnings innecesarios
import warnings
warnings.filterwarnings('ignore')

# ğŸ¨ Configurar estilo de grÃ¡ficos para que se vean mÃ¡s bonitos
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("âœ… LibrerÃ­as importadas correctamente")
print("ğŸ“Š ConfiguraciÃ³n de grÃ¡ficos lista")
print("ğŸš€ Â¡Listos para comenzar la actividad!")""")
    
    # === CELDA 3: SecciÃ³n de datos simulados ===
    celda3 = nbf.v4.new_markdown_cell("""## ğŸ“Š Paso 1: GeneraciÃ³n de Datos Simulados

### Â¿Por quÃ© usar datos simulados?
Para entender mejor cÃ³mo funcionan Ridge y Lasso, vamos a crear datos donde **sabemos exactamente** quÃ© variables son importantes y cuÃ¡les no. Esto nos permitirÃ¡ evaluar si nuestros modelos pueden identificar correctamente las variables relevantes.

### ğŸ¯ Estructura de nuestros datos:
- **10 variables relevantes**: Que realmente afectan el ingreso anual
- **20 variables irrelevantes**: Que no tienen relaciÃ³n con el ingreso
- **1000 observaciones**: Para tener suficientes datos
- **Ruido**: Para simular condiciones reales (nada es perfecto en la vida real)

### ğŸ§  Concepto importante: Coeficientes Verdaderos
En la vida real, nunca sabemos los "coeficientes verdaderos", pero aquÃ­ los definimos para poder evaluar quÃ© tan bien funcionan nuestros modelos.

### ğŸ“ˆ Variables que simularemos:
1. **EducaciÃ³n** (coef = 5000): AÃ±os de estudio
2. **Experiencia laboral** (coef = 3000): AÃ±os trabajando
3. **Edad** (coef = 2000): Edad del trabajador
4. **Horas trabajadas** (coef = 1500): Horas semanales
5. **Sector econÃ³mico** (coef = 1000): Tipo de industria
6. **TamaÃ±o de empresa** (coef = 800): NÃºmero de empleados
7. **Nivel de responsabilidad** (coef = 600): Cargo en la empresa
8. **UbicaciÃ³n geogrÃ¡fica** (coef = 400): Ciudad/regiÃ³n
9. **Certificaciones** (coef = 300): Certificaciones profesionales
10. **Idiomas** (coef = 200): NÃºmero de idiomas hablados""")
    
    # === CELDA 4: CÃ³digo de generaciÃ³n de datos ===
    celda4 = nbf.v4.new_code_cell("""# ğŸ”§ Configurar semilla para reproducibilidad
# Esto asegura que obtengamos los mismos resultados cada vez que ejecutemos el cÃ³digo
np.random.seed(42)

# ğŸ“Š ParÃ¡metros de la simulaciÃ³n
n_samples = 1000                    # NÃºmero de personas en nuestro dataset
n_relevant_features = 10            # Variables que realmente afectan el ingreso
n_irrelevant_features = 20          # Variables que NO afectan el ingreso
n_total_features = n_relevant_features + n_irrelevant_features

print(f"ğŸ¯ Creando dataset con {n_samples} personas y {n_total_features} variables")
print(f"ğŸ“ˆ Variables relevantes: {n_relevant_features}")
print(f"âŒ Variables irrelevantes: {n_irrelevant_features}")

# ğŸ² Generar variables explicativas (caracterÃ­sticas de cada persona)
# randn genera nÃºmeros aleatorios con distribuciÃ³n normal
X = np.random.randn(n_samples, n_total_features)

# ğŸ¯ Definir coeficientes reales (solo las primeras 10 variables son relevantes)
true_coefficients = np.zeros(n_total_features)  # Inicializar todos en cero
true_coefficients[:n_relevant_features] = np.array([
    5000,  # EducaciÃ³n: Cada aÃ±o adicional suma $5000 al ingreso
    3000,  # Experiencia laboral: Cada aÃ±o de experiencia suma $3000
    2000,  # Edad: La edad tiene un efecto moderado
    1500,  # Horas trabajadas: MÃ¡s horas = mÃ¡s ingreso
    1000,  # Sector econÃ³mico: Algunos sectores pagan mejor
    800,   # TamaÃ±o de empresa: Empresas grandes suelen pagar mÃ¡s
    600,   # Nivel de responsabilidad: MÃ¡s responsabilidad = mÃ¡s pago
    400,   # UbicaciÃ³n geogrÃ¡fica: Algunas ciudades pagan mejor
    300,   # Certificaciones: Certificaciones profesionales aumentan el ingreso
    200    # Idiomas: Cada idioma adicional suma un poco
])

print("\\nğŸ’° Coeficientes verdaderos (solo las primeras 10 variables son relevantes):")
for i, coef in enumerate(true_coefficients[:n_relevant_features]):
    print(f"   Variable {i+1}: ${coef:.0f}")

# ğŸ¯ Generar variable objetivo (ingreso anual) con ruido
# La fÃ³rmula es: ingreso = X1*coef1 + X2*coef2 + ... + ruido
y = X @ true_coefficients + np.random.normal(0, 1000, n_samples)

# ğŸ“ Crear nombres de variables para mejor interpretaciÃ³n
feature_names = []
for i in range(n_relevant_features):
    feature_names.append(f'Variable_Relevante_{i+1}')
for i in range(n_irrelevant_features):
    feature_names.append(f'Variable_Irrelevante_{i+1}')

# ğŸ“Š Crear DataFrame con pandas
df = pd.DataFrame(X, columns=feature_names)
df['ingreso_anual'] = y

# ğŸ“ˆ Mostrar resumen del dataset
print(f"\\nâœ… Dataset creado exitosamente!")
print(f"ğŸ“Š Observaciones: {n_samples}")
print(f"ğŸ“ˆ Variables totales: {n_total_features}")
print(f"ğŸ’° Rango de ingresos: ${y.min():.0f} - ${y.max():.0f}")
print(f"ğŸ’° Ingreso promedio: ${y.mean():.0f}")
print(f"ğŸ’° DesviaciÃ³n estÃ¡ndar: ${y.std():.0f}")

print("\\nğŸ“‹ Primeras 5 filas del dataset:")
print(df.head())

print("\\nğŸ” InformaciÃ³n del dataset:")
print(df.info())""")
    
    # === CELDA 5: PreparaciÃ³n de datos ===
    celda5 = nbf.v4.new_markdown_cell("""## ğŸ”§ Paso 2: PreparaciÃ³n de los Datos

### Â¿Por quÃ© necesitamos preparar los datos?

Antes de entrenar nuestros modelos, necesitamos hacer algunos ajustes importantes:

1. **Separar variables explicativas y objetivo**: Distinguir entre lo que queremos predecir y lo que usamos para predecir
2. **Dividir en entrenamiento y prueba**: Para evaluar quÃ© tan bien generaliza nuestro modelo
3. **Estandarizar las variables**: Para que todas las variables tengan la misma escala

### ğŸ§  Conceptos importantes:

**Train-Test Split**: Dividimos nuestros datos en dos partes:
- **Datos de entrenamiento** (70%): Para enseÃ±ar al modelo
- **Datos de prueba** (30%): Para evaluar quÃ© tan bien funciona

**EstandarizaciÃ³n**: Convertimos todas las variables a la misma escala (media=0, desviaciÃ³n=1). Esto es importante porque:
- Ridge y Lasso son sensibles a la escala de las variables
- Variables con valores grandes pueden dominar el modelo
- La estandarizaciÃ³n hace que todas las variables tengan igual importancia inicial""")
    
    # === CELDA 6: CÃ³digo de preparaciÃ³n ===
    celda6 = nbf.v4.new_code_cell("""# ğŸ“Š Separar variables explicativas (X) y variable objetivo (y)
print("ğŸ” Separando variables explicativas y objetivo...")
X = df.drop('ingreso_anual', axis=1)  # Todas las variables excepto el ingreso
y = df['ingreso_anual']               # Solo el ingreso (lo que queremos predecir)

print(f"ğŸ“ˆ Variables explicativas (X): {X.shape[1]} variables")
print(f"ğŸ¯ Variable objetivo (y): 1 variable (ingreso anual)")
print(f"ğŸ“Š Total de observaciones: {X.shape[0]}")

# ğŸ”„ Dividir en conjuntos de entrenamiento y prueba
print("\\nğŸ”„ Dividiendo datos en entrenamiento (70%) y prueba (30%)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42  # 30% para prueba, semilla para reproducibilidad
)

print(f"ğŸ“š Datos de entrenamiento: {X_train.shape[0]} observaciones")
print(f"ğŸ§ª Datos de prueba: {X_test.shape[0]} observaciones")
print(f"ğŸ“ˆ Variables en cada conjunto: {X_train.shape[1]}")

# âš–ï¸ Estandarizar las variables (muy importante para Ridge y Lasso)
print("\\nâš–ï¸ Estandarizando variables...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Ajustar y transformar datos de entrenamiento
X_test_scaled = scaler.transform(X_test)        # Solo transformar datos de prueba

print("âœ… EstandarizaciÃ³n completada!")
print("ğŸ“Š Ahora todas las variables tienen media=0 y desviaciÃ³n=1")

# ğŸ” Verificar la estandarizaciÃ³n
print("\\nğŸ” Verificando la estandarizaciÃ³n:")
print(f"Media de variables estandarizadas: {X_train_scaled.mean():.6f} (deberÃ­a ser ~0)")
print(f"DesviaciÃ³n de variables estandarizadas: {X_train_scaled.std():.6f} (deberÃ­a ser ~1)")

print("\\nâœ… Â¡Datos preparados y listos para entrenar modelos!")""")
    
    # === CELDA 7: Entrenamiento Ridge ===
    celda7 = nbf.v4.new_markdown_cell("""## ğŸ”ï¸ Paso 3: Entrenamiento del Modelo Ridge

### Â¿QuÃ© es Ridge Regression?

**Ridge Regression** es una tÃ©cnica de regularizaciÃ³n que usa **penalizaciÃ³n L2**. Su objetivo es reducir el overfitting agregando una penalizaciÃ³n a los coeficientes grandes.

### ğŸ§  Concepto clave: PenalizaciÃ³n L2

La funciÃ³n objetivo de Ridge es:
```
Error = Error de predicciÃ³n + Î± Ã— (Î²â‚Â² + Î²â‚‚Â² + ... + Î²â‚šÂ²)
```

Donde:
- **Î± (alpha)**: ParÃ¡metro de regularizaciÃ³n (controla la fuerza de la penalizaciÃ³n)
- **Î²áµ¢Â²**: Cuadrado de cada coeficiente

### ğŸ” Â¿CÃ³mo funciona Ridge?

1. **Reduce coeficientes**: Hace que los coeficientes sean mÃ¡s pequeÃ±os
2. **Nunca los hace cero**: Los coeficientes se acercan a cero pero nunca llegan exactamente a cero
3. **Mantiene todas las variables**: Todas las variables siguen en el modelo

### ğŸ¯ Â¿CuÃ¡ndo usar Ridge?

- Cuando todas las variables podrÃ­an ser relevantes
- Cuando quieres evitar eliminar variables potencialmente Ãºtiles
- Cuando el rendimiento predictivo es la prioridad

### ğŸ“Š Proceso que vamos a seguir:

1. **Probar diferentes valores de alpha**: Para encontrar el mejor parÃ¡metro
2. **Usar validaciÃ³n cruzada**: Para evaluar cada valor de alpha
3. **Entrenar el modelo final**: Con el mejor alpha encontrado
4. **Evaluar el rendimiento**: En datos de prueba""")
    
    # === CELDA 8: CÃ³digo Ridge ===
    celda8 = nbf.v4.new_code_cell("""# ğŸ¯ Definir valores de alpha para Ridge
print("ğŸ” Buscando el mejor parÃ¡metro alpha para Ridge...")
print("ğŸ“Š Probando valores desde 0.001 hasta 1000...")

# Usar logspace para probar valores en escala logarÃ­tmica
alpha_values = np.logspace(-3, 3, 50)  # 50 valores entre 10^-3 y 10^3
print(f"ğŸ¯ Probando {len(alpha_values)} valores diferentes de alpha")

# ğŸ”„ Entrenar Ridge con validaciÃ³n cruzada para cada alpha
print("\\nğŸ”„ Entrenando modelos Ridge con validaciÃ³n cruzada...")
ridge_scores = []

for i, alpha in enumerate(alpha_values):
    ridge = Ridge(alpha=alpha)
    # Usar validaciÃ³n cruzada con 5 folds
    scores = cross_val_score(ridge, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')
    ridge_scores.append(-np.mean(scores))  # Convertir a error positivo
    
    # Mostrar progreso cada 10 iteraciones
    if (i + 1) % 10 == 0:
        print(f"   Progreso: {i+1}/{len(alpha_values)} alphas probados")

# ğŸ† Encontrar el mejor alpha
best_alpha_ridge = alpha_values[np.argmin(ridge_scores)]
best_score_ridge = min(ridge_scores)

print(f"\\nğŸ† Mejor alpha encontrado: {best_alpha_ridge:.4f}")
print(f"ğŸ“Š Mejor error MSE: {best_score_ridge:.2f}")

# ğŸš€ Entrenar modelo Ridge final con el mejor alpha
print("\\nğŸš€ Entrenando modelo Ridge final con el mejor alpha...")
ridge_model = Ridge(alpha=best_alpha_ridge)
ridge_model.fit(X_train_scaled, y_train)

# ğŸ“ˆ Hacer predicciones en datos de prueba
y_pred_ridge = ridge_model.predict(X_test_scaled)

# ğŸ“Š Calcular mÃ©tricas de rendimiento
rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))
r2_ridge = r2_score(y_test, y_pred_ridge)

print("\\nğŸ“Š RESULTADOS DEL MODELO RIDGE:")
print(f"ğŸ¯ Mejor alpha: {best_alpha_ridge:.4f}")
print(f"ğŸ’° RMSE (Error de predicciÃ³n): ${rmse_ridge:.2f}")
print(f"ğŸ“ˆ RÂ² (Coeficiente de determinaciÃ³n): {r2_ridge:.4f}")

# ğŸ” Analizar coeficientes
ridge_non_zero = np.sum(ridge_model.coef_ != 0)
print(f"ğŸ“Š Coeficientes no cero: {ridge_non_zero}/{len(ridge_model.coef_)}")
print(f"ğŸ“Š Porcentaje de variables usadas: {ridge_non_zero/len(ridge_model.coef_)*100:.1f}%")

# ğŸ“Š Mostrar algunos coeficientes como ejemplo
print("\\nğŸ” Ejemplos de coeficientes Ridge:")
coef_ridge_df = pd.DataFrame({
    'Variable': feature_names,
    'Coeficiente': ridge_model.coef_
})
print(coef_ridge_df.head(10))""")
    
    # === CELDA 9: Entrenamiento Lasso ===
    celda9 = nbf.v4.new_markdown_cell("""## ğŸ¯ Paso 4: Entrenamiento del Modelo Lasso

### Â¿QuÃ© es Lasso Regression?

**Lasso Regression** es una tÃ©cnica de regularizaciÃ³n que usa **penalizaciÃ³n L1**. Su objetivo es reducir el overfitting y realizar **selecciÃ³n automÃ¡tica de variables**.

### ğŸ§  Concepto clave: PenalizaciÃ³n L1

La funciÃ³n objetivo de Lasso es:
```
Error = Error de predicciÃ³n + Î± Ã— (|Î²â‚| + |Î²â‚‚| + ... + |Î²â‚š|)
```

Donde:
- **Î± (alpha)**: ParÃ¡metro de regularizaciÃ³n (controla la fuerza de la penalizaciÃ³n)
- **|Î²áµ¢|**: Valor absoluto de cada coeficiente

### ğŸ” Â¿CÃ³mo funciona Lasso?

1. **Reduce coeficientes**: Hace que los coeficientes sean mÃ¡s pequeÃ±os
2. **Puede hacerlos cero**: Los coeficientes pueden llegar exactamente a cero
3. **SelecciÃ³n de variables**: Elimina automÃ¡ticamente variables irrelevantes

### ğŸ¯ Â¿CuÃ¡ndo usar Lasso?

- Cuando tienes muchas variables y quieres identificar las mÃ¡s importantes
- Cuando la interpretabilidad es crucial
- Cuando quieres un modelo mÃ¡s simple y fÃ¡cil de explicar
- Cuando sospechas que muchas variables son irrelevantes

### ğŸ†š Diferencias clave con Ridge:

| Aspecto | Ridge (L2) | Lasso (L1) |
|---------|------------|------------|
| PenalizaciÃ³n | Î²áµ¢Â² (cuadrado) | \|Î²áµ¢\| (valor absoluto) |
| Coeficientes cero | Nunca | Pueden ser cero |
| SelecciÃ³n de variables | No | SÃ­ |
| Interpretabilidad | Baja | Alta |

### ğŸ“Š Proceso que vamos a seguir:

1. **Probar diferentes valores de alpha**: Para encontrar el mejor parÃ¡metro
2. **Usar validaciÃ³n cruzada**: Para evaluar cada valor de alpha
3. **Entrenar el modelo final**: Con el mejor alpha encontrado
4. **Evaluar el rendimiento**: En datos de prueba
5. **Analizar selecciÃ³n de variables**: Ver quÃ© variables fueron eliminadas""")
    
    # === CELDA 10: CÃ³digo Lasso ===
    celda10 = nbf.v4.new_code_cell("""# ğŸ¯ Definir valores de alpha para Lasso
print("ğŸ” Buscando el mejor parÃ¡metro alpha para Lasso...")
print("ğŸ“Š Probando valores desde 0.001 hasta 10...")

# Usar logspace para probar valores en escala logarÃ­tmica
alpha_values_lasso = np.logspace(-3, 1, 50)  # 50 valores entre 10^-3 y 10^1
print(f"ğŸ¯ Probando {len(alpha_values_lasso)} valores diferentes de alpha")

# ğŸ”„ Entrenar Lasso con validaciÃ³n cruzada para cada alpha
print("\\nğŸ”„ Entrenando modelos Lasso con validaciÃ³n cruzada...")
lasso_scores = []

for i, alpha in enumerate(alpha_values_lasso):
    lasso = Lasso(alpha=alpha, max_iter=2000)  # MÃ¡s iteraciones para convergencia
    # Usar validaciÃ³n cruzada con 5 folds
    scores = cross_val_score(lasso, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')
    lasso_scores.append(-np.mean(scores))  # Convertir a error positivo
    
    # Mostrar progreso cada 10 iteraciones
    if (i + 1) % 10 == 0:
        print(f"   Progreso: {i+1}/{len(alpha_values_lasso)} alphas probados")

# ğŸ† Encontrar el mejor alpha
best_alpha_lasso = alpha_values_lasso[np.argmin(lasso_scores)]
best_score_lasso = min(lasso_scores)

print(f"\\nğŸ† Mejor alpha encontrado: {best_alpha_lasso:.4f}")
print(f"ğŸ“Š Mejor error MSE: {best_score_lasso:.2f}")

# ğŸš€ Entrenar modelo Lasso final con el mejor alpha
print("\\nğŸš€ Entrenando modelo Lasso final con el mejor alpha...")
lasso_model = Lasso(alpha=best_alpha_lasso, max_iter=2000)
lasso_model.fit(X_train_scaled, y_train)

# ğŸ“ˆ Hacer predicciones en datos de prueba
y_pred_lasso = lasso_model.predict(X_test_scaled)

# ğŸ“Š Calcular mÃ©tricas de rendimiento
rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))
r2_lasso = r2_score(y_test, y_pred_lasso)

print("\\nğŸ“Š RESULTADOS DEL MODELO LASSO:")
print(f"ğŸ¯ Mejor alpha: {best_alpha_lasso:.4f}")
print(f"ğŸ’° RMSE (Error de predicciÃ³n): ${rmse_lasso:.2f}")
print(f"ğŸ“ˆ RÂ² (Coeficiente de determinaciÃ³n): {r2_lasso:.4f}")

# ğŸ” Analizar coeficientes y selecciÃ³n de variables
lasso_non_zero = np.sum(lasso_model.coef_ != 0)
lasso_zero = np.sum(lasso_model.coef_ == 0)

print(f"ğŸ“Š Coeficientes no cero: {lasso_non_zero}/{len(lasso_model.coef_)}")
print(f"ğŸ“Š Coeficientes cero (variables eliminadas): {lasso_zero}/{len(lasso_model.coef_)}")
print(f"ğŸ“Š Porcentaje de variables usadas: {lasso_non_zero/len(lasso_model.coef_)*100:.1f}%")
print(f"ğŸ“Š Porcentaje de variables eliminadas: {lasso_zero/len(lasso_model.coef_)*100:.1f}%")

# ğŸ“Š Mostrar variables seleccionadas y eliminadas
print("\\nğŸ” Variables seleccionadas por Lasso (coeficiente â‰  0):")
lasso_selected_vars = []
lasso_eliminated_vars = []

for i, (var, coef) in enumerate(zip(feature_names, lasso_model.coef_)):
    if coef != 0:
        lasso_selected_vars.append((var, coef))
    else:
        lasso_eliminated_vars.append(var)

print(f"âœ… Variables seleccionadas ({len(lasso_selected_vars)}):")
for var, coef in lasso_selected_vars[:10]:  # Mostrar solo las primeras 10
    print(f"   {var}: {coef:.4f}")

if len(lasso_eliminated_vars) > 0:
    print(f"\\nâŒ Variables eliminadas ({len(lasso_eliminated_vars)}):")
    for var in lasso_eliminated_vars[:10]:  # Mostrar solo las primeras 10
        print(f"   {var}")

print(f"\\nğŸ¯ Â¡Lasso eliminÃ³ {len(lasso_eliminated_vars)} variables irrelevantes!")""")
    
    # === CELDA 11: ComparaciÃ³n visual ===
    celda11 = nbf.v4.new_markdown_cell("""## ğŸ“Š Paso 5: ComparaciÃ³n Visual de Coeficientes

### Â¿Por quÃ© visualizar los coeficientes?

La visualizaciÃ³n nos ayuda a entender mejor cÃ³mo funcionan Ridge y Lasso:

1. **Ridge**: Todos los coeficientes son pequeÃ±os pero no cero
2. **Lasso**: Algunos coeficientes son exactamente cero (variables eliminadas)

### ğŸ§  Conceptos clave de la visualizaciÃ³n:

- **Altura de las barras**: Magnitud del coeficiente
- **Barras en cero**: Variables eliminadas por Lasso
- **PatrÃ³n de distribuciÃ³n**: CÃ³mo se distribuyen los coeficientes

### ğŸ“ˆ Lo que vamos a observar:

1. **Diferencias en magnitud**: Ridge vs Lasso
2. **SelecciÃ³n de variables**: Variables eliminadas por Lasso
3. **Interpretabilidad**: CuÃ¡l modelo es mÃ¡s fÃ¡cil de interpretar

### ğŸ¯ Preguntas que responderemos:

- Â¿CuÃ¡ntas variables eliminÃ³ Lasso?
- Â¿QuÃ© variables considera mÃ¡s importantes cada modelo?
- Â¿CuÃ¡l modelo es mÃ¡s interpretable?""")
    
    # === CELDA 12: CÃ³digo de visualizaciÃ³n ===
    celda12 = nbf.v4.new_code_cell("""# ğŸ“Š Crear figura con subplots para comparar Ridge vs Lasso
print("ğŸ¨ Creando visualizaciÃ³n comparativa de coeficientes...")

fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 14))

# ğŸ”ï¸ GrÃ¡fico de coeficientes Ridge
print("ğŸ“ˆ Preparando grÃ¡fico de coeficientes Ridge...")
coef_ridge = pd.Series(ridge_model.coef_, index=feature_names)
coef_ridge_sorted = coef_ridge.sort_values(key=abs, ascending=False)

# Crear barras con colores diferentes para variables relevantes vs irrelevantes
colors_ridge = ['red' if i < n_relevant_features else 'gray' for i in range(len(coef_ridge_sorted))]
coef_ridge_sorted.plot(kind='bar', ax=ax1, color=colors_ridge, alpha=0.7)

ax1.set_title('Coeficientes del Modelo Ridge (L2)', fontsize=16, fontweight='bold', pad=20)
ax1.set_ylabel('Valor del Coeficiente', fontsize=12)
ax1.tick_params(axis='x', rotation=45, labelsize=10)
ax1.grid(True, alpha=0.3)
ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)

# Agregar leyenda
from matplotlib.patches import Patch
legend_elements_ridge = [
    Patch(facecolor='red', alpha=0.7, label='Variables Relevantes'),
    Patch(facecolor='gray', alpha=0.7, label='Variables Irrelevantes')
]
ax1.legend(handles=legend_elements_ridge, loc='upper right')

# ğŸ¯ GrÃ¡fico de coeficientes Lasso
print("ğŸ“ˆ Preparando grÃ¡fico de coeficientes Lasso...")
coef_lasso = pd.Series(lasso_model.coef_, index=feature_names)
coef_lasso_sorted = coef_lasso.sort_values(key=abs, ascending=False)

# Crear barras con colores diferentes
colors_lasso = ['red' if i < n_relevant_features else 'gray' for i in range(len(coef_lasso_sorted))]
coef_lasso_sorted.plot(kind='bar', ax=ax2, color=colors_lasso, alpha=0.7)

ax2.set_title('Coeficientes del Modelo Lasso (L1)', fontsize=16, fontweight='bold', pad=20)
ax2.set_ylabel('Valor del Coeficiente', fontsize=12)
ax2.tick_params(axis='x', rotation=45, labelsize=10)
ax2.grid(True, alpha=0.3)
ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)

# Agregar leyenda
legend_elements_lasso = [
    Patch(facecolor='red', alpha=0.7, label='Variables Relevantes'),
    Patch(facecolor='gray', alpha=0.7, label='Variables Irrelevantes')
]
ax2.legend(handles=legend_elements_lasso, loc='upper right')

plt.tight_layout()
plt.show()

# ğŸ“Š AnÃ¡lisis detallado de los resultados
print("\\n" + "="*80)
print("ğŸ“Š ANÃLISIS COMPARATIVO DE COEFICIENTES")
print("="*80)

# ğŸ”ï¸ AnÃ¡lisis Ridge
print("\\nğŸ”ï¸ ANÃLISIS RIDGE:")
print(f"ğŸ“Š Total de variables: {len(coef_ridge)}")
print(f"ğŸ“Š Variables con coeficiente > 0.1: {np.sum(np.abs(coef_ridge) > 0.1)}")
print(f"ğŸ“Š Variables con coeficiente > 1.0: {np.sum(np.abs(coef_ridge) > 1.0)}")
print(f"ğŸ“Š Rango de coeficientes: {coef_ridge.min():.4f} a {coef_ridge.max():.4f}")

# ğŸ¯ AnÃ¡lisis Lasso
print("\\nğŸ¯ ANÃLISIS LASSO:")
print(f"ğŸ“Š Total de variables: {len(coef_lasso)}")
print(f"ğŸ“Š Variables seleccionadas (â‰  0): {np.sum(coef_lasso != 0)}")
print(f"ğŸ“Š Variables eliminadas (= 0): {np.sum(coef_lasso == 0)}")
print(f"ğŸ“Š Rango de coeficientes: {coef_lasso.min():.4f} a {coef_lasso.max():.4f}")

# ğŸ† ComparaciÃ³n
print("\\nğŸ† COMPARACIÃ“N:")
print(f"ğŸ“Š Variables usadas por Ridge: {len(coef_ridge)} (100%)")
print(f"ğŸ“Š Variables usadas por Lasso: {np.sum(coef_lasso != 0)} ({np.sum(coef_lasso != 0)/len(coef_lasso)*100:.1f}%)")
print(f"ğŸ“Š ReducciÃ³n de variables por Lasso: {len(coef_lasso) - np.sum(coef_lasso != 0)} variables")

# ğŸ“‹ Mostrar las variables mÃ¡s importantes segÃºn cada modelo
print("\\n" + "="*80)
print("ğŸ“‹ TOP 10 VARIABLES MÃS IMPORTANTES")
print("="*80)

print("\\nğŸ”ï¸ Ridge (por valor absoluto):")
for i, (var, coef) in enumerate(coef_ridge_sorted.head(10).items()):
    relevante = "âœ…" if i < n_relevant_features else "âŒ"
    print(f"{i+1:2d}. {var}: {coef:.4f} {relevante}")

print("\\nğŸ¯ Lasso (variables seleccionadas):")
lasso_selected = coef_lasso[coef_lasso != 0].sort_values(key=abs, ascending=False)
for i, (var, coef) in enumerate(lasso_selected.items()):
    relevante = "âœ…" if var in feature_names[:n_relevant_features] else "âŒ"
    print(f"{i+1:2d}. {var}: {coef:.4f} {relevante}")

print("\\nğŸ“Š Resumen:")
print(f"âœ… Ridge identificÃ³ {np.sum(np.abs(coef_ridge_sorted.head(10).index.isin(feature_names[:n_relevant_features])))} variables relevantes en su top 10")
print(f"âœ… Lasso identificÃ³ {np.sum(lasso_selected.head(10).index.isin(feature_names[:n_relevant_features])))} variables relevantes en su top 10")""")
    
    # === CELDA 13: Tabla de resultados ===
    celda13 = nbf.v4.new_markdown_cell("""## ğŸ“Š Paso 6: Tabla de Resultados Comparativos

### Â¿Por quÃ© crear una tabla comparativa?

Una tabla nos permite ver de manera clara y organizada las diferencias entre Ridge y Lasso en tÃ©rminos de:

1. **Rendimiento predictivo**: Â¿CuÃ¡l modelo predice mejor?
2. **Interpretabilidad**: Â¿CuÃ¡l modelo es mÃ¡s fÃ¡cil de entender?
3. **SelecciÃ³n de variables**: Â¿CuÃ¡l modelo identifica mejor las variables importantes?

### ğŸ§  MÃ©tricas que vamos a comparar:

- **RMSE**: Error de predicciÃ³n (menor es mejor)
- **RÂ²**: Coeficiente de determinaciÃ³n (mÃ¡s cercano a 1 es mejor)
- **NÃºmero de variables**: CuÃ¡ntas variables usa cada modelo
- **Capacidad de selecciÃ³n**: QuÃ© tan bien identifica variables relevantes

### ğŸ¯ Preguntas que responderemos:

- Â¿CuÃ¡l modelo tiene mejor rendimiento predictivo?
- Â¿CuÃ¡l modelo es mÃ¡s interpretable?
- Â¿CuÃ¡l modelo identifica mejor las variables relevantes?
- Â¿CuÃ¡l modelo elimina mejor las variables irrelevantes?""")
    
    # === CELDA 14: CÃ³digo de tabla ===
    celda14 = nbf.v4.new_code_cell("""# ğŸ“Š Crear tabla de resultados comparativos
print("ğŸ“‹ Creando tabla comparativa de resultados...")

# Calcular mÃ©tricas adicionales para el anÃ¡lisis
ridge_relevant_identified = np.sum(ridge_model.coef_[:n_relevant_features] != 0)
ridge_irrelevant_eliminated = np.sum(ridge_model.coef_[n_relevant_features:] == 0)
lasso_relevant_identified = np.sum(lasso_model.coef_[:n_relevant_features] != 0)
lasso_irrelevant_eliminated = np.sum(lasso_model.coef_[n_relevant_features:] == 0)

# Calcular porcentajes
ridge_relevant_pct = ridge_relevant_identified / n_relevant_features * 100
ridge_irrelevant_pct = ridge_irrelevant_eliminated / n_irrelevant_features * 100
lasso_relevant_pct = lasso_relevant_identified / n_relevant_features * 100
lasso_irrelevant_pct = lasso_irrelevant_eliminated / n_irrelevant_features * 100

# Crear tabla de resultados
resultados = pd.DataFrame({
    'MÃ©trica': [
        'ğŸ’° RMSE (Error de PredicciÃ³n)', 
        'ğŸ“ˆ RÂ² (Coeficiente de DeterminaciÃ³n)',
        'ğŸ“Š NÃºmero de Variables Usadas',
        'âœ… Variables Relevantes Identificadas',
        'âŒ Variables Irrelevantes Eliminadas',
        'ğŸ¯ PrecisiÃ³n en SelecciÃ³n (%)',
        'ğŸ¯ Especificidad (%)'
    ],
    'Ridge': [
        f"${rmse_ridge:.2f}", 
        f"{r2_ridge:.4f}",
        f"{ridge_non_zero}/{len(ridge_model.coef_)} (100%)",
        f"{ridge_relevant_identified}/{n_relevant_features} ({ridge_relevant_pct:.1f}%)",
        f"{ridge_irrelevant_eliminated}/{n_irrelevant_features} ({ridge_irrelevant_pct:.1f}%)",
        f"{ridge_relevant_pct:.1f}%",
        f"{ridge_irrelevant_pct:.1f}%"
    ],
    'Lasso': [
        f"${rmse_lasso:.2f}", 
        f"{r2_lasso:.4f}",
        f"{lasso_non_zero}/{len(lasso_model.coef_)} ({lasso_non_zero/len(lasso_model.coef_)*100:.1f}%)",
        f"{lasso_relevant_identified}/{n_relevant_features} ({lasso_relevant_pct:.1f}%)",
        f"{lasso_irrelevant_eliminated}/{n_irrelevant_features} ({lasso_irrelevant_pct:.1f}%)",
        f"{lasso_relevant_pct:.1f}%",
        f"{lasso_irrelevant_pct:.1f}%"
    ]
})

# Mostrar tabla con formato mejorado
print("\\n" + "="*100)
print("ğŸ“Š TABLA DE RESULTADOS: RIDGE vs LASSO")
print("="*100)
print(resultados.to_string(index=False))
print("="*100)

# ğŸ“Š AnÃ¡lisis de la tabla
print("\\nğŸ“Š ANÃLISIS DE RESULTADOS:")

# Comparar rendimiento predictivo
if rmse_lasso < rmse_ridge:
    print(f"ğŸ† RENDIMIENTO PREDICTIVO: Lasso es mejor por ${rmse_ridge - rmse_lasso:.2f}")
elif rmse_ridge < rmse_lasso:
    print(f"ğŸ† RENDIMIENTO PREDICTIVO: Ridge es mejor por ${rmse_lasso - rmse_ridge:.2f}")
else:
    print("ğŸ† RENDIMIENTO PREDICTIVO: Ambos modelos tienen rendimiento similar")

# Comparar interpretabilidad
reduccion_variables = len(ridge_model.coef_) - lasso_non_zero
print(f"\\nğŸ“Š INTERPRETABILIDAD:")
print(f"   â€¢ Ridge usa todas las {len(ridge_model.coef_)} variables")
print(f"   â€¢ Lasso usa solo {lasso_non_zero} variables ({reduccion_variables} menos)")
print(f"   â€¢ Lasso eliminÃ³ {reduccion_variables/len(ridge_model.coef_)*100:.1f}% de las variables")

# Comparar capacidad de selecciÃ³n
print(f"\\nğŸ¯ CAPACIDAD DE SELECCIÃ“N:")
print(f"   â€¢ Ridge identificÃ³ {ridge_relevant_pct:.1f}% de variables relevantes")
print(f"   â€¢ Lasso identificÃ³ {lasso_relevant_pct:.1f}% de variables relevantes")
print(f"   â€¢ Ridge eliminÃ³ {ridge_irrelevant_pct:.1f}% de variables irrelevantes")
print(f"   â€¢ Lasso eliminÃ³ {lasso_irrelevant_pct:.1f}% de variables irrelevantes")

# Determinar el ganador en cada categorÃ­a
print(f"\\nğŸ† GANADORES POR CATEGORÃA:")
if rmse_lasso <= rmse_ridge:
    print("   ğŸ¥‡ Rendimiento Predictivo: Lasso")
else:
    print("   ğŸ¥‡ Rendimiento Predictivo: Ridge")

if lasso_relevant_pct >= ridge_relevant_pct:
    print("   ğŸ¥‡ IdentificaciÃ³n de Variables Relevantes: Lasso")
else:
    print("   ğŸ¥‡ IdentificaciÃ³n de Variables Relevantes: Ridge")

if lasso_irrelevant_pct >= ridge_irrelevant_pct:
    print("   ğŸ¥‡ EliminaciÃ³n de Variables Irrelevantes: Lasso")
else:
    print("   ğŸ¥‡ EliminaciÃ³n de Variables Irrelevantes: Ridge")

print("   ğŸ¥‡ Interpretabilidad: Lasso (menos variables = mÃ¡s simple)")""")
    
    # === CELDA 15: AnÃ¡lisis detallado ===
    celda15 = nbf.v4.new_markdown_cell("""## Paso 7: AnÃ¡lisis de la Capacidad de SelecciÃ³n de Variables""")
    
    # === CELDA 16: CÃ³digo de anÃ¡lisis ===
    celda16 = nbf.v4.new_code_cell("""# AnÃ¡lisis detallado de la selecciÃ³n de variables
print("\\n=== ANÃLISIS DE SELECCIÃ“N DE VARIABLES ===")

# Variables realmente relevantes (primeras 10)
variables_relevantes = feature_names[:n_relevant_features]
variables_irrelevantes = feature_names[n_relevant_features:]

# AnÃ¡lisis Ridge
ridge_relevant_coefs = ridge_model.coef_[:n_relevant_features]
ridge_irrelevant_coefs = ridge_model.coef_[n_relevant_features:]

print(f"\\nRIDGE:")
print(f"- Variables relevantes con coeficiente > 0.1: {np.sum(np.abs(ridge_relevant_coefs) > 0.1)}/{n_relevant_features}")
print(f"- Variables irrelevantes con coeficiente > 0.1: {np.sum(np.abs(ridge_irrelevant_coefs) > 0.1)}/{n_irrelevant_features}")
print(f"- Promedio |coef| variables relevantes: {np.mean(np.abs(ridge_relevant_coefs)):.4f}")
print(f"- Promedio |coef| variables irrelevantes: {np.mean(np.abs(ridge_irrelevant_coefs)):.4f}")

# AnÃ¡lisis Lasso
lasso_relevant_coefs = lasso_model.coef_[:n_relevant_features]
lasso_irrelevant_coefs = lasso_model.coef_[n_relevant_features:]

print(f"\\nLASSO:")
print(f"- Variables relevantes seleccionadas: {np.sum(lasso_relevant_coefs != 0)}/{n_relevant_features}")
print(f"- Variables irrelevantes eliminadas: {np.sum(lasso_irrelevant_coefs == 0)}/{n_irrelevant_features}")
print(f"- PrecisiÃ³n en selecciÃ³n: {np.sum(lasso_relevant_coefs != 0) / n_relevant_features:.2%}")
print(f"- Especificidad: {np.sum(lasso_irrelevant_coefs == 0) / n_irrelevant_features:.2%}")

# Mostrar quÃ© variables relevantes fueron identificadas por Lasso
print(f"\\nVariables relevantes identificadas por Lasso:")
for i, (var, coef) in enumerate(zip(variables_relevantes, lasso_relevant_coefs)):
    status = "âœ“" if coef != 0 else "âœ—"
    print(f"{status} {var}: {coef:.4f}")""")
    
    # === CELDA 17: VisualizaciÃ³n de evoluciÃ³n ===
    celda17 = nbf.v4.new_markdown_cell("""## Paso 8: VisualizaciÃ³n de la EvoluciÃ³n de Coeficientes""")
    
    # === CELDA 18: CÃ³digo de evoluciÃ³n ===
    celda18 = nbf.v4.new_code_cell("""# Visualizar cÃ³mo cambian los coeficientes con diferentes valores de alpha
alphas_ridge = np.logspace(-3, 3, 20)
alphas_lasso = np.logspace(-3, 1, 20)

coefs_ridge = []
coefs_lasso = []

for alpha in alphas_ridge:
    ridge_temp = Ridge(alpha=alpha)
    ridge_temp.fit(X_train_scaled, y_train)
    coefs_ridge.append(ridge_temp.coef_)

for alpha in alphas_lasso:
    lasso_temp = Lasso(alpha=alpha, max_iter=2000)
    lasso_temp.fit(X_train_scaled, y_train)
    coefs_lasso.append(lasso_temp.coef_)

coefs_ridge = np.array(coefs_ridge)
coefs_lasso = np.array(coefs_lasso)

# Crear grÃ¡ficos
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# Ridge
for i in range(n_total_features):
    color = 'red' if i < n_relevant_features else 'gray'
    alpha_val = 0.8 if i < n_relevant_features else 0.3
    ax1.plot(alphas_ridge, coefs_ridge[:, i], color=color, alpha=alpha_val)
ax1.set_xscale('log')
ax1.set_xlabel('Alpha (ParÃ¡metro de RegularizaciÃ³n)')
ax1.set_ylabel('Coeficientes')
ax1.set_title('EvoluciÃ³n de Coeficientes - Ridge')
ax1.grid(True, alpha=0.3)

# Lasso
for i in range(n_total_features):
    color = 'red' if i < n_relevant_features else 'gray'
    alpha_val = 0.8 if i < n_relevant_features else 0.3
    ax2.plot(alphas_lasso, coefs_lasso[:, i], color=color, alpha=alpha_val)
ax2.set_xscale('log')
ax2.set_xlabel('Alpha (ParÃ¡metro de RegularizaciÃ³n)')
ax2.set_ylabel('Coeficientes')
ax2.set_title('EvoluciÃ³n de Coeficientes - Lasso')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\\nObservaciones:")
print("â€¢ LÃ­neas rojas: Variables realmente relevantes")
print("â€¢ LÃ­neas grises: Variables irrelevantes")
print("â€¢ Ridge: Los coeficientes se hacen pequeÃ±os pero nunca llegan a cero")
print("â€¢ Lasso: Los coeficientes pueden llegar exactamente a cero")""")
    
    # === CELDA 19: Conclusiones ===
    celda19 = nbf.v4.new_markdown_cell("""## Paso 9: Conclusiones y Recomendaciones""")
    
    # === CELDA 20: CÃ³digo de conclusiones ===
    celda20 = nbf.v4.new_code_cell("""print("\\n" + "="*80)
print("CONCLUSIONES Y RECOMENDACIONES")
print("="*80)

# Comparar rendimiento predictivo
if rmse_lasso < rmse_ridge:
    mejor_prediccion = "Lasso"
    diferencia_rmse = rmse_ridge - rmse_lasso
    print(f"1. RENDIMIENTO PREDICTIVO: Lasso es mejor por ${diferencia_rmse:.2f}")
else:
    mejor_prediccion = "Ridge"
    diferencia_rmse = rmse_lasso - rmse_ridge
    print(f"1. RENDIMIENTO PREDICTIVO: Ridge es mejor por ${diferencia_rmse:.2f}")

# Comparar interpretabilidad
reduccion_variables = len(ridge_model.coef_) - lasso_non_zero
print(f"\\n2. INTERPRETABILIDAD:")
print(f"   â€¢ Ridge usa todas las {len(ridge_model.coef_)} variables")
print(f"   â€¢ Lasso usa solo {lasso_non_zero} variables ({reduccion_variables} menos)")
print(f"   â€¢ Lasso eliminÃ³ {reduccion_variables/len(ridge_model.coef_)*100:.1f}% de las variables")

# AnÃ¡lisis de selecciÃ³n correcta
precision_lasso = np.sum(lasso_relevant_coefs != 0) / n_relevant_features
especificidad_lasso = np.sum(lasso_irrelevant_coefs == 0) / n_irrelevant_features

print(f"\\n3. CAPACIDAD DE SELECCIÃ“N DE VARIABLES:")
print(f"   â€¢ PrecisiÃ³n (variables relevantes identificadas): {precision_lasso:.1%}")
print(f"   â€¢ Especificidad (variables irrelevantes eliminadas): {especificidad_lasso:.1%}")

# RecomendaciÃ³n final
print(f"\\n4. RECOMENDACIÃ“N FINAL:")
if precision_lasso > 0.7 and especificidad_lasso > 0.8:
    print("   âœ“ Lasso es la mejor opciÃ³n para este problema")
    print("   â€¢ Excelente capacidad de selecciÃ³n de variables")
    print("   â€¢ Modelo mÃ¡s interpretable y simple")
elif rmse_lasso < rmse_ridge * 1.05:  # Si Lasso no es mÃ¡s del 5% peor
    print("   âœ“ Lasso es recomendable")
    print("   â€¢ Rendimiento predictivo similar a Ridge")
    print("   â€¢ Ventaja en interpretabilidad")
else:
    print("   âš  Ridge podrÃ­a ser preferible")
    print("   â€¢ Mejor rendimiento predictivo")
    print("   â€¢ Considerar el trade-off con interpretabilidad")

print("\\n" + "="*80)""")
    
    # === CELDA 21: Resumen final ===
    celda21 = nbf.v4.new_markdown_cell("""## ğŸ“ Resumen de la Actividad

### ğŸ§  Lo que hemos aprendido:

#### 1. **Diferencias fundamentales entre Ridge y Lasso:**

| Aspecto | Ridge (L2) | Lasso (L1) |
|---------|------------|------------|
| **PenalizaciÃ³n** | Î²áµ¢Â² (cuadrado) | \|Î²áµ¢\| (valor absoluto) |
| **Coeficientes cero** | Nunca | Pueden ser cero |
| **SelecciÃ³n de variables** | No | SÃ­ |
| **Interpretabilidad** | Baja | Alta |

#### 2. **Capacidad de selecciÃ³n de variables:**
- **Lasso**: Puede identificar automÃ¡ticamente las variables mÃ¡s importantes
- **Ridge**: Mantiene todas las variables pero con pesos reducidos

#### 3. **Trade-offs importantes:**
- **Interpretabilidad vs. Rendimiento predictivo**
- **Simplicidad del modelo vs. Complejidad**
- **SelecciÃ³n de variables vs. Uso de toda la informaciÃ³n**

### ğŸ¯ Aplicaciones prÃ¡cticas:

#### **Usar Lasso cuando:**
- âœ… Tienes muchas variables y quieres identificar las mÃ¡s importantes
- âœ… La interpretabilidad es crucial
- âœ… Quieres un modelo mÃ¡s simple y fÃ¡cil de explicar
- âœ… Sospechas que muchas variables son irrelevantes

#### **Usar Ridge cuando:**
- âœ… Todas las variables podrÃ­an ser relevantes
- âœ… El rendimiento predictivo es la prioridad mÃ¡xima
- âœ… Quieres evitar la eliminaciÃ³n de variables potencialmente Ãºtiles
- âœ… Tienes correlaciÃ³n alta entre variables

### ğŸš€ PrÃ³ximos pasos sugeridos:

1. **ğŸ“Š Probar con datos reales**: Aplicar estos conceptos al dataset real de ingresos de PerÃº
2. **ğŸ”¬ Experimentar con Elastic Net**: CombinaciÃ³n de Ridge y Lasso
3. **ğŸŒ Aplicar a otros problemas**: Usar estos conceptos en otros problemas de regresiÃ³n
4. **ğŸ“ˆ Explorar mÃ¡s tÃ©cnicas**: Aprender sobre otras tÃ©cnicas de regularizaciÃ³n

### ğŸ’¡ Conceptos clave para recordar:

- **RegularizaciÃ³n**: TÃ©cnica para prevenir overfitting
- **PenalizaciÃ³n L1 vs L2**: Diferentes formas de regularizar
- **SelecciÃ³n de variables**: Capacidad de eliminar variables irrelevantes
- **ValidaciÃ³n cruzada**: Para encontrar el mejor parÃ¡metro de regularizaciÃ³n
- **Trade-offs**: Siempre hay compensaciones entre diferentes objetivos

### ğŸ‰ Â¡Felicidades!

Has completado exitosamente esta actividad prÃ¡ctica sobre Ridge vs Lasso. Ahora tienes una comprensiÃ³n sÃ³lida de:

- âœ… CÃ³mo funcionan las tÃ©cnicas de regularizaciÃ³n
- âœ… CuÃ¡ndo usar Ridge vs Lasso
- âœ… CÃ³mo interpretar los resultados
- âœ… CÃ³mo evaluar el rendimiento de los modelos

Â¡Sigue practicando y explorando mÃ¡s tÃ©cnicas de Machine Learning! ğŸš€""")
    
    # Agregar todas las celdas al notebook
    nb.cells = [celda1, celda2, celda3, celda4, celda5, celda6, celda7, celda8, 
                celda9, celda10, celda11, celda12, celda13, celda14, celda15, 
                celda16, celda17, celda18, celda19, celda20, celda21]
    
    return nb

if __name__ == "__main__":
    # Crear el notebook
    notebook = crear_notebook_ridge_lasso()
    
    # Guardar el notebook
    nbf.write(notebook, 'Capitulo_4/actividad.ipynb')
    
    print("âœ… Notebook creado exitosamente!")
    print("ğŸ“ Archivo guardado como: Capitulo_4/actividad.ipynb")
    print("ğŸš€ Puedes abrir el notebook en Jupyter o VS Code") 