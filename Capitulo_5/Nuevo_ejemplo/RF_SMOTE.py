# %% [markdown]
# # üå≥ Modelo de Machine Learning para Predecir la Pobreza Monetaria en Per√∫
# 
# ##  Objetivo de la Actividad
# En este notebook, construiremos, entrenaremos y evaluaremos un modelo de **Random Forest** para predecir si un hogar en Per√∫ caer√° en situaci√≥n de pobreza monetaria. Utilizaremos una base de datos sint√©tica que simula las caracter√≠sticas de los hogares peruanos.
# 
# ### ¬øPor qu√© Random Forest?
# El Random Forest (Bosque Aleatorio) es un modelo de *aprendizaje supervisado* ideal para este problema por varias razones:
# - **Versatilidad**: Funciona muy bien tanto con variables num√©ricas como categ√≥ricas.
# - **Robustez**: Es menos propenso al sobreajuste (overfitting) que un √∫nico √°rbol de decisi√≥n.
# - **Interpretabilidad**: Nos permite conocer qu√© variables son las m√°s importantes para predecir la pobreza.
# 
# ###  Hip√≥tesis a Validar:
# Esperamos que las variables m√°s influyentes para predecir la pobreza sean:
# 1.  **Ingreso y Gasto del Hogar**: La relaci√≥n directa con la capacidad econ√≥mica.
# 2.  **Nivel Educativo y A√±os de Estudio**: A mayor educaci√≥n, menor probabilidad de pobreza.
# 3.  **Tipo de Empleo**: El empleo formal protege contra la pobreza.
# 4.  **√Årea de Residencia**: La incidencia de pobreza suele ser mayor en zonas rurales.
# 
# ###  Conceptos Clave que Aprenderemos:
# - **Preprocesamiento de datos**: C√≥mo preparar variables categ√≥ricas y num√©ricas.
# - **Pipelines en Scikit-learn**: Para organizar nuestro flujo de trabajo de forma profesional.
# - **Entrenamiento de un clasificador**: C√≥mo ense√±arle al modelo a partir de los datos.
# - **M√©tricas de Evaluaci√≥n**: No solo la exactitud (accuracy), sino tambi√©n la **Precisi√≥n**, el **Recall** y la **Matriz de Confusi√≥n**, cruciales para problemas sociales.
# - **Importancia de Variables (Feature Importance)**: C√≥mo el modelo nos "explica" su decisi√≥n.
# 

# %% [markdown]
# ##  1. Definici√≥n del Problema y Preparaci√≥n Inicial

# %%
# Importamos las librer√≠as necesarias para nuestro an√°lisis

# Para manipulaci√≥n de datos
import pandas as pd
import numpy as np

# Para visualizaciones
import matplotlib.pyplot as plt
import seaborn as sns

# Para preprocesamiento y modelado con Scikit-Learn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# Para SMOTE (t√©cnica de sobremuestreo)
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline


# Para evaluar el modelo
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, RocCurveDisplay

# Configuraciones adicionales
import warnings
warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-whitegrid')

print("‚úÖ Librer√≠as importadas correctamente. ¬°Listos para empezar!")


# %% [markdown]
# ##  2. Preprocesamiento y Limpieza de Datos
# Este es el paso m√°s cr√≠tico en cualquier proyecto de Machine Learning.  Nuestro objetivo es transformar los datos crudos en un formato limpio y estructurado que el modelo pueda entender.
# 
# ### Pasos a seguir:
# 1.  **Cargar los datos**: Importar nuestro archivo `prediccion_pobreza_peru2.csv`.
# 2.  **Inspecci√≥n inicial**: Entender la estructura, tipos de datos y buscar posibles problemas (aunque nuestra base es sint√©tica y limpia).
# 3.  **Separar variables**: Dividir nuestro dataset en variables predictoras (`X`) y la variable objetivo (`y`).
# 4.  **Identificar tipos de variables**: Separar las columnas num√©ricas de las categ√≥ricas para aplicarles transformaciones diferentes.
# 

# %%
# 2.1 Cargar e Inspeccionar los Datos
df = pd.read_csv('prediccion_pobreza_peru2.csv')

print("Primeras 5 filas del dataset:")
display(df.head())

print("\nInformaci√≥n general del DataFrame:")
df.info()

print(f"\nEl dataset tiene {df.shape[0]} filas y {df.shape[1]} columnas.")

# Verificamos que no haya valores nulos (importante en un caso real)
print("\nConteo de valores nulos por columna:")
print(df.isnull().sum())


# %%
# 2.2 Separar variables predictoras (X) y objetivo (y)
X = df.drop('PobrezaMonetaria', axis=1)
y = df['PobrezaMonetaria']

print(f"Dimensiones de X (variables predictoras): {X.shape}")
print(f"Dimensiones de y (variable objetivo): {y.shape}")

# 2.3 Identificar columnas num√©ricas y categ√≥ricas
numerical_cols = X.select_dtypes(include=np.number).columns
categorical_cols = X.select_dtypes(include=['object', 'category']).columns

print(f"\nColumnas Num√©ricas ({len(numerical_cols)}): {list(numerical_cols)}")
print(f"\nColumnas Categ√≥ricas ({len(categorical_cols)}): {list(categorical_cols)}")


# %% [markdown]
# ## 3. Divisi√≥n de los Datos (Entrenamiento y Prueba)
# Para evaluar de manera honesta el rendimiento de nuestro modelo, debemos dividir nuestros datos en dos conjuntos:
# - **Conjunto de Entrenamiento (Training set)**: Usado para "ense√±ar" al modelo. Generalmente es el 70-80% de los datos.
# - **Conjunto de Prueba (Test set)**: Usado para evaluar qu√© tan bien generaliza el modelo a datos nuevos que nunca ha visto.
# 
# Usaremos el par√°metro `stratify=y` para asegurar que la proporci√≥n de hogares pobres y no pobres sea la misma en ambos conjuntos. Esto es crucial en problemas de clasificaci√≥n, especialmente si las clases est√°n desbalanceadas. 
# 

# %%
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.3,      # 30% de los datos para el conjunto de prueba
    random_state=42,    # Semilla para reproducibilidad
    stratify=y          # Mantener la proporci√≥n de la variable objetivo
)

print("Distribuci√≥n de la variable objetivo en el conjunto original:")
print(y.value_counts(normalize=True))

print("\nDistribuci√≥n en el conjunto de entrenamiento:")
print(y_train.value_counts(normalize=True))

print("\nDistribuci√≥n en el conjunto de prueba:")
print(y_test.value_counts(normalize=True))

print(f"\nTama√±o del conjunto de entrenamiento: {X_train.shape[0]} hogares")
print(f"Tama√±o del conjunto de prueba: {X_test.shape[0]} hogares")


# %% [markdown]
# ###  An√°lisis de la Divisi√≥n: Confirmando el Desbalance de Clases
# 
# Los resultados de la divisi√≥n de datos nos muestran algo fundamental sobre nuestro problema:
# 
# -   **Proporci√≥n de Clases:** En todos nuestros conjuntos (original, entrenamiento y prueba), la distribuci√≥n es constante: aproximadamente **70% de hogares no pobres (clase 0)** y **30% de hogares pobres (clase 1)**.
# 
# Esta distribuci√≥n confirma que estamos ante un problema de **desbalance de clases moderado**.
# 
# #### **¬øPor qu√© este 70/30 es tan importante?**
# 
# Aunque no es un desbalance extremo (como 99/1), una proporci√≥n 70/30 es m√°s que suficiente para **afectar negativamente las estimaciones de un modelo de machine learning** si no se trata adecuadamente.
# 
# 1.  **El Sesgo hacia la Mayor√≠a:** Por defecto, los algoritmos buscan minimizar el error total. Con un 70% de datos pertenecientes a la clase "No Pobre", el modelo tiene un fuerte incentivo para aprender a predecir esta clase mayoritaria, ya que as√≠ acierta la mayor√≠a de las veces. Puede volverse "perezoso" y no esforzarse lo suficiente en aprender los patrones complejos que identifican a la clase minoritaria (los hogares pobres).
# 
# 2.  **La Paradoja de la Exactitud:** Un modelo ingenuo que simplemente prediga "No Pobre" para todos los casos tendr√≠a una exactitud del 70%. A primera vista, esto podr√≠a parecer un buen resultado, pero en realidad el modelo ser√≠a completamente in√∫til para nuestro objetivo, que es identificar a quienes necesitan ayuda. Esto demuestra por qu√© la **exactitud (accuracy) es una m√©trica peligrosa y enga√±osa** en datasets desbalanceados.
# 
# 3.  **La Importancia de la M√©trica Correcta:** Dado este desbalance, nuestro enfoque no puede ser simplemente "acertar mucho". Debemos concentrarnos en nuestra capacidad para identificar correctamente a la clase minoritaria. Por eso, en los siguientes pasos, prestaremos especial atenci√≥n al **Recall**, que mide cu√°ntos de los hogares realmente pobres fuimos capaces de encontrar.
# 
# Haber confirmado esta distribuci√≥n 70/30 justifica plenamente las decisiones que tomaremos m√°s adelante:
# -   Utilizar m√©tricas como **Recall, Precisi√≥n y F1-Score** en lugar de solo la exactitud.
# -   Implementar t√©cnicas como el **ajuste de pesos (`class_weight='balanced'`)** para forzar al modelo a prestar la debida atenci√≥n a la poblaci√≥n pobre.

# %% [markdown]
# ##  4. Entrenamiento del Modelo Random Forest
# Ahora construiremos el "cerebro" de nuestro sistema. Para hacerlo de forma ordenada y profesional, usaremos **Pipelines**.
# 
# ### ¬øQu√© es un Pipeline?
# Un Pipeline de Scikit-learn encadena m√∫ltiples pasos de preprocesamiento y modelado en un solo objeto. Esto tiene grandes ventajas:
# - **C√≥digo m√°s limpio**: Evita tener que aplicar transformaciones paso a paso.
# - **Previene errores**: Asegura que apliquemos las mismas transformaciones a los datos de entrenamiento y de prueba.
# - **Facilita la automatizaci√≥n**: Simplifica la b√∫squeda de los mejores par√°metros (hiperpar√°metros).
# 
# ### Nuestro Pipeline contendr√°:
# 1.  **Un transformador para variables num√©ricas**: `StandardScaler` para estandarizarlas (media 0, desviaci√≥n 1).
# 2.  **Un transformador para variables categ√≥ricas**: `OneHotEncoder` para convertirlas a un formato num√©rico que el modelo entienda.
# 3.  **El modelo clasificador**: `RandomForestClassifier`.
# 

# %%
# Creamos el pipeline para las variables num√©ricas
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

# Creamos el pipeline para las variables categ√≥ricas
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore')) # 'ignore' para manejar categor√≠as en test que no estaban en train
])

# Combinamos los preprocesadores usando ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ],
    remainder='passthrough' # Mantiene columnas no especificadas (si las hubiera)
)

# Creamos el modelo de Random Forest sin class_weight ya que usaremos SMOTE
rf_model = RandomForestClassifier(random_state=42, n_estimators=100)

# Creamos el Pipeline final que une el preprocesador, SMOTE y el modelo
# Usamos ImbPipeline de imblearn para manejar correctamente SMOTE
pipeline_final = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smote', SMOTE(random_state=42)),  # SMOTE para balancear las clases
    ('classifier', rf_model)
])

# ¬°Entrenamos el modelo!
print("üöÄ Entrenando el modelo Random Forest...")
pipeline_final.fit(X_train, y_train)
print("‚úÖ ¬°Modelo entrenado exitosamente!")


# %% [markdown]
# #### **¬øComo opera SMOTE?**
# SMOTE (Synthetic Minority Over-sampling Technique) es una t√©cnica que modifica nuestros datos ANTES del entrenamiento:
# 1.  Identifica los ejemplos de la clase minoritaria (los "Pobres").
# 2.  Para cada ejemplo de la clase minoritaria, encuentra sus k vecinos m√°s cercanos (tambi√©n de la clase minoritaria).
# 3.  Crea nuevas muestras sint√©ticas interpolando entre el ejemplo original y sus vecinos.
# 4.  El resultado es un dataset balanceado con igual n√∫mero de ejemplos de ambas clases.
#
# A diferencia de `class_weight='balanced'` que solo ajusta los pesos durante el entrenamiento, SMOTE crea f√≠sicamente nuevos datos de entrenamiento. Esto puede mejorar el rendimiento del modelo al proporcionarle m√°s ejemplos para aprender los patrones de la clase minoritaria.

# %% [markdown]
# ##  5. Evaluaci√≥n del Modelo
# Entrenar un modelo no es suficiente. Necesitamos saber qu√© tan bueno es. Para un problema de clasificaci√≥n como este, la exactitud (accuracy) no lo es todo.
# 
# ### M√©tricas Clave:
# - **Matriz de Confusi√≥n**: Una tabla que nos muestra los aciertos y errores del modelo.
#   - **Verdaderos Positivos (TP)**: Predijo "Pobre" y acert√≥.
#   - **Verdaderos Negativos (TN)**: Predijo "No Pobre" y acert√≥.
#   - **Falsos Positivos (FP)**: Predijo "Pobre" pero era "No Pobre" (Error Tipo I).
#   - **Falsos Negativos (FN)**: Predijo "No Pobre" pero era "Pobre" (Error Tipo II). **¬°Este es el error m√°s costoso socialmente!**
# - **Precisi√≥n (Precision)**: De todos los que predijo como "Pobres", ¬øcu√°ntos lo eran realmente? `TP / (TP + FP)`
# - **Recall (Sensibilidad)**: De todos los que *eran* "Pobres", ¬øa cu√°ntos identificamos correctamente? `TP / (TP + FN)`. **¬°M√©trica crucial para este problema!**
# - **F1-Score**: La media arm√≥nica de Precisi√≥n y Recall. Un buen balance entre ambas.
# - **ROC-AUC Score**: Mide la capacidad del modelo para distinguir entre las dos clases. Un valor de 1 es perfecto, 0.5 es aleatorio.
# 

# %%
# Hacemos predicciones en el conjunto de prueba
y_pred = pipeline_final.predict(X_test)
y_pred_proba = pipeline_final.predict_proba(X_test)[:, 1] # Probabilidades para la clase positiva

# 1. Reporte de Clasificaci√≥n
print("="*60)
print("Classification Report")
print("="*60)
print(classification_report(y_test, y_pred, target_names=['No Pobre (0)', 'Pobre (1)']))

# 2. Accuracy y ROC-AUC
accuracy = accuracy_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_proba)
print(f"Accuracy (Exactitud): {accuracy:.4f}")
print(f"ROC-AUC Score: {roc_auc:.4f}")
print("="*60)

# 3. Matriz de Confusi√≥n
print("\nMatriz de Confusi√≥n:")
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Pred. No Pobre', 'Pred. Pobre'],
            yticklabels=['Real No Pobre', 'Real Pobre'])
plt.title('Matriz de Confusi√≥n', fontsize=16)
plt.ylabel('Clase Real')
plt.xlabel('Clase Predicha')

plt.savefig('1_matriz_confusion_base.png')

plt.show()




# %%
# 4. Curva ROC (Receiver Operating Characteristic)
# Esta curva nos muestra el rendimiento del clasificador en todos los umbrales de clasificaci√≥n.
# Un buen modelo se pega a la esquina superior izquierda.

print("Curva ROC:")
fig, ax = plt.subplots(figsize=(8, 6))
RocCurveDisplay.from_estimator(pipeline_final, X_test, y_test, ax=ax)
ax.plot([0, 1], [0, 1], linestyle='--', color='r', label='Clasificador Aleatorio')
ax.set_title('Curva ROC', fontsize=16)
plt.legend()

plt.savefig('2_curva_roc_base.png')


plt.show()


# %% [markdown]
# ### Diagn√≥stico
# 
# Al analizar los resultados del modelo base, salta a la vista un problema cr√≠tico. Aunque la exactitud general es del **71.7%**, esta cifra es enga√±osa. El verdadero indicador de rendimiento para nuestro objetivo es el **`recall` para la clase "Pobre"**, que es de un alarmante **0.16 (16%)**.
# 
# **¬øQu√© significa esto en la pr√°ctica?**
# 
# Nuestro modelo actual solo est√° identificando correctamente a 16 de cada 100 hogares que realmente est√°n en situaci√≥n de pobreza. La matriz de confusi√≥n lo confirma con **152 Falsos Negativos**: 152 familias pobres que nuestro sistema no detectar√≠a.
# 
# Este comportamiento se debe a que el modelo, para minimizar su error total, ha aprendido a ser muy bueno prediciendo la clase mayoritaria ("No Pobre"), pero a costa de ignorar a la minor√≠a. Para un problema con un alto costo social, este resultado no es aceptable.
# 
# ### ¬øC√≥mo Mejorar la Identificaci√≥n de Hogares Pobres?
# 
# Debemos "forzar" al modelo a ser m√°s sensible a la clase minoritaria. Para ello, realizaremos un **ajuste de hiperpar√°metros**.
# 
# Usaremos una t√©cnica llamada **`GridSearchCV`** (B√∫squeda en Rejilla con Validaci√≥n Cruzada) para encontrar la combinaci√≥n √≥ptima de hiperpar√°metros. Lo m√°s importante es que le daremos una instrucci√≥n espec√≠fica:
# 
# > **El objetivo no es maximizar la exactitud general, sino maximizar el `recall` para la clase "Pobre".**
# 
# De esta manera, `GridSearchCV` buscar√° la configuraci√≥n que mejor identifique a los hogares pobres, incluso si eso implica cometer m√°s errores con la clase no pobre. Es un intercambio que estamos dispuestos a hacer para cumplir nuestro objetivo principal.
# 

# %%
# 1. DEFINIR EL DICCIONARIO DE HIPERPAR√ÅMETROS (LA "REJILLA")
# Este diccionario contiene las "perillas" del modelo que queremos ajustar y los valores a probar para cada una.
param_grid = {
    # 'classifier__' le dice al pipeline que este ajuste es para el paso llamado 'classifier'.
    
    # n_estimators: El n√∫mero de √°rboles en el bosque.
    # Probaremos con m√°s √°rboles para mejor rendimiento.
    'classifier__n_estimators': [100, 200, 300],
    
    # max_depth: La profundidad m√°xima de cada √°rbol.
    # Probaremos √°rboles m√°s simples (10), m√°s complejos (20) y sin l√≠mite.
    'classifier__max_depth': [10, 20, None],
    
    # min_samples_leaf: El n√∫mero m√≠nimo de muestras en una hoja final.
    # Ayuda a prevenir que el modelo cree reglas demasiado espec√≠ficas (sobreajuste).
    'classifier__min_samples_leaf': [1, 2, 4],
    
    # smote__k_neighbors: N√∫mero de vecinos m√°s cercanos que SMOTE usar√° para crear muestras sint√©ticas
    'smote__k_neighbors': [3, 5, 7]
}

# 2. CONFIGURAR EL BUSCADOR INTELIGENTE: GridSearchCV
# GridSearchCV probar√° todas las combinaciones de la rejilla anterior.
grid_search = GridSearchCV(
    # estimator: El modelo o pipeline base que se va a optimizar.
    estimator=pipeline_final,
    
    # param_grid: El diccionario con los par√°metros a probar.
    param_grid=param_grid,
    
    # scoring: Le decimos que el objetivo es encontrar
    # el modelo con el RECALL m√°s alto para la clase positiva (1).
    scoring='recall',
    
    # cv (Cross-Validation): N√∫mero de pliegues para la validaci√≥n cruzada.
    # cv=3 significa que dividir√° los datos de entrenamiento en 3, entrenar√° en 2 y probar√° en 1,
    # repitiendo el proceso 3 veces para asegurar un resultado estable.
    cv=3,
    
    # n_jobs: N√∫mero de n√∫cleos de CPU a utilizar. -1 significa "usa todos los disponibles" para
    # acelerar el proceso de entrenamiento de m√∫ltiples modelos en paralelo.
    n_jobs=-1,
    
    # verbose: Muestra mensajes de progreso durante la b√∫squeda.
    verbose=1
)

# 3. EJECUTAR LA B√öSQUEDA
# La funci√≥n .fit() inicia el proceso. GridSearchCV entrenar√° y evaluar√°
# 3 * 3 * 3 * 3 = 81 combinaciones, cada una con 3 pliegues de validaci√≥n cruzada.
# En total, se entrenan 243 modelos para encontrar al ganador.
# SMOTE a√±ade complejidad, esto puede tardar m√°s tiempo que la versi√≥n anterior.
grid_search.fit(X_train, y_train)

# 4. MOSTRAR LOS RESULTADOS
print("\n‚úÖ B√∫squeda completada.")
# El atributo .best_params_ es un diccionario que contiene la combinaci√≥n
# de hiperpar√°metros que logr√≥ el 'recall' m√°s alto durante la b√∫squeda.
print("La mejor configuraci√≥n de hiperpar√°metros es:")
print(grid_search.best_params_)

# %% [markdown]
# ### Evaluaci√≥n Final: Modelo Optimizado

# %%
# Extraemos el mejor modelo encontrado por GridSearchCV
best_model = grid_search.best_estimator_

# Hacemos predicciones con este nuevo modelo
y_pred_best = best_model.predict(X_test)

# Evaluamos el rendimiento del modelo optimizado
print("\n" + "="*60)
print("Rendimiento del Modelo Optimizado")
print("="*60)
print(classification_report(y_test, y_pred_best, target_names=['No Pobre (0)', 'Pobre (1)']))

# Visualizamos la nueva matriz de confusi√≥n
cm_best = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_best, annot=True, fmt='d', cmap='Greens', 
            xticklabels=['Pred. No Pobre', 'Pred. Pobre'],
            yticklabels=['Real No Pobre', 'Real Pobre'])
plt.title('Matriz de Confusi√≥n - Modelo Optimizado', fontsize=16)
plt.ylabel('Clase Real')
plt.xlabel('Clase Predicha')

plt.savefig('3_matriz_confusion_optimizado.png')
plt.show()

# %%
#Curva ROC

fig, ax = plt.subplots(figsize=(8, 7))

# Graficar la Curva ROC para el modelo optimizado ('best_model')
RocCurveDisplay.from_estimator(
    best_model,
    X_test,
    y_test,
    ax=ax,
    name='Modelo Optimizado',
    color='darkorange', # Un color que destaque
    linewidth=2
)

ax.plot([0, 1], [0, 1], linestyle='--', color='navy', label='Clasificador Aleatorio')

ax.set_title('Curva ROC del Modelo Optimizado', fontsize=16)
ax.set_xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
ax.set_ylabel('Tasa de Verdaderos Positivos (Recall)')

ax.legend(loc='lower right')
ax.grid(True)

plt.savefig('4_curva_roc_optimizado.png')
plt.show()


# %% [markdown]
# ### Conclusi√≥n
# La optimizaci√≥n ha sido un √©xito. Al instruir a `GridSearchCV` para que maximizara el **`recall`**, logramos transformar un modelo con una exactitud enga√±osa en una herramienta **√∫til y alineada con el objetivo del proyecto**.
# 
# El nuevo modelo identifica a un porcentaje mucho mayor de los hogares pobres (alto `recall`), a costa de una menor `precisi√≥n`, que es exactamente el intercambio que busc√°bamos. Esto demuestra la importancia de no solo entrenar un modelo, sino de **evaluarlo cr√≠ticamente y optimizarlo para la m√©trica que realmente importa**

# %% [markdown]
# ##  6. Interpretaci√≥n y Ajuste del Modelo
# Una de las mayores ventajas de los modelos basados en √°rboles como Random Forest es que podemos "preguntarles" qu√© variables consideraron m√°s importantes para tomar sus decisiones.
# 
# ### Importancia de Variables (Feature Importance)
# El modelo calcula la importancia de cada variable midiendo cu√°nto contribuye a reducir la "impureza" (o el desorden) en los nodos de los √°rboles. Una variable que separa muy bien a los hogares pobres de los no pobres tendr√° una alta importancia.
# 
# A continuaci√≥n, extraeremos estas puntuaciones y las visualizaremos para validar nuestra hip√≥tesis inicial.
# 

# %%
# Extraer los componentes del mejor modelo encontrado por GridSearchCV
preprocessor_best = best_model.named_steps['preprocessor']
classifier_best = best_model.named_steps['classifier']

# Obtener los nombres de todas las caracter√≠sticas despu√©s del preprocesamiento
try:
    ohe_feature_names = preprocessor_best.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_cols)
except AttributeError:
    ohe_feature_names = preprocessor_best.named_transformers_['cat']['onehot'].get_feature_names(categorical_cols)

all_feature_names = np.concatenate([numerical_cols, ohe_feature_names])

# Obtener las puntuaciones de importancia del clasificador optimizado
importances = classifier_best.feature_importances_

# Crear un DataFrame para ordenar y visualizar las importancias
feature_importance_df = pd.DataFrame({
    'feature': all_feature_names,
    'importance': importances
}).sort_values('importance', ascending=False)

# Visualizar las 15 variables m√°s importantes
plt.figure(figsize=(12, 10))
sns.barplot(x='importance', y='feature', data=feature_importance_df.head(15), palette='plasma')
plt.title('Top 15 Variables m√°s Importantes (Modelo Optimizado)', fontsize=16)
plt.xlabel('Puntuaci√≥n de Importancia')
plt.ylabel('Variable')


plt.savefig('5_importancia_variables.png')
plt.show()

# Mostrar el top 10 en una tabla
print("\nTop 10 variables m√°s importantes:")
display(feature_importance_df.head(10))

# %% [markdown]
# 
# ##  7. Conclusi√≥n General del Ejercicio
# 
# Este ejercicio pr√°ctico nos ha llevado a trav√©s del ciclo de vida completo de un proyecto de Machine Learning: desde la formulaci√≥n de una hip√≥tesis hasta la construcci√≥n, evaluaci√≥n cr√≠tica y optimizaci√≥n de un modelo predictivo. El objetivo no era solo crear un modelo, sino crear un modelo **√∫til y alineado con un objetivo social**: identificar a los hogares en situaci√≥n de pobreza.
# 
# ### Verificaci√≥n de la Hip√≥tesis Inicial
# 
# Al comienzo de la actividad, planteamos la hip√≥tesis de que las variables m√°s influyentes para predecir la pobreza estar√≠an relacionadas con la capacidad econ√≥mica, la educaci√≥n, el empleo y la geograf√≠a. Analizando el gr√°fico de **"Top 15 Variables m√°s Importantes (Modelo Optimizado)"**, podemos validar esta hip√≥tesis.
# 
# -   **Hip√≥tesis 1: Ingreso y Gasto del Hogar.** **CONFIRMADA.** Las dos variables m√°s importantes, por un amplio margen, son `IngresoMensualHogar` y `GastoMensualHogar`. Esto confirma que la capacidad econ√≥mica directa es el predictor m√°s fuerte.
# 
# -   **Hip√≥tesis 2: Nivel Educativo y A√±os de Estudio.** **CONFIRMADA.** `AniosEstudioJefeHogar` aparece en el top 5, y las categor√≠as de `NivelEducativoJefeHogar` (Secundaria y Primaria) tambi√©n est√°n entre las 15 primeras, validando el rol crucial de la educaci√≥n.
# 
# -   **Hip√≥tesis 3: Tipo de Empleo.** **CONFIRMADA.** La variable `TipoEmpleo_Formal` se encuentra entre las 10 m√°s importantes, lo que demuestra que tener un empleo formal es un factor protector significativo contra la pobreza.
# 
# -   **Hip√≥teses 4: √Årea de Residencia.** **CONFIRMADA.** Variables como `Region_Costa`, `AreaResidencia_Rural` y `AreaResidencia_Urbana` tienen una importancia notable, lo que ratifica que la geograf√≠a es un factor estructural determinante.
# 
# Adem√°s, el modelo nos ha revelado otros factores de gran importancia que no estaban en nuestra hip√≥tesis inicial, como el `RatioDependencia`, la `EdadJefeHogar` y el n√∫mero de `MiembrosHogar`, enriqueciendo nuestro entendimiento del fen√≥meno.
# 
# ### Balance de Hallazgos: El Triunfo del `Recall` sobre la Exactitud
# 
# El hallazgo m√°s importante de este ejercicio es la demostraci√≥n pr√°ctica del **trade-off entre Precisi√≥n y Recall**.
# 
# -   **Modelo Base:** Nuestro primer modelo ten√≠a una exactitud enga√±osa del 72%. Sin embargo, su **matriz de confusi√≥n** identific√≥ a **30** hogares pobres, dejando a **152** sin detectar (Falsos Negativos). Su curva ROC, con un AUC de 0.66, mostraba un rendimiento apenas superior al azar.
# 
# -   **Modelo Optimizado:** Tras enfocar la optimizaci√≥n con `GridSearchCV` en maximizar el **`recall`**, el comportamiento del modelo cambi√≥ radicalmente. La nueva **matriz de confusi√≥n** muestra que ahora identificamos a **139** hogares pobres, **reduciendo los casos no detectados de 152 a solo 43**.
# 
# Este logro vino con un costo calculado: el n√∫mero de Falsos Positivos (hogares no pobres clasificados incorrectamente como pobres) aument√≥ de 18 a 224. Sin embargo, este es un intercambio aceptable y deseable. **Es preferible investigar 224 casos que resultan no necesitar ayuda (un costo administrativo) que dejar sin apoyo a 109 familias adicionales que s√≠ lo necesitan (un alto costo social).**
# 
# La mejora tambi√©n es visible en la **Curva ROC**, que se ha desplazado hacia la esquina superior izquierda, y el **AUC ha aumentado a 0.68**, confirmando que el modelo optimizado es un clasificador superior en general.
# 
# ### Aprendizajes Clave
# 
# 1.  **La M√©trica lo es Todo:** La elecci√≥n de la m√©trica de evaluaci√≥n (`recall` en nuestro caso) debe estar alineada con el objetivo del problema, no con la simple exactitud.
# 2.  **La Exactitud es Peligrosa:** En problemas con desbalance de clases, la exactitud puede ocultar un rendimiento deficiente.
# 3.  **La Optimizaci√≥n Funciona:** `GridSearchCV` es una herramienta poderosa para automatizar la b√∫squeda del mejor modelo para una tarea espec√≠fica.
# 4.  **La Interpretabilidad Valida:** Analizar la importancia de las variables nos permite confirmar que el modelo ha aprendido patrones l√≥gicos y coherentes con la realidad.
# 
# 


