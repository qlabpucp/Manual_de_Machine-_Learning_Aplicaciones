{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a2bd1c",
   "metadata": {},
   "source": [
    "\n",
    "# Modelo Random Forest: Clasificaci√≥n de Nivel de Contagios\n",
    "## Paso 1: Definici√≥n del Problema y Preparaci√≥n Inicial\n",
    "\n",
    "### üéØ Objetivo de la Actividad\n",
    "Establecer las bases del proyecto: cargar librer√≠as, importar datos, realizar una exploraci√≥n inicial y crear nuestra variable objetivo para la clasificaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705155f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente.\")\n",
    "\n",
    "nombre_archivo = 'merge_RENAMU_GASTO_V.dta'\n",
    "try:\n",
    "    df = pd.read_stata(nombre_archivo)\n",
    "    print(f\"‚úÖ Base de datos '{nombre_archivo}' cargada: {df.shape[0]} filas y {df.shape[1]} columnas.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: No se pudo encontrar el archivo '{nombre_archivo}'.\")\n",
    "\n",
    "mediana_contagiados = df['contagiados'].median()\n",
    "df['nivel_contagios'] = df['contagiados'].apply(lambda x: 'ALTO' if x > mediana_contagiados else 'BAJO')\n",
    "print(\"‚úÖ Variable objetivo 'nivel_contagios' creada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a07b72",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 2: Preprocesamiento y Limpieza de Datos\n",
    "\n",
    "### üéØ Objetivo de la Actividad\n",
    "Preparar todas las variables del dataset para que sean aptas para el modelo, manejando valores faltantes, corrigiendo datos an√≥malos y asegurando un formato num√©rico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa93462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Eliminar columnas no informativas o de fuga de datos\n",
    "cols_to_drop = [\n",
    "    'UBIGEO', 'DEPARTAMENTO', 'PROVINCIA', 'DISTRITO', 'VFI_P66', \n",
    "    'VFI_P67', 'VFI_P68', '_merge', 'P67_11_O', 'P68_8_O', 'contagiados'\n",
    "]\n",
    "df_clean = df_clean.drop(columns=cols_to_drop)\n",
    "\n",
    "# 2. Corregir y transformar variables\n",
    "df_clean.loc[df_clean['MONTO_GIRADO'] < 0, 'MONTO_GIRADO'] = 0\n",
    "df_clean[['mes', 'year']] = df_clean[['mes', 'year']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 3. Imputar valores faltantes\n",
    "p_cols = [col for col in df_clean.columns if col.startswith('P')]\n",
    "df_clean[p_cols] = df_clean[p_cols].fillna(0)\n",
    "\n",
    "# 4. Estandarizar codificaci√≥n binaria\n",
    "p66_recode_2_to_0 = ['P66_1', 'P66_2', 'P66_3', 'P66_4', 'P66_5', 'P66_6', 'P66_7', 'P66_8', 'P66_9', 'P66_10']\n",
    "for col in p66_recode_2_to_0:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].replace(2, 0)\n",
    "\n",
    "p_recode_gt0_to_1 = [col for col in df_clean.columns if col.startswith(('P67_', 'P68_'))]\n",
    "for col in p_recode_gt0_to_1:\n",
    "    df_clean[col] = df_clean[col].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# 5. Definir X e y\n",
    "y = df_clean['nivel_contagios'].apply(lambda nivel: 1 if nivel == 'ALTO' else 0)\n",
    "X = df_clean.drop(columns=['nivel_contagios'])\n",
    "\n",
    "print(\"‚úÖ Preprocesamiento completado.\")\n",
    "print(f\"Forma de X (predictoras): {X.shape}\")\n",
    "print(f\"Forma de y (objetivo): {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc48ca",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 3: Divisi√≥n de los Datos (Entrenamiento y Prueba)\n",
    "\n",
    "### üéØ Objetivo de la Actividad\n",
    "Dividir nuestro conjunto de datos en dos subconjuntos: uno para entrenar el modelo y otro para evaluarlo de manera imparcial.\n",
    "\n",
    "### ¬øPor qu√© es crucial esta divisi√≥n?\n",
    "- **Conjunto de Entrenamiento (Training Set)**: El modelo \"aprende\" los patrones y relaciones de estos datos. T√≠picamente, constituye el 70-80% del total.\n",
    "- **Conjunto de Prueba (Test Set)**: Estos datos son \"nuevos\" para el modelo. Se usan para evaluar qu√© tan bien generaliza sus aprendizajes a datos que nunca ha visto. Esto nos da una medida realista de su rendimiento.\n",
    "\n",
    "### üß† Conceptos Clave:\n",
    "- **`train_test_split`**: La funci√≥n de `scikit-learn` que realiza esta divisi√≥n.\n",
    "- **`test_size`**: Define el porcentaje de datos que se destinar√° al conjunto de prueba (e.g., `0.2` para un 20%).\n",
    "- **`random_state`**: Fija una \"semilla\" para la aleatoriedad, asegurando que la divisi√≥n sea siempre la misma cada vez que se ejecuta el c√≥digo. Esto es vital para la **reproducibilidad**.\n",
    "- **`stratify`**: Asegura que la proporci√≥n de clases (ej. \"ALTO\" vs \"BAJO\") sea la misma tanto en el conjunto de entrenamiento como en el de prueba. Es fundamental en problemas de clasificaci√≥n para evitar sesgos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb9fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividir los datos: 80% para entrenamiento, 20% para prueba.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Datos divididos exitosamente.\")\n",
    "print(f\"Tama√±o del conjunto de entrenamiento (X_train): {X_train.shape}\")\n",
    "print(f\"Tama√±o del conjunto de prueba (X_test):      {X_test.shape}\")\n",
    "print(f\"Proporci√≥n de clase 'ALTO' en y_train: {y_train.mean():.2f}\")\n",
    "print(f\"Proporci√≥n de clase 'ALTO' en y_test:  {y_test.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d597ed",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 4: Entrenamiento del Modelo Random Forest\n",
    "\n",
    "### üéØ Objetivo de la Actividad\n",
    "Instanciar y entrenar nuestro modelo de clasificaci√≥n usando el conjunto de entrenamiento.\n",
    "\n",
    "### ¬øQu√© es un Random Forest?\n",
    "Un **Random Forest** (Bosque Aleatorio) es un modelo de *aprendizaje de conjunto* (ensemble learning). Funciona construyendo una multitud de **√°rboles de decisi√≥n** durante el entrenamiento y emitiendo la clase que es la moda de las clases (clasificaci√≥n) o la predicci√≥n media (regresi√≥n) de los √°rboles individuales.\n",
    "\n",
    "### üß† Conceptos Clave:\n",
    "- **`RandomForestClassifier`**: La clase de `scikit-learn` que implementa el algoritmo.\n",
    "- **`n_estimators`**: El n√∫mero de √°rboles que se construir√°n en el bosque. Un n√∫mero mayor generalmente mejora el rendimiento, pero tambi√©n aumenta el costo computacional. `100` es un buen punto de partida.\n",
    "- **`random_state`**: Al igual que antes, garantiza la reproducibilidad del modelo.\n",
    "- **`fit(X_train, y_train)`**: El m√©todo que \"entrena\" el modelo, encontrando los patrones en los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a24df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Crear una instancia del clasificador Random Forest.\n",
    "#    n_jobs=-1 utiliza todos los n√∫cleos de CPU disponibles para acelerar el entrenamiento.\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 2. Entrenar el modelo con los datos de entrenamiento.\n",
    "print(\"üöÄ Entrenando el modelo Random Forest...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Modelo entrenado exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63822b09",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 5: Evaluaci√≥n del Modelo\n",
    "\n",
    "### üéØ Objetivo de la Actividad\n",
    "Evaluar el rendimiento de nuestro modelo entrenado usando el conjunto de prueba, que contiene datos que el modelo no ha visto antes.\n",
    "\n",
    "### M√©tricas Clave de Evaluaci√≥n:\n",
    "1.  **Matriz de Confusi√≥n**: Una tabla que muestra el rendimiento del modelo. Nos dice cu√°ntos casos fueron clasificados correctamente y cu√°ntos incorrectamente.\n",
    "    - **Verdaderos Positivos (TP)**: Predijo \"ALTO\" y era \"ALTO\".\n",
    "    - **Verdaderos Negativos (TN)**: Predijo \"BAJO\" y era \"BAJO\".\n",
    "    - **Falsos Positivos (FP)**: Predijo \"ALTO\" pero era \"BAJO\" (Error Tipo I).\n",
    "    - **Falsos Negativos (FN)**: Predijo \"BAJO\" pero era \"ALTO\" (Error Tipo II).\n",
    "\n",
    "2.  **Reporte de Clasificaci√≥n**:\n",
    "    - **Accuracy (Exactitud)**: Porcentaje total de predicciones correctas. `(TP + TN) / Total`.\n",
    "    - **Precision (Precisi√≥n)**: De todos los que predijo como \"ALTO\", ¬øcu√°ntos acert√≥? `TP / (TP + FP)`.\n",
    "    - **Recall (Sensibilidad)**: De todos los que realmente eran \"ALTO\", ¬øa cu√°ntos identific√≥? `TP / (TP + FN)`.\n",
    "    - **F1-Score**: La media arm√≥nica de Precisi√≥n y Recall. Es una m√©trica balanceada muy √∫til.\n",
    "\n",
    "3.  **Curva ROC y AUC**:\n",
    "    - **Curva ROC**: Visualiza la capacidad de un clasificador para distinguir entre clases. Un buen modelo tiene una curva que se acerca a la esquina superior izquierda.\n",
    "    - **AUC (Area Under the Curve)**: El √°rea bajo la curva ROC. Un valor de 1.0 representa un modelo perfecto, mientras que 0.5 representa un modelo que no es mejor que el azar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Hacer predicciones sobre el conjunto de prueba.\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 2. Calcular y mostrar la Matriz de Confusi√≥n.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Pred. BAJO', 'Pred. ALTO'], \n",
    "            yticklabels=['Real BAJO', 'Real ALTO'])\n",
    "plt.title('Matriz de Confusi√≥n', fontsize=16)\n",
    "plt.ylabel('Clase Real')\n",
    "plt.xlabel('Clase Predicha')\n",
    "plt.show()\n",
    "\n",
    "# 3. Imprimir el Reporte de Clasificaci√≥n.\n",
    "print(\"=\"*60)\n",
    "print(\"Reporte de Clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAJO (0)', 'ALTO (1)']))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 4. Calcular y mostrar la Curva ROC y el AUC.\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC (Receiver Operating Characteristic)', fontsize=16)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da05fc",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 6: Interpretaci√≥n del Modelo\n",
    "\n",
    "### üéØ Objetivo de la Actividad\n",
    "Entender qu√© variables fueron las m√°s importantes para las predicciones del modelo. Un modelo no es solo una \"caja negra\"; Random Forest nos permite inspeccionar su l√≥gica interna.\n",
    "\n",
    "### Importancia de las Caracter√≠sticas (Feature Importance)\n",
    "El algoritmo de Random Forest puede calcular una puntuaci√≥n para cada variable predictora, indicando su contribuci√≥n relativa a la reducci√≥n de la impureza (o mejora de la precisi√≥n) en los √°rboles del bosque.\n",
    "\n",
    "Una puntuaci√≥n m√°s alta significa que la variable fue m√°s decisiva para separar las clases \"ALTO\" y \"BAJO\".\n",
    "\n",
    "**¬øPara qu√© sirve esto?**\n",
    "- **Entender el fen√≥meno**: Nos ayuda a comprender qu√© factores est√°n m√°s asociados con un alto nivel de contagios.\n",
    "- **Selecci√≥n de variables**: Podr√≠amos decidir construir un modelo m√°s simple usando solo las variables m√°s importantes.\n",
    "- **Comunicaci√≥n**: Es una forma efectiva de explicar los resultados del modelo a partes interesadas no t√©cnicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Obtener la importancia de cada caracter√≠stica desde el modelo entrenado.\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# 2. Crear un DataFrame para facilitar la visualizaci√≥n.\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# 3. Ordenar el DataFrame por importancia de forma descendente.\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 4. Visualizar las 20 caracter√≠sticas m√°s importantes.\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20), palette='viridis')\n",
    "plt.title('Top 20 Variables m√°s Importantes', fontsize=16)\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Variable')\n",
    "plt.grid(True, axis='x')\n",
    "plt.show()\n",
    "\n",
    "# Imprimir el top 10 para referencia\n",
    "print(\"=\"*60)\n",
    "print(\"Top 10 Variables m√°s Importantes:\")\n",
    "print(feature_importance_df.head(10).to_string(index=False))\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
