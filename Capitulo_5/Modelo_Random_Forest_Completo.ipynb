{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a2bd1c",
   "metadata": {},
   "source": [
    "\n",
    "# Modelo Random Forest: Clasificación de Nivel de Contagios\n",
    "## Paso 1: Definición del Problema y Preparación Inicial\n",
    "\n",
    "### 🎯 Objetivo de la Actividad\n",
    "Establecer las bases del proyecto: cargar librerías, importar datos, realizar una exploración inicial y crear nuestra variable objetivo para la clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705155f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Librerías importadas correctamente.\n",
      "✅ Base de datos 'merge_RENAMU_GASTO_V.dta' cargada: 14730 filas y 58 columnas.\n",
      "✅ Variable objetivo 'nivel_contagios' creada.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\n",
    "\n",
    "print(\"✅ Librerías importadas correctamente.\")\n",
    "\n",
    "nombre_archivo = 'merge_RENAMU_GASTO_V.dta'\n",
    "try:\n",
    "    df = pd.read_stata(nombre_archivo)\n",
    "    print(f\"✅ Base de datos '{nombre_archivo}' cargada: {df.shape[0]} filas y {df.shape[1]} columnas.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: No se pudo encontrar el archivo '{nombre_archivo}'.\")\n",
    "\n",
    "mediana_contagiados = df['contagiados'].median()\n",
    "df['nivel_contagios'] = df['contagiados'].apply(lambda x: 'ALTO' if x > mediana_contagiados else 'BAJO')\n",
    "print(\"✅ Variable objetivo 'nivel_contagios' creada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a07b72",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 2: Preprocesamiento y Limpieza de Datos\n",
    "\n",
    "### 🎯 Objetivo de la Actividad\n",
    "Preparar todas las variables del dataset para que sean aptas para el modelo, manejando valores faltantes, corrigiendo datos anómalos y asegurando un formato numérico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa93462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Eliminar columnas no informativas o de fuga de datos\n",
    "cols_to_drop = [\n",
    "    'UBIGEO', 'DEPARTAMENTO', 'PROVINCIA', 'DISTRITO', 'VFI_P66', \n",
    "    'VFI_P67', 'VFI_P68', '_merge', 'P67_11_O', 'P68_8_O', 'contagiados'\n",
    "]\n",
    "df_clean = df_clean.drop(columns=cols_to_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115a6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Corregir y transformar variables\n",
    "df_clean.loc[df_clean['MONTO_GIRADO'] < 0, 'MONTO_GIRADO'] = 0\n",
    "df_clean[['mes', 'year']] = df_clean[['mes', 'year']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fbbb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocesamiento completado.\n",
      "Forma de X (predictoras): (14730, 47)\n",
      "Forma de y (objetivo): (14730,)\n"
     ]
    }
   ],
   "source": [
    "# 5. Definir X e y\n",
    "y = df_clean['nivel_contagios'].apply(lambda nivel: 1 if nivel == 'ALTO' else 0)\n",
    "X = df_clean.drop(columns=['nivel_contagios'])\n",
    "\n",
    "print(\"✅ Preprocesamiento completado.\")\n",
    "print(f\"Forma de X (predictoras): {X.shape}\")\n",
    "print(f\"Forma de y (objetivo): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc48ca",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 3: División de los Datos (Entrenamiento y Prueba)\n",
    "\n",
    "### 🎯 Objetivo de la Actividad\n",
    "Dividir nuestro conjunto de datos en dos subconjuntos: uno para entrenar el modelo y otro para evaluarlo de manera imparcial.\n",
    "\n",
    "### ¿Por qué es crucial esta división?\n",
    "- **Conjunto de Entrenamiento (Training Set)**: El modelo \"aprende\" los patrones y relaciones de estos datos. Típicamente, constituye el 70-80% del total.\n",
    "- **Conjunto de Prueba (Test Set)**: Estos datos son \"nuevos\" para el modelo. Se usan para evaluar qué tan bien generaliza sus aprendizajes a datos que nunca ha visto. Esto nos da una medida realista de su rendimiento.\n",
    "\n",
    "### 🧠 Conceptos Clave:\n",
    "- **`train_test_split`**: La función de `scikit-learn` que realiza esta división.\n",
    "- **`test_size`**: Define el porcentaje de datos que se destinará al conjunto de prueba (e.g., `0.2` para un 20%).\n",
    "- **`random_state`**: Fija una \"semilla\" para la aleatoriedad, asegurando que la división sea siempre la misma cada vez que se ejecuta el código. Esto es vital para la **reproducibilidad**.\n",
    "- **`stratify`**: Asegura que la proporción de clases (ej. \"ALTO\" vs \"BAJO\") sea la misma tanto en el conjunto de entrenamiento como en el de prueba. Es fundamental en problemas de clasificación para evitar sesgos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb9fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividir los datos: 80% para entrenamiento, 20% para prueba.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"✅ Datos divididos exitosamente.\")\n",
    "print(f\"Tamaño del conjunto de entrenamiento (X_train): {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba (X_test):      {X_test.shape}\")\n",
    "print(f\"Proporción de clase 'ALTO' en y_train: {y_train.mean():.2f}\")\n",
    "print(f\"Proporción de clase 'ALTO' en y_test:  {y_test.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d597ed",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 4: Entrenamiento del Modelo Random Forest\n",
    "\n",
    "### 🎯 Objetivo de la Actividad\n",
    "Instanciar y entrenar nuestro modelo de clasificación usando el conjunto de entrenamiento.\n",
    "\n",
    "### ¿Qué es un Random Forest?\n",
    "Un **Random Forest** (Bosque Aleatorio) es un modelo de *aprendizaje de conjunto* (ensemble learning). Funciona construyendo una multitud de **árboles de decisión** durante el entrenamiento y emitiendo la clase que es la moda de las clases (clasificación) o la predicción media (regresión) de los árboles individuales.\n",
    "\n",
    "### 🧠 Conceptos Clave:\n",
    "- **`RandomForestClassifier`**: La clase de `scikit-learn` que implementa el algoritmo.\n",
    "- **`n_estimators`**: El número de árboles que se construirán en el bosque. Un número mayor generalmente mejora el rendimiento, pero también aumenta el costo computacional. `100` es un buen punto de partida.\n",
    "- **`random_state`**: Al igual que antes, garantiza la reproducibilidad del modelo.\n",
    "- **`fit(X_train, y_train)`**: El método que \"entrena\" el modelo, encontrando los patrones en los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a24df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Crear una instancia del clasificador Random Forest.\n",
    "#    n_jobs=-1 utiliza todos los núcleos de CPU disponibles para acelerar el entrenamiento.\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 2. Entrenar el modelo con los datos de entrenamiento.\n",
    "print(\"🚀 Entrenando el modelo Random Forest...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"✅ Modelo entrenado exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63822b09",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 5: Evaluación del Modelo\n",
    "\n",
    "### 🎯 Objetivo de la Actividad\n",
    "Evaluar el rendimiento de nuestro modelo entrenado usando el conjunto de prueba, que contiene datos que el modelo no ha visto antes.\n",
    "\n",
    "### Métricas Clave de Evaluación:\n",
    "1.  **Matriz de Confusión**: Una tabla que muestra el rendimiento del modelo. Nos dice cuántos casos fueron clasificados correctamente y cuántos incorrectamente.\n",
    "    - **Verdaderos Positivos (TP)**: Predijo \"ALTO\" y era \"ALTO\".\n",
    "    - **Verdaderos Negativos (TN)**: Predijo \"BAJO\" y era \"BAJO\".\n",
    "    - **Falsos Positivos (FP)**: Predijo \"ALTO\" pero era \"BAJO\" (Error Tipo I).\n",
    "    - **Falsos Negativos (FN)**: Predijo \"BAJO\" pero era \"ALTO\" (Error Tipo II).\n",
    "\n",
    "2.  **Reporte de Clasificación**:\n",
    "    - **Accuracy (Exactitud)**: Porcentaje total de predicciones correctas. `(TP + TN) / Total`.\n",
    "    - **Precision (Precisión)**: De todos los que predijo como \"ALTO\", ¿cuántos acertó? `TP / (TP + FP)`.\n",
    "    - **Recall (Sensibilidad)**: De todos los que realmente eran \"ALTO\", ¿a cuántos identificó? `TP / (TP + FN)`.\n",
    "    - **F1-Score**: La media armónica de Precisión y Recall. Es una métrica balanceada muy útil.\n",
    "\n",
    "3.  **Curva ROC y AUC**:\n",
    "    - **Curva ROC**: Visualiza la capacidad de un clasificador para distinguir entre clases. Un buen modelo tiene una curva que se acerca a la esquina superior izquierda.\n",
    "    - **AUC (Area Under the Curve)**: El área bajo la curva ROC. Un valor de 1.0 representa un modelo perfecto, mientras que 0.5 representa un modelo que no es mejor que el azar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Hacer predicciones sobre el conjunto de prueba.\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 2. Calcular y mostrar la Matriz de Confusión.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Pred. BAJO', 'Pred. ALTO'], \n",
    "            yticklabels=['Real BAJO', 'Real ALTO'])\n",
    "plt.title('Matriz de Confusión', fontsize=16)\n",
    "plt.ylabel('Clase Real')\n",
    "plt.xlabel('Clase Predicha')\n",
    "plt.show()\n",
    "\n",
    "# 3. Imprimir el Reporte de Clasificación.\n",
    "print(\"=\"*60)\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAJO (0)', 'ALTO (1)']))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 4. Calcular y mostrar la Curva ROC y el AUC.\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC (Receiver Operating Characteristic)', fontsize=16)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da05fc",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 6: Interpretación del Modelo\n",
    "\n",
    "### 🎯 Objetivo de la Actividad\n",
    "Entender qué variables fueron las más importantes para las predicciones del modelo. Un modelo no es solo una \"caja negra\"; Random Forest nos permite inspeccionar su lógica interna.\n",
    "\n",
    "### Importancia de las Características (Feature Importance)\n",
    "El algoritmo de Random Forest puede calcular una puntuación para cada variable predictora, indicando su contribución relativa a la reducción de la impureza (o mejora de la precisión) en los árboles del bosque.\n",
    "\n",
    "Una puntuación más alta significa que la variable fue más decisiva para separar las clases \"ALTO\" y \"BAJO\".\n",
    "\n",
    "**¿Para qué sirve esto?**\n",
    "- **Entender el fenómeno**: Nos ayuda a comprender qué factores están más asociados con un alto nivel de contagios.\n",
    "- **Selección de variables**: Podríamos decidir construir un modelo más simple usando solo las variables más importantes.\n",
    "- **Comunicación**: Es una forma efectiva de explicar los resultados del modelo a partes interesadas no técnicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Obtener la importancia de cada característica desde el modelo entrenado.\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# 2. Crear un DataFrame para facilitar la visualización.\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# 3. Ordenar el DataFrame por importancia de forma descendente.\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 4. Visualizar las 20 características más importantes.\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20), palette='viridis')\n",
    "plt.title('Top 20 Variables más Importantes', fontsize=16)\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Variable')\n",
    "plt.grid(True, axis='x')\n",
    "plt.show()\n",
    "\n",
    "# Imprimir el top 10 para referencia\n",
    "print(\"=\"*60)\n",
    "print(\"Top 10 Variables más Importantes:\")\n",
    "print(feature_importance_df.head(10).to_string(index=False))\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
