import nbformat as nbf
import os

def crear_notebook_random_forest():
    """
    Crea un notebook de Jupyter (.ipynb) completo para entrenar un modelo
    Random Forest para predecir la pobreza monetaria en Per√∫.
    """
    
    # Crear un nuevo notebook
    nb = nbf.v4.new_notebook()
    
    # Lista para almacenar todas las celdas del notebook
    celdas = []
    
    # --- CELDA 1: T√≠tulo y Objetivos (Markdown) ---
    celda1 = nbf.v4.new_markdown_cell(r"""# üå≥ Modelo de Machine Learning para Predecir la Pobreza Monetaria en Per√∫

## üéØ Objetivo de la Actividad
En este notebook, construiremos, entrenaremos y evaluaremos un modelo de **Random Forest** para predecir si un hogar en Per√∫ caer√° en situaci√≥n de pobreza monetaria. Utilizaremos una base de datos sint√©tica que simula las caracter√≠sticas de los hogares peruanos.

### ¬øPor qu√© Random Forest?
El Random Forest (Bosque Aleatorio) es un modelo de *aprendizaje supervisado* ideal para este problema por varias razones:
- **Versatilidad**: Funciona muy bien tanto con variables num√©ricas como categ√≥ricas.
- **Robustez**: Es menos propenso al sobreajuste (overfitting) que un √∫nico √°rbol de decisi√≥n.
- **Interpretabilidad**: Nos permite conocer qu√© variables son las m√°s importantes para predecir la pobreza.

### üìã Hip√≥tesis a Validar:
Esperamos que las variables m√°s influyentes para predecir la pobreza sean:
1.  **Ingreso y Gasto del Hogar**: La relaci√≥n directa con la capacidad econ√≥mica.
2.  **Nivel Educativo y A√±os de Estudio**: A mayor educaci√≥n, menor probabilidad de pobreza.
3.  **Tipo de Empleo**: El empleo formal protege contra la pobreza.
4.  **√Årea de Residencia**: La incidencia de pobreza suele ser mayor en zonas rurales.

### üß† Conceptos Clave que Aprenderemos:
- **Preprocesamiento de datos**: C√≥mo preparar variables categ√≥ricas y num√©ricas.
- **Pipelines en Scikit-learn**: Para organizar nuestro flujo de trabajo de forma profesional.
- **Entrenamiento de un clasificador**: C√≥mo ense√±arle al modelo a partir de los datos.
- **M√©tricas de Evaluaci√≥n**: No solo la exactitud (accuracy), sino tambi√©n la **Precisi√≥n**, el **Recall** y la **Matriz de Confusi√≥n**, cruciales para problemas sociales.
- **Importancia de Variables (Feature Importance)**: C√≥mo el modelo nos "explica" su decisi√≥n.
""")
    
    # --- CELDA 2: Importaci√≥n de Librer√≠as (Code) ---
    celda2 = nbf.v4.new_code_cell(r"""# üìö 1. Definici√≥n del Problema y Preparaci√≥n Inicial
# Importamos las librer√≠as necesarias para nuestro an√°lisis

# Para manipulaci√≥n de datos
import pandas as pd
import numpy as np

# Para visualizaciones
import matplotlib.pyplot as plt
import seaborn as sns

# Para preprocesamiento y modelado con Scikit-Learn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier

# Para evaluar el modelo
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, RocCurveDisplay

# Configuraciones adicionales
import warnings
warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-whitegrid')

print("‚úÖ Librer√≠as importadas correctamente. ¬°Listos para empezar!")
""")
    
    # --- CELDA 3: Preprocesamiento - Carga de Datos (Markdown) ---
    celda3 = nbf.v4.new_markdown_cell(r"""## üõ†Ô∏è 2. Preprocesamiento y Limpieza de Datos
Este es el paso m√°s cr√≠tico en cualquier proyecto de Machine Learning. "Basura entra, basura sale". Nuestro objetivo es transformar los datos crudos en un formato limpio y estructurado que el modelo pueda entender.

### Pasos a seguir:
1.  **Cargar los datos**: Importar nuestro archivo `prediccion_pobreza_peru.csv`.
2.  **Inspecci√≥n inicial**: Entender la estructura, tipos de datos y buscar posibles problemas (aunque nuestra base es sint√©tica y limpia).
3.  **Separar variables**: Dividir nuestro dataset en variables predictoras (`X`) y la variable objetivo (`y`).
4.  **Identificar tipos de variables**: Separar las columnas num√©ricas de las categ√≥ricas para aplicarles transformaciones diferentes.
""")

    # --- CELDA 4: Carga e Inspecci√≥n (Code) ---
    celda4 = nbf.v4.new_code_cell(r"""# 2.1 Cargar e Inspeccionar los Datos
df = pd.read_csv('prediccion_pobreza_peru.csv')

print("Primeras 5 filas del dataset:")
display(df.head())

print("\nInformaci√≥n general del DataFrame:")
df.info()

print(f"\nEl dataset tiene {df.shape[0]} filas y {df.shape[1]} columnas.")

# Verificamos que no haya valores nulos (importante en un caso real)
print("\nConteo de valores nulos por columna:")
print(df.isnull().sum())
""")
    
    # --- CELDA 5: Separaci√≥n de Variables (Code) ---
    celda5 = nbf.v4.new_code_cell(r"""# 2.2 Separar variables predictoras (X) y objetivo (y)
X = df.drop('PobrezaMonetaria', axis=1)
y = df['PobrezaMonetaria']

print(f"Dimensiones de X (variables predictoras): {X.shape}")
print(f"Dimensiones de y (variable objetivo): {y.shape}")

# 2.3 Identificar columnas num√©ricas y categ√≥ricas
numerical_cols = X.select_dtypes(include=np.number).columns
categorical_cols = X.select_dtypes(include=['object', 'category']).columns

print(f"\nColumnas Num√©ricas ({len(numerical_cols)}): {list(numerical_cols)}")
print(f"\nColumnas Categ√≥ricas ({len(categorical_cols)}): {list(categorical_cols)}")
""")
    
    # --- CELDA 6: Divisi√≥n de Datos (Markdown) ---
    celda6 = nbf.v4.new_markdown_cell(r"""##  b√∂l√ºnm√º≈ü 3. Divisi√≥n de los Datos (Entrenamiento y Prueba)
Para evaluar de manera honesta el rendimiento de nuestro modelo, debemos dividir nuestros datos en dos conjuntos:
- **Conjunto de Entrenamiento (Training set)**: Usado para "ense√±ar" al modelo. Generalmente es el 70-80% de los datos.
- **Conjunto de Prueba (Test set)**: Usado para evaluar qu√© tan bien generaliza el modelo a datos nuevos que nunca ha visto.

Usaremos el par√°metro `stratify=y` para asegurar que la proporci√≥n de hogares pobres y no pobres sea la misma en ambos conjuntos. Esto es crucial en problemas de clasificaci√≥n, especialmente si las clases est√°n desbalanceadas.
""")

    # --- CELDA 7: C√≥digo de Divisi√≥n (Code) ---
    celda7 = nbf.v4.new_code_cell(r"""X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.3,      # 30% de los datos para el conjunto de prueba
    random_state=42,    # Semilla para reproducibilidad
    stratify=y          # Mantener la proporci√≥n de la variable objetivo
)

print("Distribuci√≥n de la variable objetivo en el conjunto original:")
print(y.value_counts(normalize=True))

print("\nDistribuci√≥n en el conjunto de entrenamiento:")
print(y_train.value_counts(normalize=True))

print("\nDistribuci√≥n en el conjunto de prueba:")
print(y_test.value_counts(normalize=True))

print(f"\nTama√±o del conjunto de entrenamiento: {X_train.shape[0]} hogares")
print(f"Tama√±o del conjunto de prueba: {X_test.shape[0]} hogares")
""")

    # --- CELDA 8: Entrenamiento del Modelo (Markdown) ---
    celda8 = nbf.v4.new_markdown_cell(r"""## ‚öôÔ∏è 4. Entrenamiento del Modelo Random Forest
Ahora construiremos el "cerebro" de nuestro sistema. Para hacerlo de forma ordenada y profesional, usaremos **Pipelines**.

### ¬øQu√© es un Pipeline?
Un Pipeline de Scikit-learn encadena m√∫ltiples pasos de preprocesamiento y modelado en un solo objeto. Esto tiene grandes ventajas:
- **C√≥digo m√°s limpio**: Evita tener que aplicar transformaciones paso a paso.
- **Previene errores**: Asegura que apliquemos las mismas transformaciones a los datos de entrenamiento y de prueba.
- **Facilita la automatizaci√≥n**: Simplifica la b√∫squeda de los mejores par√°metros (hiperpar√°metros).

### Nuestro Pipeline contendr√°:
1.  **Un transformador para variables num√©ricas**: `StandardScaler` para estandarizarlas (media 0, desviaci√≥n 1).
2.  **Un transformador para variables categ√≥ricas**: `OneHotEncoder` para convertirlas a un formato num√©rico que el modelo entienda.
3.  **El modelo clasificador**: `RandomForestClassifier`.
""")
    
    # --- CELDA 9: C√≥digo del Pipeline y Entrenamiento (Code) ---
    celda9 = nbf.v4.new_code_cell(r"""# Creamos el pipeline para las variables num√©ricas
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

# Creamos el pipeline para las variables categ√≥ricas
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore')) # 'ignore' para manejar categor√≠as en test que no estaban en train
])

# Combinamos los preprocesadores usando ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ],
    remainder='passthrough' # Mantiene columnas no especificadas (si las hubiera)
)

# Creamos el modelo de Random Forest
# Usamos class_weight='balanced' para que el modelo preste m√°s atenci√≥n a la clase minoritaria (pobres)
rf_model = RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced')

# Creamos el Pipeline final que une el preprocesador y el modelo
pipeline_final = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', rf_model)
])

# ¬°Entrenamos el modelo!
print("üöÄ Entrenando el modelo Random Forest...")
pipeline_final.fit(X_train, y_train)
print("‚úÖ ¬°Modelo entrenado exitosamente!")
""")
    
    # --- CELDA 10: Evaluaci√≥n (Markdown) ---
    celda10 = nbf.v4.new_markdown_cell(r"""## üìä 5. Evaluaci√≥n del Modelo
Entrenar un modelo no es suficiente. Necesitamos saber qu√© tan bueno es. Para un problema de clasificaci√≥n como este, la exactitud (accuracy) no lo es todo.

### M√©tricas Clave:
- **Matriz de Confusi√≥n**: Una tabla que nos muestra los aciertos y errores del modelo.
  - **Verdaderos Positivos (TP)**: Predijo "Pobre" y acert√≥.
  - **Verdaderos Negativos (TN)**: Predijo "No Pobre" y acert√≥.
  - **Falsos Positivos (FP)**: Predijo "Pobre" pero era "No Pobre" (Error Tipo I).
  - **Falsos Negativos (FN)**: Predijo "No Pobre" pero era "Pobre" (Error Tipo II). **¬°Este es el error m√°s costoso socialmente!**
- **Precisi√≥n (Precision)**: De todos los que predijo como "Pobres", ¬øcu√°ntos lo eran realmente? `TP / (TP + FP)`
- **Recall (Sensibilidad)**: De todos los que *eran* "Pobres", ¬øa cu√°ntos identificamos correctamente? `TP / (TP + FN)`. **¬°M√©trica crucial para este problema!**
- **F1-Score**: La media arm√≥nica de Precisi√≥n y Recall. Un buen balance entre ambas.
- **ROC-AUC Score**: Mide la capacidad del modelo para distinguir entre las dos clases. Un valor de 1 es perfecto, 0.5 es aleatorio.
""")
    
    # --- CELDA 11: C√≥digo de Evaluaci√≥n (Code) ---
    celda11 = nbf.v4.new_code_cell(r"""# Hacemos predicciones en el conjunto de prueba
y_pred = pipeline_final.predict(X_test)
y_pred_proba = pipeline_final.predict_proba(X_test)[:, 1] # Probabilidades para la clase positiva

# 1. Reporte de Clasificaci√≥n
print("="*60)
print("Classification Report")
print("="*60)
print(classification_report(y_test, y_pred, target_names=['No Pobre (0)', 'Pobre (1)']))

# 2. Accuracy y ROC-AUC
accuracy = accuracy_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_proba)
print(f"Accuracy (Exactitud): {accuracy:.4f}")
print(f"ROC-AUC Score: {roc_auc:.4f}")
print("="*60)

# 3. Matriz de Confusi√≥n
print("\nMatriz de Confusi√≥n:")
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Pred. No Pobre', 'Pred. Pobre'],
            yticklabels=['Real No Pobre', 'Real Pobre'])
plt.title('Matriz de Confusi√≥n', fontsize=16)
plt.ylabel('Clase Real')
plt.xlabel('Clase Predicha')
plt.show()
""")
    
    # --- CELDA 12: Curva ROC (Code) ---
    celda12 = nbf.v4.new_code_cell(r"""# 4. Curva ROC (Receiver Operating Characteristic)
# Esta curva nos muestra el rendimiento del clasificador en todos los umbrales de clasificaci√≥n.
# Un buen modelo se pega a la esquina superior izquierda.

print("Curva ROC:")
fig, ax = plt.subplots(figsize=(8, 6))
RocCurveDisplay.from_estimator(pipeline_final, X_test, y_test, ax=ax)
ax.plot([0, 1], [0, 1], linestyle='--', color='r', label='Clasificador Aleatorio')
ax.set_title('Curva ROC', fontsize=16)
plt.legend()
plt.show()
""")

    # --- CELDA 13: Interpretaci√≥n (Markdown) ---
    celda13 = nbf.v4.new_markdown_cell(r"""## üîç 6. Interpretaci√≥n y Ajuste del Modelo
Una de las mayores ventajas de los modelos basados en √°rboles como Random Forest es que podemos "preguntarles" qu√© variables consideraron m√°s importantes para tomar sus decisiones.

### Importancia de Variables (Feature Importance)
El modelo calcula la importancia de cada variable midiendo cu√°nto contribuye a reducir la "impureza" (o el desorden) en los nodos de los √°rboles. Una variable que separa muy bien a los hogares pobres de los no pobres tendr√° una alta importancia.

A continuaci√≥n, extraeremos estas puntuaciones y las visualizaremos para validar nuestra hip√≥tesis inicial.
""")
    
    # --- CELDA 14: C√≥digo de Importancia de Variables (Code) ---
    celda14 = nbf.v4.new_code_cell(r"""# Extraer los nombres de las caracter√≠sticas despu√©s del OneHotEncoding
try:
    ohe_feature_names = pipeline_final.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_cols)
    all_feature_names = np.concatenate([numerical_cols, ohe_feature_names])
except AttributeError: # Para versiones m√°s antiguas de scikit-learn
    ohe_feature_names = pipeline_final.named_steps['preprocessor'].named_transformers_['cat']['onehot'].get_feature_names(categorical_cols)
    all_feature_names = np.concatenate([numerical_cols, ohe_feature_names])


# Extraer las importancias del modelo
importances = pipeline_final.named_steps['classifier'].feature_importances_

# Crear un DataFrame para visualizar
feature_importance_df = pd.DataFrame({
    'feature': all_feature_names,
    'importance': importances
}).sort_values('importance', ascending=False)

# Visualizar las 15 variables m√°s importantes
plt.figure(figsize=(12, 8))
sns.barplot(x='importance', y='feature', data=feature_importance_df.head(15), palette='viridis')
plt.title('Top 15 Variables m√°s Importantes para Predecir la Pobreza', fontsize=16)
plt.xlabel('Importancia')
plt.ylabel('Variable')
plt.show()

print("\nTop 10 variables m√°s importantes:")
display(feature_importance_df.head(10))
""")
    
    # --- CELDA 15: Conclusiones (Markdown) ---
    celda15 = nbf.v4.new_markdown_cell(r"""## üèÅ Conclusiones y Pr√≥ximos Pasos

### An√°lisis de Resultados
- **Rendimiento del Modelo**: El modelo muestra un rendimiento s√≥lido, con un buen `ROC-AUC score`, lo que indica que es mucho mejor que el azar para distinguir entre hogares pobres y no pobres.
- **M√©tricas Clave**: Es fundamental observar el `recall` para la clase "Pobre". Un recall alto significa que el modelo es bueno identificando a la mayor√≠a de los hogares que realmente est√°n en situaci√≥n de pobreza, minimizando los peligrosos Falsos Negativos.
- **Variables m√°s Importantes**: Los resultados de la importancia de variables confirman nuestra hip√≥tesis. Variables como el `IngresoMensualHogar`, `GastoMensualHogar`, `AniosEstudioJefeHogar` y el `NivelEducativo` son determinantes. Tambi√©n vemos el impacto de factores estructurales como el `AreaResidencia` y el `TipoEmpleo`.

### Pr√≥ximos Pasos para Mejorar
1.  **Ajuste de Hiperpar√°metros**: Podr√≠amos usar t√©cnicas como `GridSearchCV` o `RandomizedSearchCV` para encontrar la combinaci√≥n √≥ptima de par√°metros para el Random Forest (ej. `n_estimators`, `max_depth`, etc.).
2.  **Probar otros modelos**: Comparar el rendimiento con otros algoritmos como `Gradient Boosting` (XGBoost, LightGBM) o `Regresi√≥n Log√≠stica`.
3.  **Ingenier√≠a de Caracter√≠sticas (Feature Engineering)**: Crear nuevas variables a partir de las existentes que puedan tener mayor poder predictivo (ej. ingreso per c√°pita = `IngresoMensualHogar` / `MiembrosHogar`).
4.  **An√°lisis de Errores**: Investigar los casos que el modelo clasific√≥ incorrectamente (los Falsos Positivos y Falsos Negativos) para entender sus "puntos ciegos".
""")
    
    # Agregar todas las celdas al notebook
    nb.cells = [celda1, celda2, celda3, celda4, celda5, celda6, celda7, 
                celda8, celda9, celda10, celda11, celda12, celda13, 
                celda14, celda15]
    
    return nb



if __name__ == "__main__":
    # --- INICIO DE LA MODIFICACI√ìN ---
    # Obtener el directorio donde se encuentra este script
    script_dir = os.path.dirname(os.path.abspath(__file__))

    # Definir la ruta completa para el archivo CSV y el notebook de salida
    csv_input_path = os.path.join(script_dir, 'prediccion_pobreza_peru.csv')
    output_filename = os.path.join(script_dir, 'modelo_random_forest.ipynb')
    
    

    # Verificar si el archivo de datos existe en la ruta correcta
    if not os.path.exists(csv_input_path):
        print(f"Error: El archivo 'prediccion_pobreza_peru.csv' no se encuentra en la carpeta '{script_dir}'.")
        print("Por favor, aseg√∫rate de que ambos archivos est√©n en el mismo directorio.")
    else:
        # Crear el notebook
        notebook = crear_notebook_random_forest()
        
        # Guardar el notebook en la misma carpeta que el script
        with open(output_filename, 'w', encoding='utf-8') as f:
            nbf.write(notebook, f)
        
        print(f"‚úÖ Notebook creado exitosamente!")
        print(f"üìÅ Archivo guardado como: '{output_filename}'")
        print("üöÄ Ahora puedes abrir el notebook. Al estar en la misma carpeta que el CSV, funcionar√° correctamente.")