{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a2bd1c",
   "metadata": {},
   "source": [
    "\n",
    "# Modelo Random Forest: ClasificaciÃ³n de Nivel de Contagios\n",
    "## Paso 1: DefiniciÃ³n del Problema y PreparaciÃ³n Inicial\n",
    "\n",
    "### ðŸŽ¯ Objetivo de la Actividad\n",
    "Establecer las bases del proyecto: cargar librerÃ­as, importar datos, realizar una exploraciÃ³n inicial y crear nuestra variable objetivo para la clasificaciÃ³n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705155f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LibrerÃ­as importadas correctamente.\n",
      "âœ… Base de datos 'merge_RENAMU_GASTO_V.dta' cargada: 14730 filas y 58 columnas.\n",
      "âœ… Variable objetivo 'nivel_contagios' creada.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente.\")\n",
    "\n",
    "nombre_archivo = 'merge_RENAMU_GASTO_V.dta'\n",
    "try:\n",
    "    df = pd.read_stata(nombre_archivo)\n",
    "    print(f\"âœ… Base de datos '{nombre_archivo}' cargada: {df.shape[0]} filas y {df.shape[1]} columnas.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: No se pudo encontrar el archivo '{nombre_archivo}'.\")\n",
    "\n",
    "mediana_contagiados = df['contagiados'].median()\n",
    "df['nivel_contagios'] = df['contagiados'].apply(lambda x: 'ALTO' if x > mediana_contagiados else 'BAJO')\n",
    "print(\"âœ… Variable objetivo 'nivel_contagios' creada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a07b72",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 2: Preprocesamiento y Limpieza de Datos\n",
    "\n",
    "### ðŸŽ¯ Objetivo de la Actividad\n",
    "Preparar todas las variables del dataset para que sean aptas para el modelo, manejando valores faltantes, corrigiendo datos anÃ³malos y asegurando un formato numÃ©rico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa93462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Eliminar columnas no informativas o de fuga de datos\n",
    "cols_to_drop = [\n",
    "    'UBIGEO', 'DEPARTAMENTO', 'PROVINCIA', 'DISTRITO', 'VFI_P66', \n",
    "    'VFI_P67', 'VFI_P68', '_merge', 'P67_11_O', 'P68_8_O', 'contagiados'\n",
    "]\n",
    "df_clean = df_clean.drop(columns=cols_to_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115a6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Corregir y transformar variables\n",
    "df_clean.loc[df_clean['MONTO_GIRADO'] < 0, 'MONTO_GIRADO'] = 0\n",
    "df_clean[['mes', 'year']] = df_clean[['mes', 'year']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fbbb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocesamiento completado.\n",
      "Forma de X (predictoras): (14730, 47)\n",
      "Forma de y (objetivo): (14730,)\n"
     ]
    }
   ],
   "source": [
    "# 5. Definir X e y\n",
    "y = df_clean['nivel_contagios'].apply(lambda nivel: 1 if nivel == 'ALTO' else 0)\n",
    "X = df_clean.drop(columns=['nivel_contagios'])\n",
    "\n",
    "print(\"âœ… Preprocesamiento completado.\")\n",
    "print(f\"Forma de X (predictoras): {X.shape}\")\n",
    "print(f\"Forma de y (objetivo): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc48ca",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 3: DivisiÃ³n de los Datos (Entrenamiento y Prueba)\n",
    "\n",
    "### ðŸŽ¯ Objetivo de la Actividad\n",
    "Dividir nuestro conjunto de datos en dos subconjuntos: uno para entrenar el modelo y otro para evaluarlo de manera imparcial.\n",
    "\n",
    "### Â¿Por quÃ© es crucial esta divisiÃ³n?\n",
    "- **Conjunto de Entrenamiento (Training Set)**: El modelo \"aprende\" los patrones y relaciones de estos datos. TÃ­picamente, constituye el 70-80% del total.\n",
    "- **Conjunto de Prueba (Test Set)**: Estos datos son \"nuevos\" para el modelo. Se usan para evaluar quÃ© tan bien generaliza sus aprendizajes a datos que nunca ha visto. Esto nos da una medida realista de su rendimiento.\n",
    "\n",
    "### ðŸ§  Conceptos Clave:\n",
    "- **`train_test_split`**: La funciÃ³n de `scikit-learn` que realiza esta divisiÃ³n.\n",
    "- **`test_size`**: Define el porcentaje de datos que se destinarÃ¡ al conjunto de prueba (e.g., `0.2` para un 20%).\n",
    "- **`random_state`**: Fija una \"semilla\" para la aleatoriedad, asegurando que la divisiÃ³n sea siempre la misma cada vez que se ejecuta el cÃ³digo. Esto es vital para la **reproducibilidad**.\n",
    "- **`stratify`**: Asegura que la proporciÃ³n de clases (ej. \"ALTO\" vs \"BAJO\") sea la misma tanto en el conjunto de entrenamiento como en el de prueba. Es fundamental en problemas de clasificaciÃ³n para evitar sesgos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb9fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividir los datos: 80% para entrenamiento, 20% para prueba.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"âœ… Datos divididos exitosamente.\")\n",
    "print(f\"TamaÃ±o del conjunto de entrenamiento (X_train): {X_train.shape}\")\n",
    "print(f\"TamaÃ±o del conjunto de prueba (X_test):      {X_test.shape}\")\n",
    "print(f\"ProporciÃ³n de clase 'ALTO' en y_train: {y_train.mean():.2f}\")\n",
    "print(f\"ProporciÃ³n de clase 'ALTO' en y_test:  {y_test.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d597ed",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 4: Entrenamiento del Modelo Random Forest\n",
    "\n",
    "### ðŸŽ¯ Objetivo de la Actividad\n",
    "Instanciar y entrenar nuestro modelo de clasificaciÃ³n usando el conjunto de entrenamiento.\n",
    "\n",
    "### Â¿QuÃ© es un Random Forest?\n",
    "Un **Random Forest** (Bosque Aleatorio) es un modelo de *aprendizaje de conjunto* (ensemble learning). Funciona construyendo una multitud de **Ã¡rboles de decisiÃ³n** durante el entrenamiento y emitiendo la clase que es la moda de las clases (clasificaciÃ³n) o la predicciÃ³n media (regresiÃ³n) de los Ã¡rboles individuales.\n",
    "\n",
    "### ðŸ§  Conceptos Clave:\n",
    "- **`RandomForestClassifier`**: La clase de `scikit-learn` que implementa el algoritmo.\n",
    "- **`n_estimators`**: El nÃºmero de Ã¡rboles que se construirÃ¡n en el bosque. Un nÃºmero mayor generalmente mejora el rendimiento, pero tambiÃ©n aumenta el costo computacional. `100` es un buen punto de partida.\n",
    "- **`random_state`**: Al igual que antes, garantiza la reproducibilidad del modelo.\n",
    "- **`fit(X_train, y_train)`**: El mÃ©todo que \"entrena\" el modelo, encontrando los patrones en los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a24df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Crear una instancia del clasificador Random Forest.\n",
    "#    n_jobs=-1 utiliza todos los nÃºcleos de CPU disponibles para acelerar el entrenamiento.\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 2. Entrenar el modelo con los datos de entrenamiento.\n",
    "print(\"ðŸš€ Entrenando el modelo Random Forest...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"âœ… Modelo entrenado exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63822b09",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 5: EvaluaciÃ³n del Modelo\n",
    "\n",
    "### ðŸŽ¯ Objetivo de la Actividad\n",
    "Evaluar el rendimiento de nuestro modelo entrenado usando el conjunto de prueba, que contiene datos que el modelo no ha visto antes.\n",
    "\n",
    "### MÃ©tricas Clave de EvaluaciÃ³n:\n",
    "1.  **Matriz de ConfusiÃ³n**: Una tabla que muestra el rendimiento del modelo. Nos dice cuÃ¡ntos casos fueron clasificados correctamente y cuÃ¡ntos incorrectamente.\n",
    "    - **Verdaderos Positivos (TP)**: Predijo \"ALTO\" y era \"ALTO\".\n",
    "    - **Verdaderos Negativos (TN)**: Predijo \"BAJO\" y era \"BAJO\".\n",
    "    - **Falsos Positivos (FP)**: Predijo \"ALTO\" pero era \"BAJO\" (Error Tipo I).\n",
    "    - **Falsos Negativos (FN)**: Predijo \"BAJO\" pero era \"ALTO\" (Error Tipo II).\n",
    "\n",
    "2.  **Reporte de ClasificaciÃ³n**:\n",
    "    - **Accuracy (Exactitud)**: Porcentaje total de predicciones correctas. `(TP + TN) / Total`.\n",
    "    - **Precision (PrecisiÃ³n)**: De todos los que predijo como \"ALTO\", Â¿cuÃ¡ntos acertÃ³? `TP / (TP + FP)`.\n",
    "    - **Recall (Sensibilidad)**: De todos los que realmente eran \"ALTO\", Â¿a cuÃ¡ntos identificÃ³? `TP / (TP + FN)`.\n",
    "    - **F1-Score**: La media armÃ³nica de PrecisiÃ³n y Recall. Es una mÃ©trica balanceada muy Ãºtil.\n",
    "\n",
    "3.  **Curva ROC y AUC**:\n",
    "    - **Curva ROC**: Visualiza la capacidad de un clasificador para distinguir entre clases. Un buen modelo tiene una curva que se acerca a la esquina superior izquierda.\n",
    "    - **AUC (Area Under the Curve)**: El Ã¡rea bajo la curva ROC. Un valor de 1.0 representa un modelo perfecto, mientras que 0.5 representa un modelo que no es mejor que el azar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Hacer predicciones sobre el conjunto de prueba.\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 2. Calcular y mostrar la Matriz de ConfusiÃ³n.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Pred. BAJO', 'Pred. ALTO'], \n",
    "            yticklabels=['Real BAJO', 'Real ALTO'])\n",
    "plt.title('Matriz de ConfusiÃ³n', fontsize=16)\n",
    "plt.ylabel('Clase Real')\n",
    "plt.xlabel('Clase Predicha')\n",
    "plt.show()\n",
    "\n",
    "# 3. Imprimir el Reporte de ClasificaciÃ³n.\n",
    "print(\"=\"*60)\n",
    "print(\"Reporte de ClasificaciÃ³n:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAJO (0)', 'ALTO (1)']))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 4. Calcular y mostrar la Curva ROC y el AUC.\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC (Receiver Operating Characteristic)', fontsize=16)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da05fc",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 6: InterpretaciÃ³n del Modelo\n",
    "\n",
    "### ðŸŽ¯ Objetivo de la Actividad\n",
    "Entender quÃ© variables fueron las mÃ¡s importantes para las predicciones del modelo. Un modelo no es solo una \"caja negra\"; Random Forest nos permite inspeccionar su lÃ³gica interna.\n",
    "\n",
    "### Importancia de las CaracterÃ­sticas (Feature Importance)\n",
    "El algoritmo de Random Forest puede calcular una puntuaciÃ³n para cada variable predictora, indicando su contribuciÃ³n relativa a la reducciÃ³n de la impureza (o mejora de la precisiÃ³n) en los Ã¡rboles del bosque.\n",
    "\n",
    "Una puntuaciÃ³n mÃ¡s alta significa que la variable fue mÃ¡s decisiva para separar las clases \"ALTO\" y \"BAJO\".\n",
    "\n",
    "**Â¿Para quÃ© sirve esto?**\n",
    "- **Entender el fenÃ³meno**: Nos ayuda a comprender quÃ© factores estÃ¡n mÃ¡s asociados con un alto nivel de contagios.\n",
    "- **SelecciÃ³n de variables**: PodrÃ­amos decidir construir un modelo mÃ¡s simple usando solo las variables mÃ¡s importantes.\n",
    "- **ComunicaciÃ³n**: Es una forma efectiva de explicar los resultados del modelo a partes interesadas no tÃ©cnicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Obtener la importancia de cada caracterÃ­stica desde el modelo entrenado.\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# 2. Crear un DataFrame para facilitar la visualizaciÃ³n.\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# 3. Ordenar el DataFrame por importancia de forma descendente.\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 4. Visualizar las 20 caracterÃ­sticas mÃ¡s importantes.\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20), palette='viridis')\n",
    "plt.title('Top 20 Variables mÃ¡s Importantes', fontsize=16)\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Variable')\n",
    "plt.grid(True, axis='x')\n",
    "plt.show()\n",
    "\n",
    "# Imprimir el top 10 para referencia\n",
    "print(\"=\"*60)\n",
    "print(\"Top 10 Variables mÃ¡s Importantes:\")\n",
    "print(feature_importance_df.head(10).to_string(index=False))\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
