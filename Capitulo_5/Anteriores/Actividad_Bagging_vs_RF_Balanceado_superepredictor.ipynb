{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f7c43d",
   "metadata": {},
   "source": [
    "# Actividad: Bagging vs. Random Forest con Datos Balanceados\n",
    "\n",
    "### Introducci√≥n Te√≥rica\n",
    "El m√©todo de Random Forest se fundamenta como una mejora sobre Bagging, principalmente por su capacidad para reducir la correlaci√≥n entre los √°rboles individuales que componen el ensamblaje. Esto se logra mediante la introducci√≥n de un subconjunto aleatorio de predictores en cada divisi√≥n del √°rbol. \n",
    "\n",
    "Dado que en esta actividad utilizaremos un **dataset perfectamente balanceado (50/50)**, podremos comparar ambos algoritmos en un escenario ideal, enfoc√°ndonos √∫nicamente en el impacto de su mec√°nica interna sin la variable confusora del desbalance de clases.\n",
    "\n",
    "### Objetivo de la Actividad\n",
    "Evaluar y comparar el rendimiento predictivo y la interpretaci√≥n de los resultados de un modelo de Bagging frente a un modelo de Random Forest en un problema de clasificaci√≥n con datos balanceados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84016291",
   "metadata": {},
   "source": [
    "## 1. Preparaci√≥n del Entorno y Carga de Datos\n",
    "Importaremos las librer√≠as necesarias y cargaremos nuestro nuevo dataset balanceado, `prediccion_pobreza_peru_balanceada.csv`, antes de dividirlo para el entrenamiento y la prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n de librer√≠as\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "# Configuraciones\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Carga y preparaci√≥n de datos\n",
    "# ¬°IMPORTANTE! Usamos el nuevo archivo balanceado.\n",
    "df = pd.read_csv('prediccion_pobreza_peru_balanceada.csv')\n",
    "X = df.drop('PobrezaMonetaria', axis=1)\n",
    "y = df['PobrezaMonetaria']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(\"‚úÖ Entorno y datos preparados.\")\n",
    "print(\"\\nVerificaci√≥n de la distribuci√≥n en el conjunto de entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6167941d",
   "metadata": {},
   "source": [
    "## 2. Implementaci√≥n del Modelo 1: Bagging Classifier\n",
    "Nuestro primer modelo ser√° un ensamblaje de Bagging. Note que, como nuestros datos est√°n balanceados, **no necesitamos usar el par√°metro `class_weight`**. El estimador base ser√° un `DecisionTreeClassifier` est√°ndar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesador (com√∫n para ambos modelos)\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Creaci√≥n del pipeline para Bagging\n",
    "# NOTA: En versiones recientes de scikit-learn, el par√°metro es 'estimator', no 'base_estimator'.\n",
    "bagging_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(random_state=42), # No se necesita class_weight\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "print(\"üöÄ Entrenando el modelo Bagging...\")\n",
    "bagging_pipeline.fit(X_train, y_train)\n",
    "print(\"‚úÖ Modelo Bagging entrenado.\")\n",
    "\n",
    "# Evaluaci√≥n\n",
    "print(\"\\n--- Evaluaci√≥n del Modelo Bagging ---\")\n",
    "y_pred_bagging = bagging_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_bagging, target_names=['No Pobre (0)', 'Pobre (1)']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601512c",
   "metadata": {},
   "source": [
    "## 3. Implementaci√≥n del Modelo 2: Random Forest\n",
    "Ahora, construiremos el modelo de Random Forest. La √∫nica diferencia con Bagging es que el algoritmo interno de Random Forest aplicar√° la selecci√≥n aleatoria de caracter√≠sticas en cada divisi√≥n del √°rbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaee587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaci√≥n del pipeline para Random Forest\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=100, # Mismo n√∫mero de √°rboles para una comparaci√≥n justa\n",
    "        random_state=42,  # No se necesita class_weight\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "print(\"üöÄ Entrenando el modelo Random Forest...\")\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "print(\"‚úÖ Modelo Random Forest entrenado.\")\n",
    "\n",
    "# Evaluaci√≥n\n",
    "print(\"\\n--- Evaluaci√≥n del Modelo Random Forest ---\")\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['No Pobre (0)', 'Pobre (1)']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2691d303",
   "metadata": {},
   "source": [
    "## 4. An√°lisis Comparativo de Resultados\n",
    "Con ambos modelos entrenados, ahora podemos comparar su rendimiento de manera directa.\n",
    "\n",
    "### 4.1 Comparaci√≥n de M√©tricas de Rendimiento\n",
    "Dado que las clases est√°n balanceadas, ahora la m√©trica de **`accuracy`** es un indicador fiable, junto con el **`AUC`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486998b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n de Curvas ROC\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "RocCurveDisplay.from_estimator(bagging_pipeline, X_test, y_test, ax=ax, name='Bagging')\n",
    "RocCurveDisplay.from_estimator(rf_pipeline, X_test, y_test, ax=ax, name='Random Forest')\n",
    "ax.set_title('Comparaci√≥n de Curvas ROC: Bagging vs. Random Forest', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Comparaci√≥n num√©rica\n",
    "auc_bagging = roc_auc_score(y_test, bagging_pipeline.predict_proba(X_test)[:, 1])\n",
    "auc_rf = roc_auc_score(y_test, rf_pipeline.predict_proba(X_test)[:, 1])\n",
    "print(f\"AUC del Modelo Bagging: {auc_bagging:.4f}\")\n",
    "print(f\"AUC del Modelo Random Forest: {auc_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989bc101",
   "metadata": {},
   "source": [
    "### 4.2 Comparaci√≥n de Importancia de Variables\n",
    "¬øCoinciden ambos modelos en cu√°les son las variables m√°s predictivas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81fdf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para obtener y graficar la importancia de variables\n",
    "def plot_feature_importance(pipeline, title, ax):\n",
    "    feature_names_raw = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "    \n",
    "    if isinstance(pipeline.named_steps['classifier'], RandomForestClassifier):\n",
    "        importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "    elif isinstance(pipeline.named_steps['classifier'], BaggingClassifier):\n",
    "        importances = np.mean([tree.feature_importances_ for tree in pipeline.named_steps['classifier'].estimators_], axis=0)\n",
    "    \n",
    "    df_importance = pd.DataFrame({'feature': feature_names_raw, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "    \n",
    "    sns.barplot(x='importance', y='feature', data=df_importance.head(15), ax=ax, palette='viridis')\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel('Importancia')\n",
    "    ax.set_ylabel('Variable')\n",
    "\n",
    "# Crear subplots para comparar\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "plt.suptitle('Top 15 Variables m√°s Importantes', fontsize=20, y=1.02)\n",
    "plot_feature_importance(bagging_pipeline, 'Bagging', ax=ax1)\n",
    "plot_feature_importance(rf_pipeline, 'Random Forest', ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05303a99",
   "metadata": {},
   "source": [
    "## 5. An√°lisis de Resultados y Discusi√≥n\n",
    "Una vez implementados ambos modelos y visualizados los resultados, proceda a realizar un an√°lisis comparativo respondiendo a las siguientes cuestiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45ebe7",
   "metadata": {},
   "source": [
    "### Cuesti√≥n 1: Rendimiento Predictivo\n",
    "Compare la m√©trica de **`accuracy`** y el valor **`AUC`** obtenidos por ambos modelos. Determine si la diferencia en el rendimiento es cuantitativamente significativa o marginal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a37bd33",
   "metadata": {},
   "source": [
    "> *Escriba aqu√≠ su respuesta...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f031516",
   "metadata": {},
   "source": [
    "### Cuesti√≥n 2: Importancia de Variables\n",
    "Analice y compare los rankings de importancia de variables generados por cada modelo. ¬øCoinciden los modelos en las variables m√°s influyentes? ¬øExisten discrepancias notables en la jerarqu√≠a de predictores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fadc173",
   "metadata": {},
   "source": [
    "> *Escriba aqu√≠ su respuesta...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d88a6",
   "metadata": {},
   "source": [
    "### Cuesti√≥n 3: An√°lisis Cr√≠tico\n",
    "A partir de los resultados obtenidos y la teor√≠a expuesta, elabore una justificaci√≥n para el rendimiento observado. Argumente si el mecanismo de descorrelaci√≥n de √°rboles que introduce Random Forest fue, en este caso pr√°ctico, un factor determinante para mejorar la capacidad predictiva en comparaci√≥n con Bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced303a7",
   "metadata": {},
   "source": [
    "> *Escriba aqu√≠ su respuesta...*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
